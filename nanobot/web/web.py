"""Web interface for nanobot."""

from pathlib import Path

from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from fastapi.responses import HTMLResponse
from loguru import logger

from nanobot.config import load_config


def diagnose_knowledge_base(workspace_path: Path) -> dict:
    """è¯Šæ–­çŸ¥è¯†åº“çŠ¶æ€."""
    try:
        from nanobot.knowledge.store import ChromaKnowledgeStore

        # æ£€æŸ¥çŸ¥è¯†åº“ç›®å½•
        knowledge_dir = workspace_path / "knowledge"
        chroma_dir = knowledge_dir / "chroma_db"

        status = {
            "available": False,
            "knowledge_dir_exists": knowledge_dir.exists(),
            "chroma_dir_exists": chroma_dir.exists(),
            "total_collections": 0,
            "total_documents": 0,
            "error": None
        }

        if not knowledge_dir.exists():
            status["error"] = "çŸ¥è¯†åº“ç›®å½•ä¸å­˜åœ¨"
            return status

        # å°è¯•åˆå§‹åŒ–ChromaKnowledgeStore
        try:
            from nanobot.knowledge.rag_config import RAGConfig

            # å…ˆæŸ¥è¯¢çŸ¥è¯†åº“
            config = load_config()
            rag_config = RAGConfig.from_env()
            if config.rerank.model_path:
                rag_config.rerank_model_path = config.rerank.model_path
            if config.rerank.threshold > 0:
                rag_config.rerank_threshold = config.rerank.threshold

            store = ChromaKnowledgeStore(workspace_path, rag_config)
            status["available"] = True

            # èŽ·å–é›†åˆä¿¡æ¯
            collections = store.chroma_client.list_collections()
            status["total_collections"] = len(collections)

            # è®¡ç®—æ€»æ–‡æ¡£æ•°
            total_docs = 0
            for collection in collections:
                try:
                    count = collection.count()
                    total_docs += count
                except:
                    pass
            status["total_documents"] = total_docs

        except Exception as e:
            status["error"] = f"ChromaKnowledgeStoreåˆå§‹åŒ–å¤±è´¥: {str(e)}"

    except ImportError as e:
        status = {
            "available": False,
            "error": f"çŸ¥è¯†åº“æ¨¡å—å¯¼å…¥å¤±è´¥: {str(e)}"
        }
    except Exception as e:
        status = {
            "available": False,
            "error": f"çŸ¥è¯†åº“è¯Šæ–­å¤±è´¥: {str(e)}"
        }

    return status


from nanobot.cli.commands import webui


class ConnectionManager:
    """Manage WebSocket connections."""

    def __init__(self):
        self.active_connections: list[WebSocket] = []

    async def connect(self, websocket: WebSocket):
        await websocket.accept()
        self.active_connections.append(websocket)

    def disconnect(self, websocket: WebSocket):
        self.active_connections.remove(websocket)

    async def send_personal_message(self, message: str, websocket: WebSocket):
        await websocket.send_text(message)

    async def broadcast(self, message: str):
        for connection in self.active_connections:
            await connection.send_text(message)


# Create FastAPI application
web_app = FastAPI(
    title="nanobot Web UI",
    description="Web interface for nanobot"
)

# Create connection manager instance
manager = ConnectionManager()

# Global instances for provider and agent_loop
provider = None
agent_loop = None


def initialize_webui_resources():
    """Initialize resources for webui."""
    global provider, agent_loop
    from nanobot.config.loader import load_config
    from nanobot.bus.queue import MessageBus
    from nanobot.agent.loop import AgentLoop
    from nanobot.providers.litellm_provider import LiteLLMProvider

    config = load_config()
    bus = MessageBus()

    # Create provider from config
    p = config.get_provider()
    model = config.agents.defaults.model
    if not (p and p.api_key) and not model.startswith("bedrock/"):
        return False

    provider = LiteLLMProvider(
        api_key=p.api_key if p else None,
        api_base=config.get_api_base(),
        default_model=model,
        extra_headers=p.extra_headers if p else None,
        provider_name=config.get_provider_name(),
    )

    agent_loop = AgentLoop(
        bus=bus,
        provider=provider,
        workspace=config.workspace_path,
        brave_api_key=config.tools.web.search.api_key or None,
        exec_config=config.tools.exec,
        restrict_to_workspace=config.tools.restrict_to_workspace,
    )

    # è¯Šæ–­çŸ¥è¯†åº“çŠ¶æ€
    knowledge_status = diagnose_knowledge_base(config.workspace_path)
    logger.info(f"[WEB] ðŸ“š çŸ¥è¯†åº“çŠ¶æ€: {knowledge_status}")

    return True


def load_html_template(template_name: str) -> str:
    """Load HTML template from file."""
    template_path = Path(__file__).parent / "templates" / template_name
    try:
        with open(template_path, 'r', encoding='utf-8') as f:
            return f.read()
    except FileNotFoundError:
        return f"<html><body><h1>Template not found: {template_name}</h1></body></html>"
    except Exception as e:
        return f"<html><body><h1>Error loading template: {str(e)}</h1></body></html>"


@web_app.get("/")
async def get():
    """Serve the Web UI homepage."""
    html_content = load_html_template("index.html")
    return HTMLResponse(content=html_content)


@web_app.get("/api/knowledge/preview")
async def preview_knowledge_item(item_id: str = None, source_url: str = None, file_path: str = None):
    """Preview knowledge item content."""
    try:
        from nanobot.config.loader import load_config
        from nanobot.knowledge.store import ChromaKnowledgeStore
        from nanobot.knowledge.rag_config import RAGConfig
        import os
        
        config = load_config()
        rag_config = RAGConfig.from_env()
        
        # ä»Žé…ç½®æ–‡ä»¶ä¸­åŠ è½½ rerank é…ç½®
        if config.rerank.model_path:
            rag_config.rerank_model_path = config.rerank.model_path
        if config.rerank.threshold > 0:
            rag_config.rerank_threshold = config.rerank.threshold
        
        store = ChromaKnowledgeStore(config.workspace_path, rag_config)
        
        # æ ¹æ®æä¾›çš„å‚æ•°èŽ·å–æ–‡æ¡£å†…å®¹
        if item_id:
            # é€šè¿‡item_idèŽ·å–çŸ¥è¯†æ¡ç›®çš„å®Œæ•´å†…å®¹
            full_content = await get_full_document_content(store, item_id)
            if full_content:
                return {
                    "status": "success",
                    "message": "æ–‡æ¡£é¢„è§ˆæˆåŠŸ",
                    "item_id": item_id,
                    "content": full_content["content"],
                    "metadata": {
                        "source": "knowledge_base",
                        "title": full_content.get("title", ""),
                        "domain": full_content.get("domain", ""),
                        "category": full_content.get("category", ""),
                        "tags": full_content.get("tags", []),
                        "created_at": full_content.get("created_at", ""),
                        "source_url": full_content.get("source_url", ""),
                        "file_path": full_content.get("file_path", ""),
                        "preview_available": True
                    }
                }
            else:
                return {
                    "status": "error",
                    "message": f"æœªæ‰¾åˆ°IDä¸º {item_id} çš„çŸ¥è¯†æ¡ç›®"
                }
                
        elif source_url:
            # é€šè¿‡URLèŽ·å–æ–‡æ¡£å†…å®¹
            try:
                # è¿™é‡Œå¯ä»¥å®žçŽ°URLå†…å®¹æŠ“å–ï¼Œæš‚æ—¶è¿”å›žæ¨¡æ‹Ÿå†…å®¹
                return {
                    "status": "success", 
                    "message": "URLæ–‡æ¡£é¢„è§ˆæˆåŠŸ",
                    "source_url": source_url,
                    "content": f"URLæ–‡æ¡£å†…å®¹é¢„è§ˆ:\n\næ¥æº: {source_url}\n\næ³¨æ„ï¼šURLå†…å®¹æŠ“å–åŠŸèƒ½éœ€è¦è¿›ä¸€æ­¥å®žçŽ°ï¼Œå½“å‰æ˜¾ç¤ºçš„æ˜¯æ¨¡æ‹Ÿå†…å®¹ã€‚",
                    "metadata": {
                        "source": "url",
                        "preview_available": True
                    }
                }
            except Exception as e:
                return {
                    "status": "error",
                    "message": f"èŽ·å–URLå†…å®¹å¤±è´¥: {str(e)}"
                }
                
        elif file_path:
            # é€šè¿‡æ–‡ä»¶è·¯å¾„èŽ·å–æ–‡æ¡£å†…å®¹
            try:
                # å®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿æ–‡ä»¶è·¯å¾„åœ¨å·¥ä½œç©ºé—´å†…
                workspace_path = str(config.workspace_path)
                abs_file_path = os.path.abspath(file_path)
                
                if not abs_file_path.startswith(workspace_path):
                    return {
                        "status": "error",
                        "message": "æ–‡ä»¶è·¯å¾„è¶…å‡ºå·¥ä½œç©ºé—´èŒƒå›´ï¼Œæ‹’ç»è®¿é—®"
                    }
                
                if not os.path.exists(abs_file_path):
                    return {
                        "status": "error",
                        "message": f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"
                    }
                
                # è¯»å–æ–‡ä»¶å†…å®¹
                with open(abs_file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                return {
                    "status": "success",
                    "message": "æ–‡ä»¶é¢„è§ˆæˆåŠŸ", 
                    "file_path": file_path,
                    "content": content,
                    "metadata": {
                        "source": "file",
                        "file_size": os.path.getsize(abs_file_path),
                        "preview_available": True
                    }
                }
            except UnicodeDecodeError:
                return {
                    "status": "error",
                    "message": "æ–‡ä»¶ç¼–ç ä¸æ”¯æŒï¼Œæ— æ³•é¢„è§ˆ"
                }
            except Exception as e:
                return {
                    "status": "error",
                    "message": f"è¯»å–æ–‡ä»¶å¤±è´¥: {str(e)}"
                }
        else:
            return {
                "status": "error",
                "message": "è¯·æä¾›item_idã€source_urlæˆ–file_pathå‚æ•°"
            }
            
    except Exception as e:
        return {
            "status": "error",
            "message": f"æ–‡æ¡£é¢„è§ˆå¤±è´¥: {str(e)}"
        }


async def get_full_document_content(store, item_id: str):
    """èŽ·å–çŸ¥è¯†æ¡ç›®çš„å®Œæ•´æ–‡æ¡£å†…å®¹."""
    try:
        # æŸ¥æ‰¾è¯¥çŸ¥è¯†æ¡ç›®æ‰€å±žçš„é¢†åŸŸ
        domain = None
        all_collections = store.chroma_client.list_collections()
        
        for coll_info in all_collections:
            coll_name = coll_info.name
            if coll_name.startswith("knowledge_"):
                try:
                    collection = store.chroma_client.get_collection(coll_name)
                    # æŸ¥è¯¢è¯¥é›†åˆä¸­æ˜¯å¦æœ‰è¯¥ item_id çš„åˆ†å—
                    results = collection.get(
                        where={"item_id": item_id},
                        include=["documents", "metadatas"]
                    )
                    
                    if results and results["ids"] and len(results["ids"]) > 0:
                        domain = coll_name.replace("knowledge_", "")
                        break
                except Exception as e:
                    logger.warning(f"æŸ¥è¯¢é›†åˆ {coll_name} å¤±è´¥: {str(e)}")
                    continue
        
        if not domain:
            return None
        
        # èŽ·å–è¯¥çŸ¥è¯†æ¡ç›®çš„æ‰€æœ‰åˆ†å—
        collection = store.chroma_client.get_collection(f"knowledge_{domain}")
        chunks = collection.get(
            where={"item_id": item_id},
            include=["documents", "metadatas"]
        )
        
        if not chunks or not chunks["ids"]:
            return None
        
        # æŒ‰ chunk_index æŽ’åºå¹¶åˆå¹¶å†…å®¹
        chunk_data = []
        metadata = None
        
        for i in range(len(chunks["ids"])):
            chunk_metadata = chunks["metadatas"][i]
            chunk_document = chunks["documents"][i]
            chunk_index = chunk_metadata.get("chunk_index", 0)
            
            chunk_data.append({
                "index": chunk_index,
                "text": chunk_document,
                "metadata": chunk_metadata
            })
            
            # ä½¿ç”¨ç¬¬ä¸€ä¸ªåˆ†å—çš„å…ƒæ•°æ®ä½œä¸ºæ•´ä½“å…ƒæ•°æ®
            if metadata is None:
                metadata = chunk_metadata
        
        # æŒ‰ç´¢å¼•æŽ’åº
        chunk_data.sort(key=lambda x: x["index"])
        
        # åˆå¹¶æ‰€æœ‰åˆ†å—çš„æ–‡æœ¬
        full_content = " ".join(chunk["text"] for chunk in chunk_data)
        
        return {
            "content": full_content,
            "title": metadata.get("title", ""),
            "domain": metadata.get("domain", ""),
            "category": metadata.get("category", ""),
            "tags": metadata.get("tags", []),
            "created_at": metadata.get("created_at", ""),
            "updated_at": metadata.get("updated_at", ""),
            "source_url": metadata.get("source_url", ""),
            "file_path": metadata.get("file_path", ""),
            "source": metadata.get("source", ""),
            "priority": metadata.get("priority", 1)
        }
        
    except Exception as e:
        logger.error(f"èŽ·å–å®Œæ•´æ–‡æ¡£å†…å®¹å¤±è´¥: {str(e)}")
        return None


@web_app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    """Handle WebSocket connections with real-time streaming."""
    await manager.connect(websocket)
    try:
        while True:
            data = await websocket.receive_text()
            # Process user message with real-time streaming
            await process_user_message_streaming(data, websocket)
    except WebSocketDisconnect:
        manager.disconnect(websocket)


async def process_user_message_streaming(user_input: str, websocket: WebSocket):
    """Process user message with real-time streaming output."""
    import time
    import json
    from nanobot.config.loader import load_config
    from nanobot.knowledge.store import ChromaKnowledgeStore

    start_time = time.time()

    # Check if provider and agent_loop are initialized
    if not provider or not agent_loop:
        await websocket.send_text("Error: Web UI resources not initialized. Please restart the server.")
        return

    # Send initial processing message
    await websocket.send_text("ðŸ¤– AI Agent is processing your request...\n\n")

    try:
        # å…ˆæŸ¥è¯¢çŸ¥è¯†åº“
        config = load_config()
        
        # åˆ›å»º RAGConfig å¹¶ä»Žé…ç½®æ–‡ä»¶åŠ è½½ rerank è®¾ç½®
        from nanobot.knowledge.rag_config import RAGConfig
        rag_config = RAGConfig.from_env()
        
        # ä»Žé…ç½®æ–‡ä»¶ä¸­åŠ è½½ rerank é…ç½®
        if config.rerank.model_path:
            rag_config.rerank_model_path = config.rerank.model_path
        if config.rerank.threshold > 0:
            rag_config.rerank_threshold = config.rerank.threshold
            
        store = ChromaKnowledgeStore(config.workspace_path, rag_config)
    except RuntimeError as e:
        # CrossEncoder åˆå§‹åŒ–å¤±è´¥
        error_msg = f"âŒ çŸ¥è¯†åº“åˆå§‹åŒ–å¤±è´¥: {str(e)}\n\næœåŠ¡å¯åŠ¨ç»ˆæ­¢ï¼Œè¯·æ£€æŸ¥ CrossEncoder æ¨¡åž‹é…ç½®ã€‚\n"
        await websocket.send_text(error_msg)
        # å…³é—­WebSocketè¿žæŽ¥
        await websocket.close(code=1011, reason="CrossEncoder initialization failed")
        return
    except Exception as e:
        # å…¶ä»–åˆå§‹åŒ–é”™è¯¯
        error_msg = f"âŒ çŸ¥è¯†åº“åˆå§‹åŒ–å¤±è´¥: {str(e)}\n\n"
        await websocket.send_text(error_msg)
        return

    # å‘é€çŸ¥è¯†åº“æŸ¥è¯¢å¼€å§‹ä¿¡æ¯
    await websocket.send_text("ðŸ“š æ­£åœ¨æŸ¥è¯¢çŸ¥è¯†åº“...\n")

    # æœç´¢çŸ¥è¯†åº“ï¼Œè¿”å›žå¾—åˆ†
    search_result = store.search_knowledge(query=user_input, return_scores=True)

    # æ£€æŸ¥è¿”å›žå€¼ç±»åž‹
    if isinstance(search_result, tuple) and len(search_result) == 2:
        knowledge_results, scores = search_result
    else:
        knowledge_results = search_result
        scores = []

    # æ£€æŸ¥æ˜¯å¦æœ‰ç»“æžœä¸”é‡æŽ’åºå¾—åˆ†è¶…è¿‡70
    if knowledge_results and scores:
        # èŽ·å–é‡æŽ’åºå¾—åˆ†æœ€é«˜çš„ç»“æžœ
        top_score = scores[0].get('rerank_score', 0)

        await websocket.send_text(f"âœ… çŸ¥è¯†åº“æŸ¥è¯¢å®Œæˆï¼Œæ‰¾åˆ° {len(knowledge_results)} ä¸ªç»“æžœ\n")
        await websocket.send_text(f"ðŸ“Š æœ€é«˜é‡æŽ’åºå¾—åˆ†: {top_score:.2f}\n\n")

        # æ ¼å¼åŒ–çŸ¥è¯†åº“ç»“æžœï¼ŒåŒ…å«é¢„è§ˆä¿¡æ¯
        top_item = knowledge_results[0]
        
        # æ·»åŠ é¢„è§ˆä¿¡æ¯
        preview_links = []
        
        # æ£€æŸ¥æ–‡æ¡£é“¾æŽ¥
        if hasattr(top_item, 'source_url') and top_item.source_url:
            preview_links.append(f"ðŸ“„ æ–‡æ¡£é“¾æŽ¥: {top_item.source_url}")
        
        # æ£€æŸ¥æ–‡ä»¶è·¯å¾„
        if hasattr(top_item, 'file_path') and top_item.file_path:
            preview_links.append(f"ðŸ“ æ–‡ä»¶è·¯å¾„: {top_item.file_path}")
        
        # æ£€æŸ¥æ˜¯å¦å¯é¢„è§ˆ
        if hasattr(top_item, 'preview_available') and top_item.preview_available:
            preview_links.append("ðŸ” æ”¯æŒé¢„è§ˆ")
        
        # æ·»åŠ çŸ¥è¯†æ¡ç›®IDç”¨äºŽé¢„è§ˆ
        if hasattr(top_item, 'id') and top_item.id:
            preview_links.append(f"ðŸ†” æ¡ç›®ID: {top_item.id}")
        
        preview_info = ""
        if preview_links:
            preview_info = f"\n**é¢„è§ˆä¿¡æ¯**: {' | '.join(preview_links)}"
        
        # æ ¼å¼åŒ–çŸ¥è¯†åº“ç»“æžœ
        formatted_result = f"""### 1. {top_item.title}
**Domain**: {top_item.domain} | **Category**: {top_item.category} | **Priority**: {top_item.priority}
**Tags**: {', '.join(top_item.tags)}
**Created**: {top_item.created_at[:10]}{preview_info}

{top_item.content}

---
"""
        
        # æž„å»ºé¢„è§ˆé¡¹ç›®æ•°ç»„
        preview_items = []
        
        # æ·»åŠ æ–‡ä»¶è·¯å¾„é¢„è§ˆé¡¹
        if hasattr(top_item, 'file_path') and top_item.file_path:
            preview_items.append({
                'type': 'file',
                'id': top_item.file_path,
                'label': 'ðŸ“ é¢„è§ˆæ–‡ä»¶å†…å®¹',
                'path': top_item.file_path
            })
        
        # æ·»åŠ æ–‡æ¡£é“¾æŽ¥é¢„è§ˆé¡¹
        if hasattr(top_item, 'source_url') and top_item.source_url:
            preview_items.append({
                'type': 'url',
                'id': top_item.source_url,
                'label': 'ðŸ“„ é¢„è§ˆæ–‡æ¡£é“¾æŽ¥',
                'url': top_item.source_url
            })
        
        # æ·»åŠ å®Œæ•´å†…å®¹é¢„è§ˆé¡¹
        if hasattr(top_item, 'id') and top_item.id and hasattr(top_item, 'preview_available') and top_item.preview_available:
            preview_items.append({
                'type': 'item',
                'id': top_item.id,
                'label': 'ðŸ” é¢„è§ˆå®Œæ•´å†…å®¹',
                'item_id': top_item.id
            })
        
        # é€šè¿‡JSONæ ¼å¼å‘é€çŸ¥è¯†åº“ç»“æžœï¼Œè¿™æ ·å‰ç«¯å¯ä»¥è§£æžé¢„è§ˆä¿¡æ¯
        import json
        knowledge_message = {
            'type': 'stream_chunk',
            'content_type': 'knowledge',
            'content': f"æ‰¾åˆ° {len(knowledge_results)} ä¸ªç»“æžœï¼Œæœ€é«˜å¾—åˆ†: {top_score:.2f}",
            'knowledge_status': 'success',
            'knowledge_count': len(knowledge_results),
            'knowledge_result': formatted_result,
            'preview_items': preview_items,  # æ–°å¢žé¢„è§ˆé¡¹ç›®æ•°ç»„
            'timestamp': time.time(),
            'duration_from_start': round(time.time() - start_time, 3)
        }
        
        await websocket.send_text(json.dumps(knowledge_message, ensure_ascii=False))

        # ä»Žé…ç½®ä¸­èŽ·å–é‡æŽ’åºé˜ˆå€¼
        rerank_threshold = config.rerank.threshold if config.rerank.threshold > 0 else 80

        # æ£€æŸ¥é‡æŽ’åºå¾—åˆ†æ˜¯å¦è¶…è¿‡é˜ˆå€¼
        if top_score >= rerank_threshold:
            await websocket.send_text(f"ðŸš€ é‡æŽ’åºå¾—åˆ†è¶…è¿‡{rerank_threshold}ï¼Œç›´æŽ¥è¾“å‡ºçŸ¥è¯†åº“ç»“æžœ\n\n")
            # ç›´æŽ¥è¾“å‡ºçŸ¥è¯†åº“ç»“æžœ
            await websocket.send_text("ðŸ“š çŸ¥è¯†åº“ç­”æ¡ˆï¼š\n")
            await websocket.send_text(f"{knowledge_results[0].content}\n\n")

            # å‘é€å¤„ç†æ—¶é—´
            end_time = time.time()
            total_processing_time = round(end_time - start_time, 1)
            await websocket.send_text(f"\n---\n*æ€»è€—æ—¶: {total_processing_time}ç§’*\n")
            return
        else:
            # å¾—åˆ†ä½ŽäºŽé˜ˆå€¼ï¼Œç»§ç»­åŽŸå§‹é€»è¾‘ï¼Œè®©LLMå¤„ç†
            await websocket.send_text(f"ðŸ¤– é‡æŽ’åºå¾—åˆ†ä½ŽäºŽ{rerank_threshold}ï¼Œè®©AIåˆ†æžçŸ¥è¯†åº“ç»“æžœ...\n\n")
    else:
        await websocket.send_text("ðŸ“­ çŸ¥è¯†åº“ä¸­æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ç»“æžœ\n\n")

    # Record LLM start time
    llm_start_time = time.time()

    # è®¾ç½®æµå¼å›žè°ƒå‡½æ•°
    async def stream_callback(context_info: dict):
        """æµå¼è¾“å‡ºå›žè°ƒå‡½æ•°ï¼ŒæŒ‰ç±»åž‹åˆ†ç±»æ˜¾ç¤ºå†…å®¹ï¼Œå¹¶ç»Ÿè®¡æ¯æ¬¡è¿”å›žçš„è€—æ—¶"""
        content = context_info.get('content', '')
        if not content.strip():
            return

        # è®°å½•å½“å‰å›žè°ƒçš„æ—¶é—´
        callback_time = time.time()

        # æ ¹æ®å†…å®¹ç±»åž‹æ·»åŠ åˆ†ç±»æ ‡è®°
        content_type = 'reasoning'
        if context_info.get('is_final_answer', False):
            content_type = 'answer'
        elif context_info.get('is_tool_call', False):
            content_type = 'tool'
        elif context_info.get('is_iteration_start', False):
            content_type = 'iteration'
        elif context_info.get('is_knowledge_query', False):
            content_type = 'knowledge'

        # è®¡ç®—ä»Žå¼€å§‹å¤„ç†åˆ°å½“å‰å›žè°ƒçš„è€—æ—¶
        current_duration = round(callback_time - start_time, 3)

        # èŽ·å–è¿­ä»£è®¡æ•°ä¿¡æ¯
        iteration_count = context_info.get('iteration_count', 0)

        # ä¸ºä¸åŒç±»åž‹çš„å†…å®¹æ·»åŠ é€‚å½“çš„æ ‡è®°ï¼Œé¿å…é‡å¤ä¿¡æ¯
        if content_type == 'iteration':
            # è¿­ä»£å¼€å§‹ä¿¡æ¯
            enhanced_content = f"ðŸ”„ ç¬¬{iteration_count}æ¬¡è¿­ä»£å¼€å§‹\n"
        elif content_type == 'tool':
            # å·¥å…·æ‰§è¡Œä¿¡æ¯ - åªæ·»åŠ çŠ¶æ€æ ‡è®°ï¼Œä¸é‡å¤æ·»åŠ è€—æ—¶ä¿¡æ¯
            tool_status = context_info.get('tool_status', '')
            if tool_status == 'start':
                enhanced_content = f"ðŸ”§ å¼€å§‹æ‰§è¡Œå·¥å…·\n{content}"
            elif tool_status == 'completed':
                enhanced_content = f"âœ… å·¥å…·æ‰§è¡Œå®Œæˆ\n{content}"
            elif tool_status == 'error':
                enhanced_content = f"âŒ å·¥å…·æ‰§è¡Œå¤±è´¥\n{content}"
            else:
                enhanced_content = f"ðŸ”§ å·¥å…·æ‰§è¡Œ\n{content}"
        elif content_type == 'knowledge':
            # çŸ¥è¯†åº“æŸ¥è¯¢ä¿¡æ¯
            knowledge_status = context_info.get('knowledge_status', '')
            if knowledge_status == 'start':
                enhanced_content = f"ðŸ“š {content}"
            elif knowledge_status == 'searching':
                enhanced_content = f"ðŸ” {content}"
            elif knowledge_status == 'success':
                knowledge_count = context_info.get('knowledge_count', 0)
                enhanced_content = f"âœ… {content}"
            elif knowledge_status == 'no_results':
                enhanced_content = f"ðŸ“­ {content}"
            elif knowledge_status == 'error':
                enhanced_content = f"âŒ {content}"
            elif knowledge_status == 'skipped':
                enhanced_content = f"âš ï¸ {content}"
            else:
                enhanced_content = f"ðŸ“š {content}"
        else:
            # å…¶ä»–ç±»åž‹å†…å®¹ - ç›´æŽ¥ä½¿ç”¨åŽŸå§‹å†…å®¹ï¼Œä¸æ·»åŠ é¢å¤–ä¿¡æ¯
            enhanced_content = content

        # å‘é€å¸¦ç±»åž‹æ ‡è®°å’Œè€—æ—¶ç»Ÿè®¡çš„å†…å®¹
        message_data = {
            'type': 'stream_chunk',
            'content_type': content_type,
            'content': enhanced_content,
            'is_reasoning': context_info.get('is_reasoning', False),
            'is_tool_call': content_type == 'tool' or context_info.get('is_tool_call', False),
            'is_final_answer': context_info.get('is_final_answer', False),
            'is_iteration_start': context_info.get('is_iteration_start', False),
            'timestamp': callback_time,
            'duration_from_start': current_duration,
            'iteration_count': iteration_count,
        }

        # å¦‚æžœæ˜¯å·¥å…·è°ƒç”¨ï¼Œæ·»åŠ å·¥å…·åç§°å’ŒçŠ¶æ€ä¿¡æ¯
        if content_type == 'tool':
            message_data['tool_name'] = context_info.get('tool_name', '')
            message_data['tool_status'] = context_info.get('tool_status', '')
            message_data['tool_duration'] = context_info.get('tool_duration', 0)
            message_data['tool_result'] = context_info.get('tool_result', '')
            message_data['tool_error'] = context_info.get('tool_error', '')
            message_data['tool_args'] = context_info.get('tool_args')

        # å¦‚æžœæ˜¯çŸ¥è¯†åº“æŸ¥è¯¢ï¼Œæ·»åŠ çŸ¥è¯†åº“ç›¸å…³ä¿¡æ¯
        if content_type == 'knowledge':
            message_data['knowledge_status'] = context_info.get('knowledge_status', '')
            message_data['knowledge_domain'] = context_info.get('knowledge_domain', '')
            message_data['knowledge_query'] = context_info.get('knowledge_query', '')
            message_data['knowledge_count'] = context_info.get('knowledge_count', 0)
            message_data['knowledge_result'] = context_info.get('knowledge_result', '')

        await websocket.send_text(json.dumps(message_data, ensure_ascii=False))

    # ä¸ºagent_loopè®¾ç½®æµå¼å›žè°ƒ
    agent_loop.stream_callback = stream_callback

    # Process with streaming output
    response = await agent_loop.process_direct(user_input, session_key="cli:webui")

    # Record LLM end time
    llm_end_time = time.time()
    llm_execution_time = round(llm_end_time - llm_start_time, 1)

    # Send the actual response (å¦‚æžœæµå¼è¾“å‡ºå·²ç»å‘é€äº†å†…å®¹ï¼Œè¿™é‡Œå¯èƒ½ä¸éœ€è¦å†å‘é€)
    if response and response.strip():
        # æ£€æŸ¥æ˜¯å¦å·²ç»é€šè¿‡æµå¼è¾“å‡ºå‘é€äº†å†…å®¹
        # å¦‚æžœæ²¡æœ‰æµå¼è¾“å‡ºï¼Œåˆ™å‘é€å®Œæ•´å“åº”
        await websocket.send_text("\n" + response)
    elif not response:
        await websocket.send_text("No response from agent.")

    end_time = time.time()
    total_processing_time = round(end_time - start_time, 1)

    # Send processing times
    await websocket.send_text(f"\n---\n*æ€»è€—æ—¶: {total_processing_time}ç§’ | LLMæ‰§è¡Œè€—æ—¶: {llm_execution_time}ç§’*")


async def process_user_message(user_input: str) -> str:
    """Process user message using nanobot's AgentLoop."""
    import time

    start_time = time.time()

    # Check if provider and agent_loop are initialized
    if not provider or not agent_loop:
        return "Error: Web UI resources not initialized. Please restart the server."

    # Record LLM start time
    llm_start_time = time.time()

    response = await agent_loop.process_direct(user_input, session_key="cli:webui")

    # Record LLM end time
    llm_end_time = time.time()
    llm_execution_time = round(llm_end_time - llm_start_time, 1)

    end_time = time.time()
    total_processing_time = round(end_time - start_time, 1)

    if response:
        return f"{response}\n\n---\n*æ€»è€—æ—¶: {total_processing_time}ç§’ | LLMæ‰§è¡Œè€—æ—¶: {llm_execution_time}ç§’*"
    else:
        return f"No response from agent.\n\n---\n*æ€»è€—æ—¶: {total_processing_time}ç§’ | LLMæ‰§è¡Œè€—æ—¶: {llm_execution_time}ç§’*"


if __name__ == "__main__":
    webui()
