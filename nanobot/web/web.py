"""Web interface for nanobot."""

from pathlib import Path

from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from fastapi.responses import HTMLResponse
from loguru import logger

from nanobot.config import load_config


def diagnose_knowledge_base(workspace_path: Path) -> dict:
    """è¯Šæ–­çŸ¥è¯†åº“çŠ¶æ€."""
    try:
        from nanobot.knowledge.store import ChromaKnowledgeStore

        # æ£€æŸ¥çŸ¥è¯†åº“ç›®å½•
        knowledge_dir = workspace_path / "knowledge"
        chroma_dir = knowledge_dir / "chroma_db"

        status = {
            "available": False,
            "knowledge_dir_exists": knowledge_dir.exists(),
            "chroma_dir_exists": chroma_dir.exists(),
            "total_collections": 0,
            "total_documents": 0,
            "error": None
        }

        if not knowledge_dir.exists():
            status["error"] = "çŸ¥è¯†åº“ç›®å½•ä¸å­˜åœ¨"
            return status

        # å°è¯•åˆå§‹åŒ–ChromaKnowledgeStore
        try:
            from nanobot.knowledge.rag_config import RAGConfig

            # å…ˆæŸ¥è¯¢çŸ¥è¯†åº“
            config = load_config()
            rag_config = RAGConfig.from_env()
            if config.rerank.model_path:
                rag_config.rerank_model_path = config.rerank.model_path
            if config.rerank.threshold > 0:
                rag_config.rerank_threshold = config.rerank.threshold

            store = ChromaKnowledgeStore(workspace_path, rag_config)
            status["available"] = True

            # èŽ·å–é›†åˆä¿¡æ¯
            collections = store.chroma_client.list_collections()
            status["total_collections"] = len(collections)

            # è®¡ç®—æ€»æ–‡æ¡£æ•°
            total_docs = 0
            for collection in collections:
                try:
                    count = collection.count()
                    total_docs += count
                except:
                    pass
            status["total_documents"] = total_docs

        except Exception as e:
            status["error"] = f"ChromaKnowledgeStoreåˆå§‹åŒ–å¤±è´¥: {str(e)}"

    except ImportError as e:
        status = {
            "available": False,
            "error": f"çŸ¥è¯†åº“æ¨¡å—å¯¼å…¥å¤±è´¥: {str(e)}"
        }
    except Exception as e:
        status = {
            "available": False,
            "error": f"çŸ¥è¯†åº“è¯Šæ–­å¤±è´¥: {str(e)}"
        }

    return status


from nanobot.cli.commands import webui


class ConnectionManager:
    """Manage WebSocket connections."""

    def __init__(self):
        self.active_connections: list[WebSocket] = []

    async def connect(self, websocket: WebSocket):
        await websocket.accept()
        self.active_connections.append(websocket)

    def disconnect(self, websocket: WebSocket):
        self.active_connections.remove(websocket)

    async def send_personal_message(self, message: str, websocket: WebSocket):
        await websocket.send_text(message)

    async def broadcast(self, message: str):
        for connection in self.active_connections:
            await connection.send_text(message)


# Create FastAPI application
web_app = FastAPI(
    title="nanobot Web UI",
    description="Web interface for nanobot"
)

# Create connection manager instance
manager = ConnectionManager()

# Global instances for provider and agent_loop
provider = None
agent_loop = None


def initialize_webui_resources():
    """Initialize resources for webui."""
    global provider, agent_loop
    from nanobot.config.loader import load_config
    from nanobot.bus.queue import MessageBus
    from nanobot.agent.loop import AgentLoop
    from nanobot.providers.litellm_provider import LiteLLMProvider

    config = load_config()
    bus = MessageBus()

    # Create provider from config
    p = config.get_provider()
    model = config.agents.defaults.model
    if not (p and p.api_key) and not model.startswith("bedrock/"):
        return False

    provider = LiteLLMProvider(
        api_key=p.api_key if p else None,
        api_base=config.get_api_base(),
        default_model=model,
        extra_headers=p.extra_headers if p else None,
        provider_name=config.get_provider_name(),
    )

    agent_loop = AgentLoop(
        bus=bus,
        provider=provider,
        workspace=config.workspace_path,
        brave_api_key=config.tools.web.search.api_key or None,
        exec_config=config.tools.exec,
        restrict_to_workspace=config.tools.restrict_to_workspace,
    )

    # è¯Šæ–­çŸ¥è¯†åº“çŠ¶æ€
    knowledge_status = diagnose_knowledge_base(config.workspace_path)
    logger.info(f"[WEB] ðŸ“š çŸ¥è¯†åº“çŠ¶æ€: {knowledge_status}")

    return True


def load_html_template(template_name: str) -> str:
    """Load HTML template from file."""
    template_path = Path(__file__).parent / "templates" / template_name
    try:
        with open(template_path, 'r', encoding='utf-8') as f:
            return f.read()
    except FileNotFoundError:
        return f"<html><body><h1>Template not found: {template_name}</h1></body></html>"
    except Exception as e:
        return f"<html><body><h1>Error loading template: {str(e)}</h1></body></html>"


@web_app.get("/")
async def get():
    """Serve the Web UI homepage."""
    html_content = load_html_template("index.html")
    return HTMLResponse(content=html_content)


@web_app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    """Handle WebSocket connections with real-time streaming."""
    await manager.connect(websocket)
    try:
        while True:
            data = await websocket.receive_text()
            # Process user message with real-time streaming
            await process_user_message_streaming(data, websocket)
    except WebSocketDisconnect:
        manager.disconnect(websocket)


async def process_user_message_streaming(user_input: str, websocket: WebSocket):
    """Process user message with real-time streaming output."""
    import time
    import json
    from nanobot.config.loader import load_config
    from nanobot.knowledge.store import ChromaKnowledgeStore

    start_time = time.time()

    # Check if provider and agent_loop are initialized
    if not provider or not agent_loop:
        await websocket.send_text("Error: Web UI resources not initialized. Please restart the server.")
        return

    # Send initial processing message
    await websocket.send_text("ðŸ¤– AI Agent is processing your request...\n\n")

    try:
        # å…ˆæŸ¥è¯¢çŸ¥è¯†åº“
        config = load_config()
        
        # åˆ›å»º RAGConfig å¹¶ä»Žé…ç½®æ–‡ä»¶åŠ è½½ rerank è®¾ç½®
        from nanobot.knowledge.rag_config import RAGConfig
        rag_config = RAGConfig.from_env()
        
        # ä»Žé…ç½®æ–‡ä»¶ä¸­åŠ è½½ rerank é…ç½®
        if config.rerank.model_path:
            rag_config.rerank_model_path = config.rerank.model_path
        if config.rerank.threshold > 0:
            rag_config.rerank_threshold = config.rerank.threshold
            
        store = ChromaKnowledgeStore(config.workspace_path, rag_config)
    except RuntimeError as e:
        # CrossEncoder åˆå§‹åŒ–å¤±è´¥
        error_msg = f"âŒ çŸ¥è¯†åº“åˆå§‹åŒ–å¤±è´¥: {str(e)}\n\næœåŠ¡å¯åŠ¨ç»ˆæ­¢ï¼Œè¯·æ£€æŸ¥ CrossEncoder æ¨¡åž‹é…ç½®ã€‚\n"
        await websocket.send_text(error_msg)
        # å…³é—­WebSocketè¿žæŽ¥
        await websocket.close(code=1011, reason="CrossEncoder initialization failed")
        return
    except Exception as e:
        # å…¶ä»–åˆå§‹åŒ–é”™è¯¯
        error_msg = f"âŒ çŸ¥è¯†åº“åˆå§‹åŒ–å¤±è´¥: {str(e)}\n\n"
        await websocket.send_text(error_msg)
        return

    # å‘é€çŸ¥è¯†åº“æŸ¥è¯¢å¼€å§‹ä¿¡æ¯
    await websocket.send_text("ðŸ“š æ­£åœ¨æŸ¥è¯¢çŸ¥è¯†åº“...\n")

    # æœç´¢çŸ¥è¯†åº“ï¼Œè¿”å›žå¾—åˆ†
    search_result = store.search_knowledge(query=user_input, return_scores=True)

    # æ£€æŸ¥è¿”å›žå€¼ç±»åž‹
    if isinstance(search_result, tuple) and len(search_result) == 2:
        knowledge_results, scores = search_result
    else:
        knowledge_results = search_result
        scores = []

    # æ£€æŸ¥æ˜¯å¦æœ‰ç»“æžœä¸”é‡æŽ’åºå¾—åˆ†è¶…è¿‡70
    if knowledge_results and scores:
        # èŽ·å–é‡æŽ’åºå¾—åˆ†æœ€é«˜çš„ç»“æžœ
        top_score = scores[0].get('rerank_score', 0)

        await websocket.send_text(f"âœ… çŸ¥è¯†åº“æŸ¥è¯¢å®Œæˆï¼Œæ‰¾åˆ° {len(knowledge_results)} ä¸ªç»“æžœ\n")
        await websocket.send_text(f"ðŸ“Š æœ€é«˜é‡æŽ’åºå¾—åˆ†: {top_score:.2f}\n\n")

        # å‘é€çŸ¥è¯†åº“ç»“æžœ
        await websocket.send_text("ðŸ“‹ çŸ¥è¯†åº“æŸ¥è¯¢ç»“æžœï¼š\n")
        for i, (item, score) in enumerate(zip(knowledge_results[:3], scores[:3]), 1):
            await websocket.send_text(f"{i}. {item.title} (å¾—åˆ†: {score.get('rerank_score', 0):.2f})\n")
            await websocket.send_text(f"   å†…å®¹: {item.content[:100]}...\n\n")

        # ä»Žé…ç½®ä¸­èŽ·å–é‡æŽ’åºé˜ˆå€¼
        rerank_threshold = config.rerank.threshold if config.rerank.threshold > 0 else 80

        # æ£€æŸ¥é‡æŽ’åºå¾—åˆ†æ˜¯å¦è¶…è¿‡é˜ˆå€¼
        if top_score >= rerank_threshold:
            await websocket.send_text(f"ðŸš€ é‡æŽ’åºå¾—åˆ†è¶…è¿‡{rerank_threshold}ï¼Œç›´æŽ¥è¾“å‡ºçŸ¥è¯†åº“ç»“æžœ\n\n")
            # ç›´æŽ¥è¾“å‡ºçŸ¥è¯†åº“ç»“æžœ
            await websocket.send_text("ðŸ“š çŸ¥è¯†åº“ç­”æ¡ˆï¼š\n")
            await websocket.send_text(f"{knowledge_results[0].content}\n\n")

            # å‘é€å¤„ç†æ—¶é—´
            end_time = time.time()
            total_processing_time = round(end_time - start_time, 1)
            await websocket.send_text(f"\n---\n*æ€»è€—æ—¶: {total_processing_time}ç§’*\n")
            return
        else:
            # å¾—åˆ†ä½ŽäºŽé˜ˆå€¼ï¼Œç»§ç»­åŽŸå§‹é€»è¾‘ï¼Œè®©LLMå¤„ç†
            await websocket.send_text(f"ðŸ¤– é‡æŽ’åºå¾—åˆ†ä½ŽäºŽ{rerank_threshold}ï¼Œè®©AIåˆ†æžçŸ¥è¯†åº“ç»“æžœ...\n\n")
    else:
        await websocket.send_text("ðŸ“­ çŸ¥è¯†åº“ä¸­æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ç»“æžœ\n\n")

    # Record LLM start time
    llm_start_time = time.time()

    # è®¾ç½®æµå¼å›žè°ƒå‡½æ•°
    async def stream_callback(context_info: dict):
        """æµå¼è¾“å‡ºå›žè°ƒå‡½æ•°ï¼ŒæŒ‰ç±»åž‹åˆ†ç±»æ˜¾ç¤ºå†…å®¹ï¼Œå¹¶ç»Ÿè®¡æ¯æ¬¡è¿”å›žçš„è€—æ—¶"""
        content = context_info.get('content', '')
        if not content.strip():
            return

        # è®°å½•å½“å‰å›žè°ƒçš„æ—¶é—´
        callback_time = time.time()

        # æ ¹æ®å†…å®¹ç±»åž‹æ·»åŠ åˆ†ç±»æ ‡è®°
        content_type = 'reasoning'
        if context_info.get('is_final_answer', False):
            content_type = 'answer'
        elif context_info.get('is_tool_call', False):
            content_type = 'tool'
        elif context_info.get('is_iteration_start', False):
            content_type = 'iteration'
        elif context_info.get('is_knowledge_query', False):
            content_type = 'knowledge'

        # è®¡ç®—ä»Žå¼€å§‹å¤„ç†åˆ°å½“å‰å›žè°ƒçš„è€—æ—¶
        current_duration = round(callback_time - start_time, 3)

        # èŽ·å–è¿­ä»£è®¡æ•°ä¿¡æ¯
        iteration_count = context_info.get('iteration_count', 0)

        # ä¸ºä¸åŒç±»åž‹çš„å†…å®¹æ·»åŠ é€‚å½“çš„æ ‡è®°ï¼Œé¿å…é‡å¤ä¿¡æ¯
        if content_type == 'iteration':
            # è¿­ä»£å¼€å§‹ä¿¡æ¯
            enhanced_content = f"ðŸ”„ ç¬¬{iteration_count}æ¬¡è¿­ä»£å¼€å§‹\n"
        elif content_type == 'tool':
            # å·¥å…·æ‰§è¡Œä¿¡æ¯ - åªæ·»åŠ çŠ¶æ€æ ‡è®°ï¼Œä¸é‡å¤æ·»åŠ è€—æ—¶ä¿¡æ¯
            tool_status = context_info.get('tool_status', '')
            if tool_status == 'start':
                enhanced_content = f"ðŸ”§ å¼€å§‹æ‰§è¡Œå·¥å…·\n{content}"
            elif tool_status == 'completed':
                enhanced_content = f"âœ… å·¥å…·æ‰§è¡Œå®Œæˆ\n{content}"
            elif tool_status == 'error':
                enhanced_content = f"âŒ å·¥å…·æ‰§è¡Œå¤±è´¥\n{content}"
            else:
                enhanced_content = f"ðŸ”§ å·¥å…·æ‰§è¡Œ\n{content}"
        elif content_type == 'knowledge':
            # çŸ¥è¯†åº“æŸ¥è¯¢ä¿¡æ¯
            knowledge_status = context_info.get('knowledge_status', '')
            if knowledge_status == 'start':
                enhanced_content = f"ðŸ“š {content}"
            elif knowledge_status == 'searching':
                enhanced_content = f"ðŸ” {content}"
            elif knowledge_status == 'success':
                knowledge_count = context_info.get('knowledge_count', 0)
                enhanced_content = f"âœ… {content}"
            elif knowledge_status == 'no_results':
                enhanced_content = f"ðŸ“­ {content}"
            elif knowledge_status == 'error':
                enhanced_content = f"âŒ {content}"
            elif knowledge_status == 'skipped':
                enhanced_content = f"âš ï¸ {content}"
            else:
                enhanced_content = f"ðŸ“š {content}"
        else:
            # å…¶ä»–ç±»åž‹å†…å®¹ - ç›´æŽ¥ä½¿ç”¨åŽŸå§‹å†…å®¹ï¼Œä¸æ·»åŠ é¢å¤–ä¿¡æ¯
            enhanced_content = content

        # å‘é€å¸¦ç±»åž‹æ ‡è®°å’Œè€—æ—¶ç»Ÿè®¡çš„å†…å®¹
        message_data = {
            'type': 'stream_chunk',
            'content_type': content_type,
            'content': enhanced_content,
            'is_reasoning': context_info.get('is_reasoning', False),
            'is_tool_call': content_type == 'tool' or context_info.get('is_tool_call', False),
            'is_final_answer': context_info.get('is_final_answer', False),
            'is_iteration_start': context_info.get('is_iteration_start', False),
            'timestamp': callback_time,
            'duration_from_start': current_duration,
            'iteration_count': iteration_count,
        }

        # å¦‚æžœæ˜¯å·¥å…·è°ƒç”¨ï¼Œæ·»åŠ å·¥å…·åç§°å’ŒçŠ¶æ€ä¿¡æ¯
        if content_type == 'tool':
            message_data['tool_name'] = context_info.get('tool_name', '')
            message_data['tool_status'] = context_info.get('tool_status', '')
            message_data['tool_duration'] = context_info.get('tool_duration', 0)
            message_data['tool_result'] = context_info.get('tool_result', '')
            message_data['tool_error'] = context_info.get('tool_error', '')
            message_data['tool_args'] = context_info.get('tool_args')

        # å¦‚æžœæ˜¯çŸ¥è¯†åº“æŸ¥è¯¢ï¼Œæ·»åŠ çŸ¥è¯†åº“ç›¸å…³ä¿¡æ¯
        if content_type == 'knowledge':
            message_data['knowledge_status'] = context_info.get('knowledge_status', '')
            message_data['knowledge_domain'] = context_info.get('knowledge_domain', '')
            message_data['knowledge_query'] = context_info.get('knowledge_query', '')
            message_data['knowledge_count'] = context_info.get('knowledge_count', 0)
            message_data['knowledge_result'] = context_info.get('knowledge_result', '')

        await websocket.send_text(json.dumps(message_data, ensure_ascii=False))

    # ä¸ºagent_loopè®¾ç½®æµå¼å›žè°ƒ
    agent_loop.stream_callback = stream_callback

    # Process with streaming output
    response = await agent_loop.process_direct(user_input, session_key="cli:webui")

    # Record LLM end time
    llm_end_time = time.time()
    llm_execution_time = round(llm_end_time - llm_start_time, 1)

    # Send the actual response (å¦‚æžœæµå¼è¾“å‡ºå·²ç»å‘é€äº†å†…å®¹ï¼Œè¿™é‡Œå¯èƒ½ä¸éœ€è¦å†å‘é€)
    if response and response.strip():
        # æ£€æŸ¥æ˜¯å¦å·²ç»é€šè¿‡æµå¼è¾“å‡ºå‘é€äº†å†…å®¹
        # å¦‚æžœæ²¡æœ‰æµå¼è¾“å‡ºï¼Œåˆ™å‘é€å®Œæ•´å“åº”
        await websocket.send_text("\n" + response)
    elif not response:
        await websocket.send_text("No response from agent.")

    end_time = time.time()
    total_processing_time = round(end_time - start_time, 1)

    # Send processing times
    await websocket.send_text(f"\n---\n*æ€»è€—æ—¶: {total_processing_time}ç§’ | LLMæ‰§è¡Œè€—æ—¶: {llm_execution_time}ç§’*")


async def process_user_message(user_input: str) -> str:
    """Process user message using nanobot's AgentLoop."""
    import time

    start_time = time.time()

    # Check if provider and agent_loop are initialized
    if not provider or not agent_loop:
        return "Error: Web UI resources not initialized. Please restart the server."

    # Record LLM start time
    llm_start_time = time.time()

    response = await agent_loop.process_direct(user_input, session_key="cli:webui")

    # Record LLM end time
    llm_end_time = time.time()
    llm_execution_time = round(llm_end_time - llm_start_time, 1)

    end_time = time.time()
    total_processing_time = round(end_time - start_time, 1)

    if response:
        return f"{response}\n\n---\n*æ€»è€—æ—¶: {total_processing_time}ç§’ | LLMæ‰§è¡Œè€—æ—¶: {llm_execution_time}ç§’*"
    else:
        return f"No response from agent.\n\n---\n*æ€»è€—æ—¶: {total_processing_time}ç§’ | LLMæ‰§è¡Œè€—æ—¶: {llm_execution_time}ç§’*"


if __name__ == "__main__":
    webui()
