"""Knowledge base storage system for domain-specific knowledge."""

import json
import logging
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Any, Union
from dataclasses import dataclass, asdict

import chromadb
from chromadb.config import Settings
from loguru import logger

from nanobot.utils.helpers import ensure_dir
from .rag_config import RAGConfig
from .vector_embedder import VectorEmbedder, EmbeddingModelError
from .text_chunker import TextChunker



class RAGKnowledgeError(Exception):
    """RAG çŸ¥è¯†åº“ç³»ç»ŸåŸºç¡€å¼‚å¸¸."""
    pass


class ChromaConnectionError(RAGKnowledgeError):
    """Chroma è¿æ¥é”™è¯¯."""
    
    def __init__(self, message: str):
        super().__init__(
            f"Chroma æ•°æ®åº“è¿æ¥å¤±è´¥: {message}\n"
            f"è¯·æ£€æŸ¥:\n"
            f"1. Chroma æœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œ\n"
            f"2. æ•°æ®åº“è·¯å¾„æ˜¯å¦æœ‰è¯»å†™æƒé™\n"
            f"3. ç£ç›˜ç©ºé—´æ˜¯å¦å……è¶³"
        )


@dataclass
class KnowledgeItem:
    """Knowledge item data structure."""
    id: str
    domain: str  # e.g., "rocketmq", "kubernetes", "github"
    category: str  # e.g., "troubleshooting", "configuration", "best_practices"
    title: str
    content: str
    tags: List[str]
    created_at: str
    updated_at: str
    source: str = "user"  # "user" or "system"
    priority: int = 1  # 1-5, higher is more important
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for JSON serialization."""
        return asdict(self)
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "KnowledgeItem":
        """Create from dictionary."""
        return cls(**data)


class LegacyKnowledgeStore:
    """Knowledge base storage system."""
    
    def __init__(self, workspace: Path):
        self.workspace = workspace
        self.knowledge_dir = ensure_dir(workspace / "knowledge")
        self.index_file = self.knowledge_dir / "index.json"
        self.init_status_file = self.knowledge_dir / "init_status.json"
        self._index: Dict[str, KnowledgeItem] = {}
        self._init_status: Dict[str, Any] = {}
        self._load_index()
        self._load_init_status()
        
        # Auto-initialize built-in knowledge with smart detection
        self._auto_initialize_builtin_knowledge()
    
    def _load_index(self) -> None:
        """Load knowledge index from file."""
        if self.index_file.exists():
            try:
                with open(self.index_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self._index = {k: KnowledgeItem.from_dict(v) for k, v in data.items()}
            except (json.JSONDecodeError, KeyError):
                self._index = {}
    
    def _load_init_status(self) -> None:
        """Load initialization status from file."""
        if self.init_status_file.exists():
            try:
                with open(self.init_status_file, 'r', encoding='utf-8') as f:
                    self._init_status = json.load(f)
            except (json.JSONDecodeError, KeyError):
                self._init_status = {}
        else:
            self._init_status = {}
    
    def _save_init_status(self) -> None:
        """Save initialization status to file."""
        with open(self.init_status_file, 'w', encoding='utf-8') as f:
            json.dump(self._init_status, f, indent=2, ensure_ascii=False)
    
    def _save_index(self) -> None:
        """Save knowledge index to file."""
        data = {k: v.to_dict() for k, v in self._index.items()}
        with open(self.index_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
    
    def add_knowledge(self, domain: str, category: str, title: str, content: str, 
                     tags: List[str] = None, source: str = "user", priority: int = 1) -> str:
        """Add a new knowledge item."""
        if tags is None:
            tags = []
        
        # Generate unique ID
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
        item_id = f"{domain}_{timestamp}"
        
        # Create knowledge item
        knowledge_item = KnowledgeItem(
            id=item_id,
            domain=domain,
            category=category,
            title=title,
            content=content,
            tags=tags,
            created_at=datetime.now().isoformat(),
            updated_at=datetime.now().isoformat(),
            source=source,
            priority=priority
        )
        
        # Save to index
        self._index[item_id] = knowledge_item
        self._save_index()
        
        return item_id
    
    def get_knowledge(self, item_id: str) -> Optional[KnowledgeItem]:
        """Get a knowledge item by ID."""
        return self._index.get(item_id)
    
    def update_knowledge(self, item_id: str, **kwargs) -> bool:
        """Update a knowledge item."""
        if item_id not in self._index:
            return False
        
        item = self._index[item_id]
        
        # Update allowed fields
        allowed_fields = ['title', 'content', 'tags', 'category', 'priority']
        for key, value in kwargs.items():
            if key in allowed_fields and hasattr(item, key):
                setattr(item, key, value)
        
        item.updated_at = datetime.now().isoformat()
        self._save_index()
        
        return True
    
    def delete_knowledge(self, item_id: str) -> bool:
        """Delete a knowledge item."""
        if item_id not in self._index:
            return False
        
        del self._index[item_id]
        self._save_index()
        return True
    
    def search_knowledge(self, query: str = None, domain: str = None, 
                        category: str = None, tags: List[str] = None) -> List[KnowledgeItem]:
        """Search knowledge items."""
        results = list(self._index.values())
        
        # Filter by domain
        if domain:
            results = [item for item in results if item.domain == domain]
        
        # Filter by category
        if category:
            results = [item for item in results if item.category == category]
        
        # Filter by tags
        if tags:
            results = [item for item in results if any(tag in item.tags for tag in tags)]
        
        # Filter by query (simple text search)
        if query:
            query_lower = query.lower()
            results = [item for item in results 
                      if query_lower in item.title.lower() or query_lower in item.content.lower()]
        
        # Sort by priority and recency
        results.sort(key=lambda x: (-x.priority, x.created_at), reverse=True)
        
        return results
    
    def get_domains(self) -> List[str]:
        """Get list of all domains."""
        domains = set(item.domain for item in self._index.values())
        return sorted(domains)
    
    def get_categories(self, domain: str = None) -> List[str]:
        """Get list of categories for a domain."""
        items = self._index.values()
        if domain:
            items = [item for item in items if item.domain == domain]
        
        categories = set(item.category for item in items)
        return sorted(categories)
    
    def get_tags(self, domain: str = None) -> List[str]:
        """Get list of all tags."""
        items = self._index.values()
        if domain:
            items = [item for item in items if item.domain == domain]
        
        tags = set()
        for item in items:
            tags.update(item.tags)
        
        return sorted(tags)
    
    def export_knowledge(self, domain: str = None) -> Dict[str, Any]:
        """Export knowledge as JSON."""
        items = self._index.values()
        if domain:
            items = [item for item in items if item.domain == domain]
        
        return {
            "exported_at": datetime.now().isoformat(),
            "knowledge_items": [item.to_dict() for item in items]
        }
    
    def import_knowledge(self, data: Dict[str, Any]) -> int:
        """Import knowledge from JSON."""
        if "knowledge_items" not in data:
            return 0
        
        imported_count = 0
        for item_data in data["knowledge_items"]:
            try:
                item = KnowledgeItem.from_dict(item_data)
                self._index[item.id] = item
                imported_count += 1
            except (KeyError, TypeError):
                continue
        
        if imported_count > 0:
            self._save_index()
        
        return imported_count
    
    def _auto_initialize_builtin_knowledge(self) -> None:
        """Auto-initialize built-in knowledge with smart detection."""
        # Check if RocketMQ knowledge needs initialization
        self._initialize_rocketmq_knowledge()
    
    def _initialize_rocketmq_knowledge(self) -> None:
        """Initialize RocketMQ knowledge with version control and content validation."""
        try:
            from .rocketmq_init import RocketMQKnowledgeInitializer, ROCKETMQ_KNOWLEDGE_VERSION
            
            # Check if RocketMQ knowledge is already initialized
            rocketmq_status = self._init_status.get("rocketmq", {})
            current_version = rocketmq_status.get("version")
            
            # Check if we need to reinitialize (version mismatch or content changed)
            needs_reinit = self._should_reinitialize_rocketmq(current_version, ROCKETMQ_KNOWLEDGE_VERSION)
            
            if needs_reinit:
                # Initialize RocketMQ knowledge
                initializer = RocketMQKnowledgeInitializer(self)
                count = initializer.initialize()
                
                # Update initialization status
                self._init_status["rocketmq"] = {
                    "version": ROCKETMQ_KNOWLEDGE_VERSION,
                    "initialized_at": datetime.now().isoformat(),
                    "item_count": count,
                    "last_check": datetime.now().isoformat()
                }
                self._save_init_status()
                
                print(f"âœ“ Initialized {count} RocketMQ knowledge items (v{ROCKETMQ_KNOWLEDGE_VERSION})")
            else:
                # Already up to date
                self._init_status["rocketmq"]["last_check"] = datetime.now().isoformat()
                self._save_init_status()
                
        except ImportError:
            # RocketMQ knowledge module not available
            pass
        except Exception as e:
            print(f"âš  Failed to initialize RocketMQ knowledge: {e}")
    
    def _should_reinitialize_rocketmq(self, current_version: str, new_version: str) -> bool:
        """Determine if RocketMQ knowledge should be reinitialized."""
        # If never initialized, need to initialize
        if not current_version:
            return True
        
        # If version changed, need to reinitialize
        if current_version != new_version:
            return True
        
        # Check if any RocketMQ knowledge items exist
        rocketmq_items = self.search_knowledge(domain="rocketmq")
        if not rocketmq_items:
            return True
        
        # For now, we'll assume content is stable unless version changes
        # In production, you'd implement file change detection here
        return False


class ChromaKnowledgeStore:
    """åŸºäº Chroma çš„çŸ¥è¯†åº“å­˜å‚¨ç³»ç»Ÿ."""
    
    def __init__(self, workspace: Path, config: Optional[RAGConfig] = None):
        """åˆå§‹åŒ–çŸ¥è¯†åº“.
        
        Args:
            workspace: å·¥ä½œç©ºé—´è·¯å¾„
            config: RAG é…ç½®
            
        Raises:
            ChromaConnectionError: Chroma æ•°æ®åº“è¿æ¥å¤±è´¥æ—¶æŠ›å‡º
            EmbeddingModelError: Embedding æ¨¡å‹åŠ è½½å¤±è´¥æ—¶æŠ›å‡º
        """
        self.workspace = workspace
        self.config = config or RAGConfig()
        self.knowledge_dir = ensure_dir(workspace / "knowledge")
        self.chroma_dir = ensure_dir(self.knowledge_dir / "chroma_db")
        self.init_status_file = self.knowledge_dir / "init_status.json"
        
        # åˆå§‹åŒ–ç»„ä»¶
        logger.info("åˆå§‹åŒ– RAG çŸ¥è¯†åº“ç»„ä»¶")
        self.embedder = VectorEmbedder(self.config.embedding_model)
        self.chunker = TextChunker(
            chunk_size=self.config.chunk_size,
            chunk_overlap=self.config.chunk_overlap
        )
        self.chroma_client = None
        self._init_chroma()
        self._init_status: Dict[str, Any] = {}
        self._load_init_status()
        
        # è‡ªåŠ¨åˆå§‹åŒ–å†…ç½®çŸ¥è¯†
        self._auto_initialize_builtin_knowledge()
    
    def _init_chroma(self) -> None:
        """åˆå§‹åŒ– Chroma å®¢æˆ·ç«¯.
        
        Raises:
            ChromaConnectionError: Chroma æ•°æ®åº“è¿æ¥å¤±è´¥æ—¶æŠ›å‡º
        """
        try:
            logger.info(f"åˆå§‹åŒ– Chroma æŒä¹…åŒ–å®¢æˆ·ç«¯: {self.chroma_dir}")
            self.chroma_client = chromadb.PersistentClient(
                path=str(self.chroma_dir),
                settings=Settings(
                    anonymized_telemetry=False,
                    allow_reset=True
                )
            )
            logger.info("Chroma å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"Chroma å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {str(e)}", exc_info=True)
            raise ChromaConnectionError(str(e))
    
    def _get_or_create_collection(self, domain: str):
        """è·å–æˆ–åˆ›å»º Chroma é›†åˆ.
        
        Args:
            domain: é¢†åŸŸåç§°
            
        Returns:
            Chroma é›†åˆå¯¹è±¡
            
        Raises:
            ChromaConnectionError: é›†åˆåˆ›å»ºå¤±è´¥æ—¶æŠ›å‡º
        """
        collection_name = f"knowledge_{domain}"
        
        try:
            # å°è¯•è·å–ç°æœ‰é›†åˆ
            collection = self.chroma_client.get_collection(name=collection_name)
            logger.debug(f"è·å–ç°æœ‰é›†åˆ: {collection_name}")
            return collection
        except Exception:
            # é›†åˆä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°é›†åˆ
            try:
                logger.info(f"åˆ›å»ºæ–°é›†åˆ: {collection_name}")
                collection = self.chroma_client.create_collection(
                    name=collection_name,
                    metadata={
                        "domain": domain,
                        "created_at": datetime.now().isoformat()
                    }
                )
                logger.info(f"é›†åˆåˆ›å»ºæˆåŠŸ: {collection_name}")
                return collection
            except Exception as e:
                logger.error(f"é›†åˆåˆ›å»ºå¤±è´¥: {collection_name}, é”™è¯¯: {str(e)}", exc_info=True)
                raise ChromaConnectionError(f"åˆ›å»ºé›†åˆå¤±è´¥: {str(e)}")
    
    def _load_init_status(self) -> None:
        """åŠ è½½åˆå§‹åŒ–çŠ¶æ€æ–‡ä»¶."""
        if self.init_status_file.exists():
            try:
                with open(self.init_status_file, 'r', encoding='utf-8') as f:
                    self._init_status = json.load(f)
                logger.info(f"åŠ è½½åˆå§‹åŒ–çŠ¶æ€: {len(self._init_status)} ä¸ªé¢†åŸŸ")
            except (json.JSONDecodeError, KeyError) as e:
                logger.warning(f"åˆå§‹åŒ–çŠ¶æ€æ–‡ä»¶åŠ è½½å¤±è´¥: {str(e)}")
                self._init_status = {}
        else:
            logger.info("åˆå§‹åŒ–çŠ¶æ€æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°çŠ¶æ€")
            self._init_status = {}
    
    def _save_init_status(self) -> None:
        """ä¿å­˜åˆå§‹åŒ–çŠ¶æ€åˆ°æ–‡ä»¶."""
        try:
            with open(self.init_status_file, 'w', encoding='utf-8') as f:
                json.dump(self._init_status, f, indent=2, ensure_ascii=False)
            logger.debug("åˆå§‹åŒ–çŠ¶æ€å·²ä¿å­˜")
        except Exception as e:
            logger.error(f"ä¿å­˜åˆå§‹åŒ–çŠ¶æ€å¤±è´¥: {str(e)}", exc_info=True)
    
    def _should_reinitialize(self, domain: str, new_version: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦é‡æ–°åˆå§‹åŒ–.
        
        Args:
            domain: é¢†åŸŸåç§°
            new_version: æ–°ç‰ˆæœ¬å·
            
        Returns:
            æ˜¯å¦éœ€è¦é‡æ–°åˆå§‹åŒ–
        """
        status = self._init_status.get(domain, {})
        current_version = status.get("version")
        
        # å¦‚æœä»æœªåˆå§‹åŒ–ï¼Œéœ€è¦åˆå§‹åŒ–
        if not current_version:
            logger.info(f"é¢†åŸŸ {domain} ä»æœªåˆå§‹åŒ–ï¼Œéœ€è¦åˆå§‹åŒ–")
            return True
        
        # å¦‚æœç‰ˆæœ¬å·å‘ç”Ÿå˜åŒ–ï¼Œéœ€è¦é‡æ–°åˆå§‹åŒ–
        if current_version != new_version:
            logger.info(
                f"é¢†åŸŸ {domain} ç‰ˆæœ¬å˜åŒ–: {current_version} -> {new_version}ï¼Œéœ€è¦é‡æ–°åˆå§‹åŒ–"
            )
            return True
        
        # æ£€æŸ¥é›†åˆæ˜¯å¦å­˜åœ¨ä¸”åŒ…å«æ•°æ®
        try:
            collection = self.chroma_client.get_collection(f"knowledge_{domain}")
            if collection.count() == 0:
                logger.info(f"é¢†åŸŸ {domain} é›†åˆä¸ºç©ºï¼Œéœ€è¦é‡æ–°åˆå§‹åŒ–")
                return True
        except Exception as e:
            logger.warning(f"é¢†åŸŸ {domain} é›†åˆä¸å­˜åœ¨æˆ–æ— æ³•è®¿é—®: {str(e)}ï¼Œéœ€è¦é‡æ–°åˆå§‹åŒ–")
            return True
        
        logger.info(f"é¢†åŸŸ {domain} å·²åˆå§‹åŒ–ä¸”ç‰ˆæœ¬æœªå˜åŒ–ï¼Œè·³è¿‡åˆå§‹åŒ–")
        return False
    
    def _auto_initialize_builtin_knowledge(self) -> None:
        """è‡ªåŠ¨åˆå§‹åŒ–å†…ç½®çŸ¥è¯†."""
        logger.info("å¼€å§‹è‡ªåŠ¨åˆå§‹åŒ–å†…ç½®çŸ¥è¯†")
        
        # åˆå§‹åŒ– RocketMQ çŸ¥è¯†
        self._initialize_rocketmq_knowledge()
        
        logger.info("å†…ç½®çŸ¥è¯†åˆå§‹åŒ–å®Œæˆ")
    
    def _initialize_rocketmq_knowledge(self) -> None:
        """åˆå§‹åŒ– RocketMQ çŸ¥è¯†ï¼Œæ”¯æŒç‰ˆæœ¬æ§åˆ¶å’Œå‘é‡åŒ–."""
        try:
            from .rocketmq_init import RocketMQKnowledgeInitializer, ROCKETMQ_KNOWLEDGE_VERSION
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°åˆå§‹åŒ–
            needs_reinit = self._should_reinitialize("rocketmq", ROCKETMQ_KNOWLEDGE_VERSION)
            
            if needs_reinit:
                import time
                start_time = time.time()
                
                logger.info(f"å¼€å§‹åˆå§‹åŒ– RocketMQ çŸ¥è¯†åº“ (v{ROCKETMQ_KNOWLEDGE_VERSION})")
                
                # å¦‚æœéœ€è¦é‡æ–°åˆå§‹åŒ–ï¼Œå…ˆæ¸…ç©ºç°æœ‰é›†åˆ
                try:
                    self.chroma_client.delete_collection(f"knowledge_rocketmq")
                    logger.info("å·²åˆ é™¤æ—§çš„ RocketMQ é›†åˆ")
                except Exception:
                    pass  # é›†åˆä¸å­˜åœ¨ï¼Œå¿½ç•¥
                
                # åˆå§‹åŒ– RocketMQ çŸ¥è¯†
                initializer = RocketMQKnowledgeInitializer(self)
                item_count, chunk_count = initializer.initialize()
                
                elapsed = time.time() - start_time
                
                # æ›´æ–°åˆå§‹åŒ–çŠ¶æ€
                self._init_status["rocketmq"] = {
                    "version": ROCKETMQ_KNOWLEDGE_VERSION,
                    "initialized_at": datetime.now().isoformat(),
                    "item_count": item_count,
                    "chunk_count": chunk_count,
                    "last_check": datetime.now().isoformat(),
                    "elapsed_seconds": round(elapsed, 2)
                }
                self._save_init_status()
                
                logger.info(
                    f"âœ“ åˆå§‹åŒ– {item_count} ä¸ª RocketMQ çŸ¥è¯†æ¡ç›®ï¼Œ"
                    f"{chunk_count} ä¸ªæ–‡æœ¬å— (v{ROCKETMQ_KNOWLEDGE_VERSION})ï¼Œ"
                    f"è€—æ—¶ {elapsed:.2f} ç§’"
                )
                print(
                    f"âœ“ åˆå§‹åŒ– {item_count} ä¸ª RocketMQ çŸ¥è¯†æ¡ç›®ï¼Œ"
                    f"{chunk_count} ä¸ªæ–‡æœ¬å— (v{ROCKETMQ_KNOWLEDGE_VERSION})ï¼Œ"
                    f"è€—æ—¶ {elapsed:.2f} ç§’"
                )
            else:
                # å·²ç»æ˜¯æœ€æ–°ç‰ˆæœ¬ï¼Œåªæ›´æ–°æ£€æŸ¥æ—¶é—´
                self._init_status["rocketmq"]["last_check"] = datetime.now().isoformat()
                self._save_init_status()
                logger.info(f"RocketMQ çŸ¥è¯†åº“å·²æ˜¯æœ€æ–°ç‰ˆæœ¬ (v{ROCKETMQ_KNOWLEDGE_VERSION})")
                
        except ImportError:
            logger.warning("RocketMQ çŸ¥è¯†æ¨¡å—ä¸å¯ç”¨")
        except Exception as e:
            logger.error(f"åˆå§‹åŒ– RocketMQ çŸ¥è¯†å¤±è´¥: {str(e)}", exc_info=True)
            print(f"âš  åˆå§‹åŒ– RocketMQ çŸ¥è¯†å¤±è´¥: {e}")
    
    def add_knowledge(
        self, 
        domain: str, 
        category: str, 
        title: str, 
        content: str,
        tags: List[str] = None, 
        source: str = "user", 
        priority: int = 1
    ) -> str:
        """æ·»åŠ çŸ¥è¯†æ¡ç›®.
        
        Args:
            domain: é¢†åŸŸ
            category: åˆ†ç±»
            title: æ ‡é¢˜
            content: å†…å®¹
            tags: æ ‡ç­¾åˆ—è¡¨
            source: æ¥æº
            priority: ä¼˜å…ˆçº§
            
        Returns:
            çŸ¥è¯†æ¡ç›® ID
        """
        # 1. åˆ›å»º KnowledgeItem
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S%f")
        item_id = f"{domain}_{timestamp}"
        
        if tags is None:
            tags = []
        
        # å‡†å¤‡å…ƒæ•°æ®
        metadata = {
            "item_id": item_id,
            "domain": domain,
            "category": category,
            "title": title,
            "tags": tags,
            "source": source,
            "priority": priority,
            "created_at": datetime.now().isoformat(),
            "updated_at": datetime.now().isoformat()
        }
        
        try:
            # 2. æ–‡æœ¬åˆ†å—
            chunks = self.chunker.chunk_text(content, metadata)
            
            if not chunks:
                logger.warning(f"çŸ¥è¯†æ¡ç›® {item_id} åˆ†å—åä¸ºç©ºï¼Œè·³è¿‡")
                return item_id
            
            # 3. æ‰¹é‡å‘é‡åŒ–
            chunk_texts = [chunk["text"] for chunk in chunks]
            try:
                embeddings = self.embedder.embed_batch(chunk_texts)
            except Exception as e:
                logger.error(f"çŸ¥è¯†æ¡ç›® {item_id} å‘é‡åŒ–å¤±è´¥: {str(e)}")
                raise
            
            # 4. å­˜å‚¨åˆ° Chroma é›†åˆ
            collection = self._get_or_create_collection(domain)
            
            # å‡†å¤‡æ‰¹é‡æ’å…¥çš„æ•°æ®
            ids = []
            documents = []
            metadatas = []
            embeddings_list = []
            
            for i, (chunk, embedding) in enumerate(zip(chunks, embeddings)):
                chunk_id = f"{item_id}_chunk_{i}"
                ids.append(chunk_id)
                documents.append(chunk["text"])
                metadatas.append(chunk["metadata"])
                embeddings_list.append(embedding)
            
            # æ‰¹é‡æ’å…¥åˆ° Chroma
            collection.add(
                ids=ids,
                documents=documents,
                metadatas=metadatas,
                embeddings=embeddings_list
            )
            
            logger.info(
                f"çŸ¥è¯†æ¡ç›® {item_id} å·²æ·»åŠ : {len(chunks)} ä¸ªåˆ†å—"
            )
            
            return item_id
            
        except Exception as e:
            logger.error(
                f"æ·»åŠ çŸ¥è¯†æ¡ç›® {item_id} å¤±è´¥: {str(e)}",
                exc_info=True
            )
            raise
    
    def search_knowledge(
        self, 
        query: str = None, 
        domain: str = None,
        category: str = None, 
        tags: List[str] = None,
        top_k: int = None
    ) -> List[KnowledgeItem]:
        """æœç´¢çŸ¥è¯†æ¡ç›®.

        Args:
            query: æŸ¥è¯¢æ–‡æœ¬ï¼ˆç”¨äºè¯­ä¹‰æ£€ç´¢ï¼Œå¯é€‰ï¼‰
            domain: é¢†åŸŸè¿‡æ»¤
            category: åˆ†ç±»è¿‡æ»¤
            tags: æ ‡ç­¾è¿‡æ»¤
            top_k: è¿”å›ç»“æœæ•°é‡

        Returns:
            çŸ¥è¯†æ¡ç›®åˆ—è¡¨ï¼ŒæŒ‰ç›¸ä¼¼åº¦åˆ†æ•°é™åºæ’åˆ—ï¼ˆè¯­ä¹‰æ£€ç´¢ï¼‰æˆ–æŒ‰åˆ›å»ºæ—¶é—´æ’åºï¼ˆå…ƒæ•°æ®è¿‡æ»¤ï¼‰
        """
        # ä½¿ç”¨é…ç½®çš„é»˜è®¤å€¼æˆ–å‚æ•°æŒ‡å®šçš„å€¼
        if top_k is None:
            top_k = self.config.top_k

        # å¦‚æœæ²¡æœ‰æä¾› queryï¼Œä½¿ç”¨åŸºäºå…ƒæ•°æ®çš„è¿‡æ»¤æ£€ç´¢ï¼ˆéœ€æ±‚ 6.5ï¼‰
        if not query:
            logger.info(f"[KNOWLEDGE_STORE] ğŸ” æ‰§è¡Œå…ƒæ•°æ®è¿‡æ»¤æ£€ç´¢: domain={domain}, category={category}, tags={tags}, top_k={top_k}")
            return self._search_by_metadata(domain, category, tags, top_k)

        # æœ‰ query å‚æ•°æ—¶ï¼Œä½¿ç”¨ RAG è¯­ä¹‰æ£€ç´¢ï¼ˆéœ€æ±‚ 6.4ï¼‰
        logger.info(f"[KNOWLEDGE_STORE] ğŸ” å¼€å§‹è¯­ä¹‰æ£€ç´¢:")
        logger.info(f"[KNOWLEDGE_STORE]   - Query: '{query}'")
        logger.info(f"[KNOWLEDGE_STORE]   - Domain: {domain}")
        logger.info(f"[KNOWLEDGE_STORE]   - Category: {category}")
        logger.info(f"[KNOWLEDGE_STORE]   - Tags: {tags}")
        logger.info(f"[KNOWLEDGE_STORE]   - Top K: {top_k}")

        try:
            # 1. å‘é‡åŒ–æŸ¥è¯¢æ–‡æœ¬
            start_time = datetime.now()
            logger.info(f"[KNOWLEDGE_STORE] ğŸ§® å¼€å§‹å‘é‡åŒ–æŸ¥è¯¢æ–‡æœ¬...")
            query_vector = self.embedder.embed_text(query)
            vectorize_time = (datetime.now() - start_time).total_seconds()
            logger.info(f"[KNOWLEDGE_STORE] âœ… æŸ¥è¯¢å‘é‡åŒ–å®Œæˆï¼Œè€—æ—¶: {vectorize_time:.3f}ç§’ï¼Œå‘é‡ç»´åº¦: {len(query_vector)}")

            # 2. æ„å»ºå…ƒæ•°æ®è¿‡æ»¤æ¡ä»¶
            where_filter = {}
            if category:
                where_filter["category"] = category
            if tags:
                # Chroma æ”¯æŒ $in æ“ä½œç¬¦è¿›è¡Œæ ‡ç­¾è¿‡æ»¤
                # ä½†ç”±äº tags å­˜å‚¨ä¸ºå­—ç¬¦ä¸²åˆ—è¡¨ï¼Œæˆ‘ä»¬éœ€è¦æ£€æŸ¥æ˜¯å¦æœ‰ä»»ä½•æ ‡ç­¾åŒ¹é…
                where_filter["tags"] = {"$in": tags}

            # 3. ç¡®å®šè¦æœç´¢çš„é›†åˆ
            collections_to_search = []
            if domain:
                # åªæœç´¢æŒ‡å®šé¢†åŸŸ
                try:
                    collection = self._get_or_create_collection(domain)
                    collections_to_search.append((domain, collection))
                except Exception as e:
                    logger.warning(f"è·å–é¢†åŸŸ '{domain}' çš„é›†åˆå¤±è´¥: {str(e)}")
            else:
                # æœç´¢æ‰€æœ‰é¢†åŸŸ
                try:
                    all_collections = self.chroma_client.list_collections()
                    for coll_info in all_collections:
                        coll_name = coll_info.name
                        if coll_name.startswith("knowledge_"):
                            domain_name = coll_name.replace("knowledge_", "")
                            try:
                                collection = self.chroma_client.get_collection(coll_name)
                                collections_to_search.append((domain_name, collection))
                            except Exception as e:
                                logger.warning(f"è·å–é›†åˆ '{coll_name}' å¤±è´¥: {str(e)}")
                except Exception as e:
                    logger.error(f"åˆ—å‡ºé›†åˆå¤±è´¥: {str(e)}")
                    return []

            if not collections_to_search:
                logger.warning("[KNOWLEDGE_STORE] âš ï¸  æ²¡æœ‰å¯æœç´¢çš„é›†åˆ")
                return []

            logger.info(f"[KNOWLEDGE_STORE] ğŸ“š å°†åœ¨ {len(collections_to_search)} ä¸ªé›†åˆä¸­æœç´¢")
            
            # 4. åœ¨æ‰€æœ‰ç›¸å…³é›†åˆä¸­æ‰§è¡Œç›¸ä¼¼åº¦æœç´¢
            all_results = []
            search_start = datetime.now()

            for domain_name, collection in collections_to_search:
                try:
                    # æ‰§è¡Œ Chroma æŸ¥è¯¢
                    results = collection.query(
                        query_embeddings=[query_vector],
                        n_results=top_k,
                        where=where_filter if where_filter else None,
                        include=["documents", "metadatas", "distances"]
                    )

                    # å¤„ç†æŸ¥è¯¢ç»“æœ
                    if results and results["ids"] and len(results["ids"][0]) > 0:
                        for i in range(len(results["ids"][0])):
                            chunk_id = results["ids"][0][i]
                            document = results["documents"][0][i]
                            metadata = results["metadatas"][0][i]
                            distance = results["distances"][0][i]

                            # å°†è·ç¦»è½¬æ¢ä¸ºç›¸ä¼¼åº¦åˆ†æ•° (è·ç¦»è¶Šå°ï¼Œç›¸ä¼¼åº¦è¶Šé«˜)
                            # Chroma ä½¿ç”¨ L2 è·ç¦»ï¼Œæˆ‘ä»¬å°†å…¶è½¬æ¢ä¸º 0-1 çš„ç›¸ä¼¼åº¦åˆ†æ•°
                            # similarity = 1 / (1 + distance)
                            similarity_score = 1.0 / (1.0 + distance)

                            # è¿‡æ»¤ä½äºé˜ˆå€¼çš„ç»“æœ
                            if similarity_score < self.config.similarity_threshold:
                                continue

                            all_results.append({
                                "chunk_id": chunk_id,
                                "document": document,
                                "metadata": metadata,
                                "similarity_score": similarity_score,
                                "domain": domain_name
                            })

                except Exception as e:
                    logger.warning(f"åœ¨é¢†åŸŸ '{domain_name}' ä¸­æœç´¢å¤±è´¥: {str(e)}")
                    continue

            search_time = (datetime.now() - search_start).total_seconds()
            logger.info(f"[KNOWLEDGE_STORE] ğŸ” ç›¸ä¼¼åº¦æœç´¢å®Œæˆï¼Œè€—æ—¶: {search_time:.3f}ç§’ï¼Œæ‰¾åˆ° {len(all_results)} ä¸ªåˆ†å—ç»“æœ")

            # 5. æŒ‰ç›¸ä¼¼åº¦åˆ†æ•°é™åºæ’åº
            all_results.sort(key=lambda x: x["similarity_score"], reverse=True)

            # 6. é™åˆ¶è¿”å›ç»“æœæ•°é‡
            all_results = all_results[:top_k]

            # 7. é‡æ„ä¸º KnowledgeItem å¯¹è±¡
            knowledge_items = []
            seen_item_ids = set()  # ç”¨äºå»é‡ï¼ˆåŒä¸€çŸ¥è¯†æ¡ç›®çš„ä¸åŒåˆ†å—ï¼‰

            for result in all_results:
                metadata = result["metadata"]
                item_id = metadata.get("item_id")

                # å¦‚æœå·²ç»æ·»åŠ è¿‡è¿™ä¸ªçŸ¥è¯†æ¡ç›®ï¼Œè·³è¿‡ï¼ˆé¿å…é‡å¤ï¼‰
                if item_id in seen_item_ids:
                    continue
                seen_item_ids.add(item_id)

                # åˆ›å»º KnowledgeItem
                try:
                    knowledge_item = KnowledgeItem(
                        id=item_id,
                        domain=metadata.get("domain", result["domain"]),
                        category=metadata.get("category", ""),
                        title=metadata.get("title", ""),
                        content=result["document"],  # ä½¿ç”¨åˆ†å—çš„å†…å®¹
                        tags=metadata.get("tags", []),
                        created_at=metadata.get("created_at", ""),
                        updated_at=metadata.get("updated_at", ""),
                        source=metadata.get("source", "user"),
                        priority=metadata.get("priority", 1)
                    )

                    # æ·»åŠ ç›¸ä¼¼åº¦åˆ†æ•°ï¼ˆä½œä¸ºé¢å¤–å±æ€§ï¼‰
                    # æ³¨æ„ï¼šKnowledgeItem æ˜¯ dataclassï¼Œæˆ‘ä»¬éœ€è¦åŠ¨æ€æ·»åŠ å±æ€§
                    knowledge_item_dict = knowledge_item.to_dict()
                    knowledge_item_dict["similarity_score"] = result["similarity_score"]
                    knowledge_item_dict["chunk_index"] = metadata.get("chunk_index", 0)

                    # é‡æ–°åˆ›å»ºå¸¦æœ‰é¢å¤–å­—æ®µçš„å¯¹è±¡
                    # ç”±äº KnowledgeItem ä¸æ”¯æŒé¢å¤–å­—æ®µï¼Œæˆ‘ä»¬ç›´æ¥è¿”å›åŸå¯¹è±¡
                    # å¹¶åœ¨æ—¥å¿—ä¸­è®°å½•ç›¸ä¼¼åº¦åˆ†æ•°
                    knowledge_items.append(knowledge_item)

                    logger.debug(
                        f"æ·»åŠ ç»“æœ: id={item_id}, title={metadata.get('title', '')[:30]}, "
                        f"similarity={result['similarity_score']:.4f}"
                    )

                except Exception as e:
                    logger.warning(f"é‡æ„ KnowledgeItem å¤±è´¥: {str(e)}")
                    continue

            total_time = (datetime.now() - start_time).total_seconds()
            logger.info(f"[KNOWLEDGE_STORE] âœ… è¯­ä¹‰æ£€ç´¢å®Œæˆ:")
            logger.info(f"[KNOWLEDGE_STORE]   - è¿”å›ç»“æœæ•°: {len(knowledge_items)}")
            logger.info(f"[KNOWLEDGE_STORE]   - æ€»è€—æ—¶: {total_time:.3f}ç§’")
            
            # è®°å½•å‰3ä¸ªç»“æœçš„æ ‡é¢˜å’Œç›¸ä¼¼åº¦
            for i, item in enumerate(knowledge_items[:3], 1):
                score = all_results[i-1]["similarity_score"] if i-1 < len(all_results) else 0
                logger.info(f"[KNOWLEDGE_STORE]   {i}. {item.title[:50]} (ç›¸ä¼¼åº¦: {score:.4f})")

            return knowledge_items

        except Exception as e:
            logger.error(f"è¯­ä¹‰æ£€ç´¢å¤±è´¥: {str(e)}", exc_info=True)
            return []

    def _search_by_metadata(
        self,
        domain: str = None,
        category: str = None,
        tags: List[str] = None,
        top_k: int = None
    ) -> List[KnowledgeItem]:
        """åŸºäºå…ƒæ•°æ®çš„è¿‡æ»¤æ£€ç´¢ï¼ˆä¸ä½¿ç”¨è¯­ä¹‰æœç´¢ï¼‰.
        
        å½“æ²¡æœ‰æä¾› query å‚æ•°æ—¶ä½¿ç”¨æ­¤æ–¹æ³•ï¼ˆéœ€æ±‚ 6.5ï¼‰ã€‚
        
        Args:
            domain: é¢†åŸŸè¿‡æ»¤
            category: åˆ†ç±»è¿‡æ»¤
            tags: æ ‡ç­¾è¿‡æ»¤
            top_k: è¿”å›ç»“æœæ•°é‡
            
        Returns:
            çŸ¥è¯†æ¡ç›®åˆ—è¡¨ï¼ŒæŒ‰åˆ›å»ºæ—¶é—´é™åºæ’åˆ—
        """
        try:
            # æ„å»ºå…ƒæ•°æ®è¿‡æ»¤æ¡ä»¶
            where_filter = {}
            if category:
                where_filter["category"] = category
            if tags:
                where_filter["tags"] = {"$in": tags}
            
            # ç¡®å®šè¦æœç´¢çš„é›†åˆ
            collections_to_search = []
            if domain:
                # åªæœç´¢æŒ‡å®šé¢†åŸŸ
                try:
                    collection = self._get_or_create_collection(domain)
                    collections_to_search.append((domain, collection))
                except Exception as e:
                    logger.warning(f"è·å–é¢†åŸŸ '{domain}' çš„é›†åˆå¤±è´¥: {str(e)}")
            else:
                # æœç´¢æ‰€æœ‰é¢†åŸŸ
                try:
                    all_collections = self.chroma_client.list_collections()
                    for coll_info in all_collections:
                        coll_name = coll_info.name
                        if coll_name.startswith("knowledge_"):
                            domain_name = coll_name.replace("knowledge_", "")
                            try:
                                collection = self.chroma_client.get_collection(coll_name)
                                collections_to_search.append((domain_name, collection))
                            except Exception as e:
                                logger.warning(f"è·å–é›†åˆ '{coll_name}' å¤±è´¥: {str(e)}")
                except Exception as e:
                    logger.error(f"åˆ—å‡ºé›†åˆå¤±è´¥: {str(e)}")
                    return []
            
            if not collections_to_search:
                logger.warning("æ²¡æœ‰å¯æœç´¢çš„é›†åˆ")
                return []
            
            # åœ¨æ‰€æœ‰ç›¸å…³é›†åˆä¸­æ‰§è¡Œå…ƒæ•°æ®è¿‡æ»¤
            all_results = []
            
            for domain_name, collection in collections_to_search:
                try:
                    # ä½¿ç”¨ Chroma çš„ get æ–¹æ³•è¿›è¡Œå…ƒæ•°æ®è¿‡æ»¤
                    results = collection.get(
                        where=where_filter if where_filter else None,
                        limit=top_k if top_k else 1000,  # è®¾ç½®ä¸€ä¸ªåˆç†çš„ä¸Šé™
                        include=["documents", "metadatas"]
                    )
                    
                    # å¤„ç†æŸ¥è¯¢ç»“æœ
                    if results and results["ids"]:
                        for i in range(len(results["ids"])):
                            chunk_id = results["ids"][i]
                            document = results["documents"][i]
                            metadata = results["metadatas"][i]
                            
                            all_results.append({
                                "chunk_id": chunk_id,
                                "document": document,
                                "metadata": metadata,
                                "domain": domain_name
                            })
                
                except Exception as e:
                    logger.warning(f"åœ¨é¢†åŸŸ '{domain_name}' ä¸­æœç´¢å¤±è´¥: {str(e)}")
                    continue
            
            logger.debug(f"å…ƒæ•°æ®è¿‡æ»¤å®Œæˆï¼Œæ‰¾åˆ° {len(all_results)} ä¸ªç»“æœ")
            
            # æŒ‰åˆ›å»ºæ—¶é—´é™åºæ’åº
            all_results.sort(
                key=lambda x: x["metadata"].get("created_at", ""),
                reverse=True
            )
            
            # é™åˆ¶è¿”å›ç»“æœæ•°é‡
            if top_k:
                all_results = all_results[:top_k]
            
            # é‡æ„ä¸º KnowledgeItem å¯¹è±¡
            knowledge_items = []
            seen_item_ids = set()  # ç”¨äºå»é‡ï¼ˆåŒä¸€çŸ¥è¯†æ¡ç›®çš„ä¸åŒåˆ†å—ï¼‰
            
            for result in all_results:
                metadata = result["metadata"]
                item_id = metadata.get("item_id")
                
                # å¦‚æœå·²ç»æ·»åŠ è¿‡è¿™ä¸ªçŸ¥è¯†æ¡ç›®ï¼Œè·³è¿‡ï¼ˆé¿å…é‡å¤ï¼‰
                if item_id in seen_item_ids:
                    continue
                seen_item_ids.add(item_id)
                
                # åˆ›å»º KnowledgeItem
                try:
                    knowledge_item = KnowledgeItem(
                        id=item_id,
                        domain=metadata.get("domain", result["domain"]),
                        category=metadata.get("category", ""),
                        title=metadata.get("title", ""),
                        content=result["document"],  # ä½¿ç”¨åˆ†å—çš„å†…å®¹
                        tags=metadata.get("tags", []),
                        created_at=metadata.get("created_at", ""),
                        updated_at=metadata.get("updated_at", ""),
                        source=metadata.get("source", "user"),
                        priority=metadata.get("priority", 1)
                    )
                    
                    knowledge_items.append(knowledge_item)
                    
                    logger.debug(
                        f"æ·»åŠ ç»“æœ: id={item_id}, title={metadata.get('title', '')[:30]}"
                    )
                
                except Exception as e:
                    logger.warning(f"é‡æ„ KnowledgeItem å¤±è´¥: {str(e)}")
                    continue
            
            logger.info(f"å…ƒæ•°æ®è¿‡æ»¤æ£€ç´¢å®Œæˆ: è¿”å› {len(knowledge_items)} ä¸ªç»“æœ")
            
            return knowledge_items
        
        except Exception as e:
            logger.error(f"å…ƒæ•°æ®è¿‡æ»¤æ£€ç´¢å¤±è´¥: {str(e)}", exc_info=True)
            return []
    
    def update_knowledge(self, item_id: str, **kwargs) -> bool:
        """æ›´æ–°çŸ¥è¯†æ¡ç›®.
        
        æ ¹æ®éœ€æ±‚ 5.2ï¼Œæ›´æ–°çŸ¥è¯†æ¡ç›®æ—¶éœ€è¦ï¼š
        1. åˆ é™¤æ—§çš„å‘é‡æ•°æ®
        2. æ›´æ–°å†…å®¹å¹¶é‡æ–°å‘é‡åŒ–
        3. å­˜å‚¨æ–°çš„å‘é‡æ•°æ®
        
        Args:
            item_id: çŸ¥è¯†æ¡ç›® ID
            **kwargs: è¦æ›´æ–°çš„å­—æ®µï¼ˆtitle, content, tags, category, priorityï¼‰
            
        Returns:
            æ˜¯å¦æ›´æ–°æˆåŠŸ
        """
        logger.info(f"å¼€å§‹æ›´æ–°çŸ¥è¯†æ¡ç›®: {item_id}")
        
        try:
            # 1. é¦–å…ˆæŸ¥æ‰¾è¯¥çŸ¥è¯†æ¡ç›®æ‰€å±çš„é¢†åŸŸ
            # é€šè¿‡éå†æ‰€æœ‰é›†åˆæŸ¥æ‰¾åŒ…å«è¯¥ item_id çš„é›†åˆ
            domain = None
            old_metadata = None
            
            try:
                all_collections = self.chroma_client.list_collections()
                for coll_info in all_collections:
                    coll_name = coll_info.name
                    if coll_name.startswith("knowledge_"):
                        try:
                            collection = self.chroma_client.get_collection(coll_name)
                            # æŸ¥è¯¢è¯¥é›†åˆä¸­æ˜¯å¦æœ‰è¯¥ item_id çš„åˆ†å—
                            results = collection.get(
                                where={"item_id": item_id},
                                limit=1
                            )
                            
                            if results and results["ids"] and len(results["ids"]) > 0:
                                domain = coll_name.replace("knowledge_", "")
                                old_metadata = results["metadatas"][0]
                                logger.info(f"æ‰¾åˆ°çŸ¥è¯†æ¡ç›® {item_id} åœ¨é¢†åŸŸ {domain}")
                                break
                        except Exception as e:
                            logger.warning(f"æŸ¥è¯¢é›†åˆ {coll_name} å¤±è´¥: {str(e)}")
                            continue
            except Exception as e:
                logger.error(f"åˆ—å‡ºé›†åˆå¤±è´¥: {str(e)}")
                return False
            
            if not domain or not old_metadata:
                logger.warning(f"çŸ¥è¯†æ¡ç›® {item_id} ä¸å­˜åœ¨")
                return False
            
            # 2. åˆ é™¤æ—§çš„å‘é‡æ•°æ®
            collection = self._get_or_create_collection(domain)
            
            # æŸ¥æ‰¾æ‰€æœ‰å±äºè¯¥ item_id çš„åˆ†å—
            old_chunks = collection.get(
                where={"item_id": item_id}
            )
            
            if old_chunks and old_chunks["ids"]:
                chunk_ids = old_chunks["ids"]
                collection.delete(ids=chunk_ids)
                logger.info(f"åˆ é™¤äº† {len(chunk_ids)} ä¸ªæ—§çš„å‘é‡åˆ†å—")
            else:
                logger.warning(f"æœªæ‰¾åˆ°çŸ¥è¯†æ¡ç›® {item_id} çš„æ—§å‘é‡æ•°æ®")
            
            # 3. å‡†å¤‡æ›´æ–°åçš„å…ƒæ•°æ®
            # åˆå¹¶æ—§å…ƒæ•°æ®å’Œæ–°çš„æ›´æ–°å­—æ®µ
            updated_metadata = old_metadata.copy()
            
            # å…è®¸æ›´æ–°çš„å­—æ®µ
            allowed_fields = ['title', 'content', 'tags', 'category', 'priority']
            for key, value in kwargs.items():
                if key in allowed_fields:
                    updated_metadata[key] = value
            
            # æ›´æ–°æ—¶é—´æˆ³
            updated_metadata["updated_at"] = datetime.now().isoformat()
            
            # 4. è·å–æ›´æ–°åçš„å†…å®¹ï¼ˆå¦‚æœæ²¡æœ‰æä¾›æ–°å†…å®¹ï¼Œä½¿ç”¨æ—§å†…å®¹ï¼‰
            # æ³¨æ„ï¼šæ—§çš„ content ä¸åœ¨ metadata ä¸­ï¼Œéœ€è¦ä» documents ä¸­è·å–
            if "content" in kwargs:
                new_content = kwargs["content"]
            else:
                # å¦‚æœæ²¡æœ‰æä¾›æ–°å†…å®¹ï¼Œä»æ—§åˆ†å—ä¸­é‡å»ºå†…å®¹
                if old_chunks and old_chunks["documents"]:
                    # å°†æ‰€æœ‰åˆ†å—çš„æ–‡æœ¬åˆå¹¶
                    new_content = " ".join(old_chunks["documents"])
                else:
                    logger.error(f"æ— æ³•è·å–çŸ¥è¯†æ¡ç›® {item_id} çš„å†…å®¹")
                    return False
            
            # 5. é‡æ–°åˆ†å—å’Œå‘é‡åŒ–
            # å‡†å¤‡ç”¨äºåˆ†å—çš„å…ƒæ•°æ®ï¼ˆä¸åŒ…å« chunk_index å’Œ total_chunksï¼‰
            chunk_metadata = {
                "item_id": item_id,
                "domain": updated_metadata.get("domain", domain),
                "category": updated_metadata.get("category", ""),
                "title": updated_metadata.get("title", ""),
                "tags": updated_metadata.get("tags", []),
                "source": updated_metadata.get("source", "user"),
                "priority": updated_metadata.get("priority", 1),
                "created_at": updated_metadata.get("created_at", ""),
                "updated_at": updated_metadata["updated_at"]
            }
            
            # æ–‡æœ¬åˆ†å—
            chunks = self.chunker.chunk_text(new_content, chunk_metadata)
            
            if not chunks:
                logger.warning(f"çŸ¥è¯†æ¡ç›® {item_id} æ›´æ–°ååˆ†å—ä¸ºç©º")
                return False
            
            # 6. æ‰¹é‡å‘é‡åŒ–
            chunk_texts = [chunk["text"] for chunk in chunks]
            try:
                embeddings = self.embedder.embed_batch(chunk_texts)
            except Exception as e:
                logger.error(f"çŸ¥è¯†æ¡ç›® {item_id} é‡æ–°å‘é‡åŒ–å¤±è´¥: {str(e)}")
                raise
            
            # 7. å­˜å‚¨æ–°çš„å‘é‡æ•°æ®
            # å‡†å¤‡æ‰¹é‡æ’å…¥çš„æ•°æ®
            ids = []
            documents = []
            metadatas = []
            embeddings_list = []
            
            for i, (chunk, embedding) in enumerate(zip(chunks, embeddings)):
                chunk_id = f"{item_id}_chunk_{i}"
                ids.append(chunk_id)
                documents.append(chunk["text"])
                metadatas.append(chunk["metadata"])
                embeddings_list.append(embedding)
            
            # æ‰¹é‡æ’å…¥åˆ° Chroma
            collection.add(
                ids=ids,
                documents=documents,
                metadatas=metadatas,
                embeddings=embeddings_list
            )
            
            logger.info(
                f"çŸ¥è¯†æ¡ç›® {item_id} æ›´æ–°æˆåŠŸ: {len(chunks)} ä¸ªæ–°åˆ†å—"
            )
            
            return True
            
        except Exception as e:
            logger.error(
                f"æ›´æ–°çŸ¥è¯†æ¡ç›® {item_id} å¤±è´¥: {str(e)}",
                exc_info=True
            )
            return False
    
    def delete_knowledge(self, item_id: str) -> bool:
        """åˆ é™¤çŸ¥è¯†æ¡ç›®.

        æ ¹æ®éœ€æ±‚ 5.3ï¼Œåˆ é™¤çŸ¥è¯†æ¡ç›®æ—¶éœ€è¦ï¼š
        ä» Chroma é›†åˆä¸­åˆ é™¤æ‰€æœ‰ç›¸å…³åˆ†å—

        Args:
            item_id: çŸ¥è¯†æ¡ç›® ID

        Returns:
            æ˜¯å¦åˆ é™¤æˆåŠŸ
        """
        logger.info(f"å¼€å§‹åˆ é™¤çŸ¥è¯†æ¡ç›®: {item_id}")

        try:
            # 1. æŸ¥æ‰¾è¯¥çŸ¥è¯†æ¡ç›®æ‰€å±çš„é¢†åŸŸ
            # é€šè¿‡éå†æ‰€æœ‰é›†åˆæŸ¥æ‰¾åŒ…å«è¯¥ item_id çš„é›†åˆ
            domain = None

            try:
                all_collections = self.chroma_client.list_collections()
                for coll_info in all_collections:
                    coll_name = coll_info.name
                    if coll_name.startswith("knowledge_"):
                        try:
                            collection = self.chroma_client.get_collection(coll_name)
                            # æŸ¥è¯¢è¯¥é›†åˆä¸­æ˜¯å¦æœ‰è¯¥ item_id çš„åˆ†å—
                            results = collection.get(
                                where={"item_id": item_id},
                                limit=1
                            )

                            if results and results["ids"] and len(results["ids"]) > 0:
                                domain = coll_name.replace("knowledge_", "")
                                logger.info(f"æ‰¾åˆ°çŸ¥è¯†æ¡ç›® {item_id} åœ¨é¢†åŸŸ {domain}")
                                break
                        except Exception as e:
                            logger.warning(f"æŸ¥è¯¢é›†åˆ {coll_name} å¤±è´¥: {str(e)}")
                            continue
            except Exception as e:
                logger.error(f"åˆ—å‡ºé›†åˆå¤±è´¥: {str(e)}")
                return False

            if not domain:
                logger.warning(f"çŸ¥è¯†æ¡ç›® {item_id} ä¸å­˜åœ¨")
                return False

            # 2. åˆ é™¤æ‰€æœ‰ç›¸å…³åˆ†å—
            collection = self._get_or_create_collection(domain)

            # æŸ¥æ‰¾æ‰€æœ‰å±äºè¯¥ item_id çš„åˆ†å—
            chunks = collection.get(
                where={"item_id": item_id}
            )

            if chunks and chunks["ids"]:
                chunk_ids = chunks["ids"]
                collection.delete(ids=chunk_ids)
                logger.info(f"æˆåŠŸåˆ é™¤çŸ¥è¯†æ¡ç›® {item_id} çš„ {len(chunk_ids)} ä¸ªåˆ†å—")
                return True
            else:
                logger.warning(f"æœªæ‰¾åˆ°çŸ¥è¯†æ¡ç›® {item_id} çš„åˆ†å—æ•°æ®")
                return False

        except Exception as e:
            logger.error(
                f"åˆ é™¤çŸ¥è¯†æ¡ç›® {item_id} å¤±è´¥: {str(e)}",
                exc_info=True
            )
            return False
    
    def get_domains(self) -> List[str]:
        """è·å–æ‰€æœ‰é¢†åŸŸåˆ—è¡¨.
        
        Returns:
            é¢†åŸŸåˆ—è¡¨
        """
        try:
            # è·å–æ‰€æœ‰é›†åˆ
            collections = self.chroma_client.list_collections()
            
            # ä»é›†åˆåç§°ä¸­æå–é¢†åŸŸåç§°
            # é›†åˆåç§°æ ¼å¼: knowledge_{domain}
            domains = []
            for collection in collections:
                if collection.name.startswith("knowledge_"):
                    domain = collection.name[len("knowledge_"):]
                    domains.append(domain)
            
            return sorted(domains)
        except Exception as e:
            logger.error(f"è·å–é¢†åŸŸåˆ—è¡¨å¤±è´¥: {str(e)}", exc_info=True)
            return []
    
    def get_categories(self, domain: str = None) -> List[str]:
        """è·å–åˆ†ç±»åˆ—è¡¨.
        
        Args:
            domain: é¢†åŸŸè¿‡æ»¤
            
        Returns:
            åˆ†ç±»åˆ—è¡¨
        """
        try:
            categories = set()
            
            if domain:
                # è·å–æŒ‡å®šé¢†åŸŸçš„åˆ†ç±»
                collection = self._get_or_create_collection(domain)
                results = collection.get()
                
                if results and results["metadatas"]:
                    for metadata in results["metadatas"]:
                        if "category" in metadata:
                            categories.add(metadata["category"])
            else:
                # è·å–æ‰€æœ‰é¢†åŸŸçš„åˆ†ç±»
                domains = self.get_domains()
                for d in domains:
                    collection = self._get_or_create_collection(d)
                    results = collection.get()
                    
                    if results and results["metadatas"]:
                        for metadata in results["metadatas"]:
                            if "category" in metadata:
                                categories.add(metadata["category"])
            
            return sorted(list(categories))
        except Exception as e:
            logger.error(f"è·å–åˆ†ç±»åˆ—è¡¨å¤±è´¥: {str(e)}", exc_info=True)
            return []
    
    def get_tags(self, domain: str = None) -> List[str]:
        """è·å–æ ‡ç­¾åˆ—è¡¨.
        
        Args:
            domain: é¢†åŸŸè¿‡æ»¤
            
        Returns:
            æ ‡ç­¾åˆ—è¡¨
        """
        try:
            tags = set()
            
            if domain:
                # è·å–æŒ‡å®šé¢†åŸŸçš„æ ‡ç­¾
                collection = self._get_or_create_collection(domain)
                results = collection.get()
                
                if results and results["metadatas"]:
                    for metadata in results["metadatas"]:
                        if "tags" in metadata and metadata["tags"]:
                            # tags å¯èƒ½æ˜¯åˆ—è¡¨
                            if isinstance(metadata["tags"], list):
                                tags.update(metadata["tags"])
                            else:
                                tags.add(metadata["tags"])
            else:
                # è·å–æ‰€æœ‰é¢†åŸŸçš„æ ‡ç­¾
                domains = self.get_domains()
                for d in domains:
                    collection = self._get_or_create_collection(d)
                    results = collection.get()
                    
                    if results and results["metadatas"]:
                        for metadata in results["metadatas"]:
                            if "tags" in metadata and metadata["tags"]:
                                # tags å¯èƒ½æ˜¯åˆ—è¡¨
                                if isinstance(metadata["tags"], list):
                                    tags.update(metadata["tags"])
                                else:
                                    tags.add(metadata["tags"])
            
            return sorted(list(tags))
        except Exception as e:
            logger.error(f"è·å–æ ‡ç­¾åˆ—è¡¨å¤±è´¥: {str(e)}", exc_info=True)
            return []


    def export_knowledge(self, domain: str = None) -> Dict[str, Any]:
        """å¯¼å‡ºçŸ¥è¯†ä¸º JSON æ ¼å¼.

        Args:
            domain: é¢†åŸŸè¿‡æ»¤ï¼ˆå¯é€‰ï¼‰

        Returns:
            åŒ…å«å¯¼å‡ºæ—¶é—´å’ŒçŸ¥è¯†æ¡ç›®åˆ—è¡¨çš„å­—å…¸
        """
        try:
            knowledge_items = []
            seen_item_ids = set()  # ç”¨äºå»é‡ï¼ˆåŒä¸€çŸ¥è¯†æ¡ç›®çš„ä¸åŒåˆ†å—ï¼‰

            # ç¡®å®šè¦å¯¼å‡ºçš„é¢†åŸŸ
            domains_to_export = [domain] if domain else self.get_domains()

            for d in domains_to_export:
                try:
                    collection = self._get_or_create_collection(d)
                    results = collection.get(
                        include=["documents", "metadatas"]
                    )

                    if results and results["ids"]:
                        # æŒ‰ item_id åˆ†ç»„ï¼Œåˆå¹¶åŒä¸€çŸ¥è¯†æ¡ç›®çš„æ‰€æœ‰åˆ†å—
                        item_chunks = {}
                        for i in range(len(results["ids"])):
                            metadata = results["metadatas"][i]
                            document = results["documents"][i]
                            item_id = metadata.get("item_id")

                            if not item_id:
                                continue

                            if item_id not in item_chunks:
                                item_chunks[item_id] = {
                                    "metadata": metadata,
                                    "chunks": []
                                }

                            # æ·»åŠ åˆ†å—å†…å®¹
                            chunk_index = metadata.get("chunk_index", 0)
                            item_chunks[item_id]["chunks"].append({
                                "index": chunk_index,
                                "text": document
                            })

                        # é‡æ„å®Œæ•´çš„çŸ¥è¯†æ¡ç›®
                        for item_id, data in item_chunks.items():
                            if item_id in seen_item_ids:
                                continue
                            seen_item_ids.add(item_id)

                            metadata = data["metadata"]

                            # æŒ‰ chunk_index æ’åºå¹¶åˆå¹¶å†…å®¹
                            sorted_chunks = sorted(data["chunks"], key=lambda x: x["index"])
                            full_content = " ".join(chunk["text"] for chunk in sorted_chunks)

                            # åˆ›å»º KnowledgeItem
                            knowledge_item = KnowledgeItem(
                                id=item_id,
                                domain=metadata.get("domain", d),
                                category=metadata.get("category", ""),
                                title=metadata.get("title", ""),
                                content=full_content,
                                tags=metadata.get("tags", []),
                                created_at=metadata.get("created_at", ""),
                                updated_at=metadata.get("updated_at", ""),
                                source=metadata.get("source", "user"),
                                priority=metadata.get("priority", 1)
                            )

                            knowledge_items.append(knowledge_item.to_dict())

                except Exception as e:
                    logger.warning(f"å¯¼å‡ºé¢†åŸŸ '{d}' çš„çŸ¥è¯†å¤±è´¥: {str(e)}")
                    continue

            logger.info(f"æˆåŠŸå¯¼å‡º {len(knowledge_items)} ä¸ªçŸ¥è¯†æ¡ç›®")

            return {
                "exported_at": datetime.now().isoformat(),
                "knowledge_items": knowledge_items
            }

        except Exception as e:
            logger.error(f"å¯¼å‡ºçŸ¥è¯†å¤±è´¥: {str(e)}", exc_info=True)
            return {
                "exported_at": datetime.now().isoformat(),
                "knowledge_items": []
            }



class DomainKnowledgeManager:
    """Specialized knowledge manager for specific domains."""
    
    def __init__(self, knowledge_store: Union[LegacyKnowledgeStore, "ChromaKnowledgeStore"], domain: str):
        self.store = knowledge_store
        self.domain = domain
    
    def add_troubleshooting_guide(self, title: str, content: str, tags: List[str] = None) -> str:
        """Add a troubleshooting guide for the domain."""
        if tags is None:
            tags = ["troubleshooting"]
        else:
            tags.append("troubleshooting")
        
        return self.store.add_knowledge(
            domain=self.domain,
            category="troubleshooting",
            title=title,
            content=content,
            tags=tags,
            priority=3
        )
    
    def add_configuration_guide(self, title: str, content: str, tags: List[str] = None) -> str:
        """Add a configuration guide for the domain."""
        if tags is None:
            tags = ["configuration"]
        else:
            tags.append("configuration")
        
        return self.store.add_knowledge(
            domain=self.domain,
            category="configuration",
            title=title,
            content=content,
            tags=tags,
            priority=2
        )
    
    def add_best_practice(self, title: str, content: str, tags: List[str] = None) -> str:
        """Add a best practice for the domain."""
        if tags is None:
            tags = ["best_practices"]
        else:
            tags.append("best_practices")
        
        return self.store.add_knowledge(
            domain=self.domain,
            category="best_practices",
            title=title,
            content=content,
            tags=tags,
            priority=4
        )
    
    def add_checker_info(self, checker_name: str, description: str, usage: str, 
                        admin_api: str = None, tags: List[str] = None) -> str:
        """Add checker information for the domain."""
        if tags is None:
            tags = ["checker", "diagnostic"]
        else:
            tags.extend(["checker", "diagnostic"])
        
        content = f"""## {checker_name}

**æè¿°**: {description}

**ä½¿ç”¨åœºæ™¯**: {usage}

"""
        
        if admin_api:
            content += f"**Admin API**: {admin_api}\n\n"
        
        return self.store.add_knowledge(
            domain=self.domain,
            category="diagnostic_tools",
            title=f"æ£€æŸ¥å™¨: {checker_name}",
            content=content,
            tags=tags,
            priority=3
        )
    
    def search_troubleshooting(self, query: str = None, tags: List[str] = None) -> List[KnowledgeItem]:
        """Search troubleshooting guides for the domain."""
        return self.store.search_knowledge(
            query=query,
            domain=self.domain,
            category="troubleshooting",
            tags=tags
        )
    
    def search_configuration(self, query: str = None, tags: List[str] = None) -> List[KnowledgeItem]:
        """Search configuration guides for the domain."""
        return self.store.search_knowledge(
            query=query,
            domain=self.domain,
            category="configuration",
            tags=tags
        )
    
    def search_checkers(self, query: str = None) -> List[KnowledgeItem]:
        """Search diagnostic checkers for the domain."""
        return self.store.search_knowledge(
            query=query,
            domain=self.domain,
            category="diagnostic_tools",
            tags=["checker"]
        )
    
    def get_all_checkers(self) -> List[KnowledgeItem]:
        """Get all diagnostic checkers for the domain."""
        return self.search_checkers()
    
    def get_common_issues(self) -> List[KnowledgeItem]:
        """Get common issues for the domain."""
        return self.store.search_knowledge(
            domain=self.domain,
            tags=["common", "issue"]
        )
    
    def export_domain_knowledge(self) -> Dict[str, Any]:
        """Export all knowledge for the domain."""
        return self.store.export_knowledge(domain=self.domain)


# é»˜è®¤ä½¿ç”¨ ChromaKnowledgeStoreï¼ˆæ”¯æŒ RAG å‘é‡æ£€ç´¢ï¼‰
# æ—§çš„ JSON å­˜å‚¨å·²é‡å‘½åä¸º LegacyKnowledgeStore
KnowledgeStore = ChromaKnowledgeStore
