"""Knowledge base storage system for domain-specific knowledge."""

import json
from dataclasses import dataclass, asdict
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any

import chromadb
from chromadb.config import Settings
from loguru import logger

from nanobot.utils.helpers import ensure_dir
from .rag_config import RAGConfig
from .text_chunker import TextChunker
from .vector_embedder import VectorEmbedder


class RAGKnowledgeError(Exception):
    """RAG çŸ¥è¯†åº“ç³»ç»ŸåŸºç¡€å¼‚å¸¸."""
    pass


class ChromaConnectionError(RAGKnowledgeError):
    """Chroma è¿æ¥é”™è¯¯."""

    def __init__(self, message: str):
        super().__init__(
            f"Chroma æ•°æ®åº“è¿æ¥å¤±è´¥: {message}\n"
            f"è¯·æ£€æŸ¥:\n"
            f"1. Chroma æœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œ\n"
            f"2. æ•°æ®åº“è·¯å¾„æ˜¯å¦æœ‰è¯»å†™æƒé™\n"
            f"3. ç£ç›˜ç©ºé—´æ˜¯å¦å……è¶³"
        )


@dataclass
class KnowledgeItem:
    """Knowledge item data structure."""
    id: str
    domain: str  # e.g., "rocketmq", "kubernetes", "github"
    category: str  # e.g., "troubleshooting", "configuration", "best_practices"
    title: str
    content: str
    tags: List[str]
    created_at: str
    updated_at: str
    source: str = "user"  # "user" or "system"
    priority: int = 1  # 1-5, higher is more important

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for JSON serialization."""
        return asdict(self)

    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> "KnowledgeItem":
        """Create from dictionary."""
        return cls(**data)


class ChromaKnowledgeStore:
    """åŸºäº Chroma çš„çŸ¥è¯†åº“å­˜å‚¨ç³»ç»Ÿ."""

    def __init__(self, workspace: Path, config: Optional[RAGConfig] = None):
        """åˆå§‹åŒ–çŸ¥è¯†åº“.
        
        Args:
            workspace: å·¥ä½œç©ºé—´è·¯å¾„
            config: RAG é…ç½®
            
        Raises:
            ChromaConnectionError: Chroma æ•°æ®åº“è¿æ¥å¤±è´¥æ—¶æŠ›å‡º
            EmbeddingModelError: Embedding æ¨¡å‹åŠ è½½å¤±è´¥æ—¶æŠ›å‡º
        """
        import time
        start_time = time.time()

        self.workspace = workspace
        self.config = config or RAGConfig()
        self.knowledge_dir = ensure_dir(workspace / "knowledge")
        self.chroma_dir = ensure_dir(self.knowledge_dir / "chroma_db")
        self.init_status_file = self.knowledge_dir / "init_status.json"

        logger.info("ğŸ—ï¸  å¼€å§‹åˆå§‹åŒ– RAG çŸ¥è¯†åº“ Chroma")
        logger.info(f"   - å·¥ä½œç©ºé—´: {workspace}")
        logger.info(f"   - çŸ¥è¯†åº“ç›®å½•: {self.knowledge_dir}")
        logger.info(f"   - Chroma æ•°æ®åº“: {self.chroma_dir}")

        # åˆå§‹åŒ–ç»„ä»¶
        logger.info("ğŸ”§ åˆå§‹åŒ– RAG çŸ¥è¯†åº“ç»„ä»¶...")
        logger.info(f"   - å‘é‡åŒ–æ¨¡å‹: {self.config.embedding_model}")
        logger.info(f"   - åˆ†å—å¤§å°: {self.config.chunk_size}")
        logger.info(f"   - åˆ†å—é‡å : {self.config.chunk_overlap}")

        self.embedder = VectorEmbedder(self.config.embedding_model)
        self.chunker = TextChunker(
            chunk_size=self.config.chunk_size,
            chunk_overlap=self.config.chunk_overlap
        )
        self.chroma_client = None
        self._init_chroma()
        self._init_status: Dict[str, Any] = {}
        self._load_init_status()

        # å»¶è¿Ÿåˆå§‹åŒ–å†…ç½®çŸ¥è¯†ï¼ˆåœ¨éœ€è¦æ—¶å†åˆå§‹åŒ–ï¼‰
        self._builtin_knowledge_initialized = False

        elapsed = time.time() - start_time
        logger.info(f"âœ… RAG çŸ¥è¯†åº“Chromaåˆå§‹åŒ–å®Œæˆï¼Œæ€»è€—æ—¶: {elapsed:.2f} ç§’")
        logger.info("ğŸ“š å†…ç½®çŸ¥è¯†åº“å°†åœ¨é¦–æ¬¡ä½¿ç”¨æ—¶è‡ªåŠ¨åˆå§‹åŒ–")

    def _ensure_builtin_knowledge_initialized(self) -> None:
        """ç¡®ä¿å†…ç½®çŸ¥è¯†åº“å·²åˆå§‹åŒ–ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰."""
        if not self._builtin_knowledge_initialized:
            logger.info("ğŸš€ å¼€å§‹å»¶è¿Ÿåˆå§‹åŒ–å†…ç½®çŸ¥è¯†åº“...")
            # åªè®¾ç½®åˆå§‹åŒ–æ ‡è®°ï¼Œä¸å®é™…æ‰§è¡Œåˆå§‹åŒ–
            # RocketMQ çŸ¥è¯†åº“å°†åœ¨éœ€è¦æ—¶ç”± RocketMQKnowledgeInitializer å•ç‹¬åˆå§‹åŒ–
            self._builtin_knowledge_initialized = True
            logger.info("âœ… å†…ç½®çŸ¥è¯†åº“å»¶è¿Ÿåˆå§‹åŒ–å®Œæˆï¼ˆä»…è®¾ç½®æ ‡è®°ï¼Œå®é™…åˆå§‹åŒ–ç”±å„çŸ¥è¯†åº“æ¨¡å—è´Ÿè´£ï¼‰")

    def _init_chroma(self) -> None:
        """åˆå§‹åŒ– Chroma å®¢æˆ·ç«¯.
        
        Raises:
            ChromaConnectionError: Chroma æ•°æ®åº“è¿æ¥å¤±è´¥æ—¶æŠ›å‡º
        """
        try:
            logger.info(f"åˆå§‹åŒ– Chroma æŒä¹…åŒ–å®¢æˆ·ç«¯: {self.chroma_dir}")
            self.chroma_client = chromadb.PersistentClient(
                path=str(self.chroma_dir),
                settings=Settings(
                    anonymized_telemetry=False,
                    allow_reset=True
                )
            )
            logger.info("Chroma å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"Chroma å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {str(e)}", exc_info=True)
            raise ChromaConnectionError(str(e))

    def _get_or_create_collection(self, domain: str):
        """è·å–æˆ–åˆ›å»º Chroma é›†åˆ.
        
        Args:
            domain: é¢†åŸŸåç§°
            
        Returns:
            Chroma é›†åˆå¯¹è±¡
            
        Raises:
            ChromaConnectionError: é›†åˆåˆ›å»ºå¤±è´¥æ—¶æŠ›å‡º
        """
        collection_name = f"knowledge_{domain}"

        try:
            # å°è¯•è·å–ç°æœ‰é›†åˆ
            logger.debug(f"ğŸ” å°è¯•è·å–ç°æœ‰é›†åˆ: {collection_name}")
            collection = self.chroma_client.get_collection(name=collection_name)

            # è·å–é›†åˆç»Ÿè®¡ä¿¡æ¯
            collection_count = collection.count()
            logger.info(f"âœ… è·å–ç°æœ‰é›†åˆæˆåŠŸ: {collection_name}")
            logger.info(f"   - é›†åˆæ•°é‡: {collection_count}")
            logger.info(f"   - åˆ›å»ºæ—¶é—´: {collection.metadata.get('created_at', 'æœªçŸ¥')}")

            return collection
        except Exception:
            # é›†åˆä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°é›†åˆ
            try:
                logger.info(f"ğŸ—ï¸  åˆ›å»ºæ–°é›†åˆ: {collection_name}")
                collection = self.chroma_client.create_collection(
                    name=collection_name,
                    metadata={
                        "domain": domain,
                        "created_at": datetime.now().isoformat(),
                        "description": f"{domain} çŸ¥è¯†åº“é›†åˆ"
                    }
                )
                logger.info(f"âœ… é›†åˆåˆ›å»ºæˆåŠŸ: {collection_name}")
                logger.info(f"   - é¢†åŸŸ: {domain}")
                logger.info(f"   - åˆ›å»ºæ—¶é—´: {collection.metadata.get('created_at', 'æœªçŸ¥')}")
                return collection
            except Exception as e:
                logger.error(f"âŒ é›†åˆåˆ›å»ºå¤±è´¥: {collection_name}, é”™è¯¯: {str(e)}", exc_info=True)
                raise ChromaConnectionError(f"åˆ›å»ºé›†åˆå¤±è´¥: {str(e)}")

    def _load_init_status(self) -> None:
        """åŠ è½½åˆå§‹åŒ–çŠ¶æ€æ–‡ä»¶."""
        if self.init_status_file.exists():
            try:
                with open(self.init_status_file, 'r', encoding='utf-8') as f:
                    self._init_status = json.load(f)
                logger.info(f"âœ… åˆå§‹åŒ–çŠ¶æ€æ–‡ä»¶åŠ è½½æˆåŠŸ: {self.init_status_file}")
                logger.debug(f"   - æ–‡ä»¶å†…å®¹: {json.dumps(self._init_status, ensure_ascii=False)}")
            except (json.JSONDecodeError, KeyError) as e:
                logger.warning(f"âš ï¸ åˆå§‹åŒ–çŠ¶æ€æ–‡ä»¶åŠ è½½å¤±è´¥: {str(e)}")
                self._init_status = {}
        else:
            logger.info(f"ğŸ“ åˆå§‹åŒ–çŠ¶æ€æ–‡ä»¶ä¸å­˜åœ¨: {self.init_status_file}")
            logger.info("   åˆ›å»ºæ–°çš„åˆå§‹åŒ–çŠ¶æ€")
            self._init_status = {}

    def _save_init_status(self) -> None:
        """ä¿å­˜åˆå§‹åŒ–çŠ¶æ€åˆ°æ–‡ä»¶."""
        try:
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            self.init_status_file.parent.mkdir(parents=True, exist_ok=True)

            with open(self.init_status_file, 'w', encoding='utf-8') as f:
                json.dump(self._init_status, f, indent=2, ensure_ascii=False)

            logger.info(f"âœ… åˆå§‹åŒ–çŠ¶æ€å·²ä¿å­˜: {self.init_status_file}")
            logger.debug(f"   - æ–‡ä»¶å¤§å°: {self.init_status_file.stat().st_size} å­—èŠ‚")
            logger.debug(f"   - çŠ¶æ€å†…å®¹: {json.dumps(self._init_status, ensure_ascii=False)}")

        except Exception as e:
            logger.error(f"âŒ ä¿å­˜åˆå§‹åŒ–çŠ¶æ€å¤±è´¥: {str(e)}", exc_info=True)
            logger.error(f"   æ–‡ä»¶è·¯å¾„: {self.init_status_file}")
            logger.error(f"   çŠ¶æ€å†…å®¹: {json.dumps(self._init_status, ensure_ascii=False)}")

    def _should_reinitialize(self, domain: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦é‡æ–°åˆå§‹åŒ–.
        
        Args:
            domain: é¢†åŸŸåç§°
            
        Returns:
            æ˜¯å¦éœ€è¦é‡æ–°åˆå§‹åŒ–
        """
        # é¦–å…ˆæ£€æŸ¥åˆå§‹åŒ–çŠ¶æ€æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not self.init_status_file.exists():
            logger.info(f"ğŸ” æ£€æŸ¥é¢†åŸŸ '{domain}' çš„åˆå§‹åŒ–çŠ¶æ€:")
            logger.info(f"   - åˆå§‹åŒ–çŠ¶æ€æ–‡ä»¶ä¸å­˜åœ¨: {self.init_status_file}")
            logger.info(f"âœ… å†³ç­–: é¢†åŸŸ '{domain}' éœ€è¦åˆå§‹åŒ–ï¼ˆæ–‡ä»¶ä¸å­˜åœ¨ï¼‰")
            return True

        # æ–‡ä»¶å­˜åœ¨ï¼Œæ£€æŸ¥è¯¥é¢†åŸŸçš„åˆå§‹åŒ–çŠ¶æ€
        status = self._init_status.get(domain, {})

        logger.info(f"ğŸ” æ£€æŸ¥é¢†åŸŸ '{domain}' çš„åˆå§‹åŒ–çŠ¶æ€:")
        logger.info(f"   - åˆå§‹åŒ–çŠ¶æ€æ–‡ä»¶: {self.init_status_file}")
        logger.info(f"   - å½“å‰çŠ¶æ€: {status.get('initialized_at', 'æœªåˆå§‹åŒ–')}")

        # å¦‚æœä»æœªåˆå§‹åŒ–ï¼Œéœ€è¦åˆå§‹åŒ–
        if not status.get("initialized_at"):
            logger.info(f"âœ… å†³ç­–: é¢†åŸŸ '{domain}' ä»æœªåˆå§‹åŒ–ï¼Œéœ€è¦åˆå§‹åŒ–")
            return True

        # å·²ç»åˆå§‹åŒ–è¿‡ï¼Œè·³è¿‡åˆå§‹åŒ–
        logger.info(f"âœ… å†³ç­–: é¢†åŸŸ '{domain}' å·²åˆå§‹åŒ–ï¼Œè·³è¿‡åˆå§‹åŒ–")
        return False
        return False

    def _auto_initialize_builtin_knowledge(self) -> None:
        """è‡ªåŠ¨åˆå§‹åŒ–å†…ç½®çŸ¥è¯†."""
        import time
        start_time = time.time()

        logger.info("ğŸš€ å¼€å§‹è‡ªåŠ¨åˆå§‹åŒ–å†…ç½®çŸ¥è¯†åº“")
        logger.info("ğŸ“Š æ£€æŸ¥å†…ç½®çŸ¥è¯†æ¨¡å—å¯ç”¨æ€§...")

        # åˆå§‹åŒ– RocketMQ çŸ¥è¯†
        self._initialize_rocketmq_knowledge()

        elapsed = time.time() - start_time

        # ç»Ÿè®¡åˆå§‹åŒ–ç»“æœ
        rocketmq_status = self._init_status.get("rocketmq", {})
        rocketmq_items = rocketmq_status.get("item_count", 0)
        rocketmq_chunks = rocketmq_status.get("chunk_count", 0)

        logger.info("âœ… å†…ç½®çŸ¥è¯†åº“åˆå§‹åŒ–å®Œæˆ:")
        logger.info(f"   - RocketMQ çŸ¥è¯†æ¡ç›®: {rocketmq_items}")
        logger.info(f"   - RocketMQ å‘é‡åŒ–åˆ†å—: {rocketmq_chunks}")
        logger.info(f"   - æ€»è€—æ—¶: {elapsed:.2f} ç§’")

        if rocketmq_items == 0:
            logger.warning("âš ï¸  RocketMQ çŸ¥è¯†åº“ä¸ºç©ºï¼Œå¯èƒ½éœ€è¦æ£€æŸ¥çŸ¥è¯†æ–‡ä»¶è·¯å¾„")
        else:
            logger.info("ğŸ‰ å†…ç½®çŸ¥è¯†åº“å·²å‡†å¤‡å°±ç»ªï¼Œå¯ä»¥å¼€å§‹ä½¿ç”¨")

    def _initialize_rocketmq_knowledge(self) -> None:
        """åˆå§‹åŒ– RocketMQ çŸ¥è¯†ï¼Œæ”¯æŒç‰ˆæœ¬æ§åˆ¶å’Œå‘é‡åŒ–."""
        try:
            from .rocketmq_init import RocketMQKnowledgeInitializer, ROCKETMQ_KNOWLEDGE_VERSION

            logger.info(f"ğŸ” æ£€æŸ¥ RocketMQ çŸ¥è¯†åº“çŠ¶æ€...")
            logger.info(f"   - åˆå§‹åŒ–çŠ¶æ€æ–‡ä»¶: {self.init_status_file}")
            logger.info(f"   - æ–‡ä»¶å­˜åœ¨: {self.init_status_file.exists()}")
            logger.info(f"   - å½“å‰ç‰ˆæœ¬: {ROCKETMQ_KNOWLEDGE_VERSION}")

            # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°åˆå§‹åŒ–
            needs_reinit = self._should_reinitialize("rocketmq")

            if needs_reinit:
                logger.info(f"ğŸ”„ éœ€è¦é‡æ–°åˆå§‹åŒ– RocketMQ çŸ¥è¯†åº“")

                import time
                start_time = time.time()

                logger.info(f"ğŸš€ å¼€å§‹åˆå§‹åŒ– RocketMQ çŸ¥è¯†åº“")

                # å¦‚æœéœ€è¦é‡æ–°åˆå§‹åŒ–ï¼Œå…ˆæ¸…ç©ºç°æœ‰é›†åˆ
                try:
                    self.chroma_client.delete_collection(f"knowledge_rocketmq")
                    logger.info("ğŸ—‘ï¸  å·²åˆ é™¤æ—§çš„ RocketMQ é›†åˆ")
                except Exception:
                    logger.info("â„¹ï¸  RocketMQ é›†åˆä¸å­˜åœ¨ï¼Œæ— éœ€åˆ é™¤")

                # åˆå§‹åŒ– RocketMQ çŸ¥è¯†
                logger.info("ğŸ“š æ­£åœ¨åŠ è½½ RocketMQ çŸ¥è¯†å†…å®¹...")
                initializer = RocketMQKnowledgeInitializer(self)
                item_count, chunk_count = initializer.initialize()

                elapsed = time.time() - start_time

                # æ›´æ–°åˆå§‹åŒ–çŠ¶æ€
                self._init_status["rocketmq"] = {
                    "initialized_at": datetime.now().isoformat(),
                    "item_count": item_count,
                    "chunk_count": chunk_count,
                    "last_check": datetime.now().isoformat(),
                    "elapsed_seconds": round(elapsed, 2)
                }
                self._save_init_status()

                logger.info("âœ… RocketMQ çŸ¥è¯†åº“åˆå§‹åŒ–å®Œæˆ:")
                logger.info(f"   - çŸ¥è¯†æ¡ç›®æ•°: {item_count}")
                logger.info(f"   - å‘é‡åŒ–åˆ†å—æ•°: {chunk_count}")
                logger.info(f"   - è€—æ—¶: {elapsed:.2f} ç§’")
                logger.info(f"   - çŠ¶æ€æ–‡ä»¶: {self.init_status_file}")

                print(
                    f"âœ… åˆå§‹åŒ– {item_count} ä¸ª RocketMQ çŸ¥è¯†æ¡ç›®ï¼Œ"
                    f"{chunk_count} ä¸ªæ–‡æœ¬å—ï¼Œ"
                    f"è€—æ—¶ {elapsed:.2f} ç§’"
                )
            else:
                # å·²ç»åˆå§‹åŒ–ï¼Œåªæ›´æ–°æ£€æŸ¥æ—¶é—´
                self._init_status["rocketmq"]["last_check"] = datetime.now().isoformat()
                self._save_init_status()

                status = self._init_status.get("rocketmq", {})
                item_count = status.get("item_count", 0)
                chunk_count = status.get("chunk_count", 0)

                logger.info(f"âœ… RocketMQ çŸ¥è¯†åº“å·²åˆå§‹åŒ–")
                logger.info(f"   - ç°æœ‰çŸ¥è¯†æ¡ç›®æ•°: {item_count}")
                logger.info(f"   - ç°æœ‰å‘é‡åŒ–åˆ†å—æ•°: {chunk_count}")
                logger.info(f"   - çŠ¶æ€æ–‡ä»¶: {self.init_status_file}")

        except ImportError:
            logger.warning("âš ï¸  RocketMQ çŸ¥è¯†æ¨¡å—ä¸å¯ç”¨ï¼Œè·³è¿‡åˆå§‹åŒ–")
        except Exception as e:
            logger.error(f"âŒ åˆå§‹åŒ– RocketMQ çŸ¥è¯†å¤±è´¥: {str(e)}", exc_info=True)
            print(f"âš ï¸ åˆå§‹åŒ– RocketMQ çŸ¥è¯†å¤±è´¥: {e}")

    def add_knowledge(
            self,
            domain: str,
            category: str,
            title: str,
            content: str,
            tags: List[str] = None,
            source: str = "user",
            priority: int = 1
    ) -> str:
        """æ·»åŠ çŸ¥è¯†æ¡ç›®.
        
        Args:
            domain: é¢†åŸŸ
            category: åˆ†ç±»
            title: æ ‡é¢˜
            content: å†…å®¹
            tags: æ ‡ç­¾åˆ—è¡¨
            source: æ¥æº
            priority: ä¼˜å…ˆçº§
            
        Returns:
            çŸ¥è¯†æ¡ç›® ID
        """
        # 1. åˆ›å»º KnowledgeItem
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S%f")
        item_id = f"{domain}_{timestamp}"

        if tags is None:
            tags = []

        # å‡†å¤‡å…ƒæ•°æ®
        metadata = {
            "item_id": item_id,
            "domain": domain,
            "category": category,
            "title": title,
            "tags": tags,
            "source": source,
            "priority": priority,
            "created_at": datetime.now().isoformat(),
            "updated_at": datetime.now().isoformat()
        }

        try:
            # 2. æ–‡æœ¬åˆ†å—
            chunks = self.chunker.chunk_text(content, metadata)

            if not chunks:
                logger.warning(f"çŸ¥è¯†æ¡ç›® {item_id} åˆ†å—åä¸ºç©ºï¼Œè·³è¿‡")
                return item_id

            # 3. æ‰¹é‡å‘é‡åŒ–
            chunk_texts = [chunk["text"] for chunk in chunks]
            try:
                embeddings = self.embedder.embed_batch(chunk_texts)
            except Exception as e:
                logger.error(f"çŸ¥è¯†æ¡ç›® {item_id} å‘é‡åŒ–å¤±è´¥: {str(e)}")
                raise

            # 4. å­˜å‚¨åˆ° Chroma é›†åˆ
            collection = self._get_or_create_collection(domain)

            # å‡†å¤‡æ‰¹é‡æ’å…¥çš„æ•°æ®
            ids = []
            documents = []
            metadatas = []
            embeddings_list = []

            for i, (chunk, embedding) in enumerate(zip(chunks, embeddings)):
                chunk_id = f"{item_id}_chunk_{i}"
                ids.append(chunk_id)
                documents.append(chunk["text"])
                metadatas.append(chunk["metadata"])
                embeddings_list.append(embedding)

            # æ‰¹é‡æ’å…¥åˆ° Chroma
            collection.add(
                ids=ids,
                documents=documents,
                metadatas=metadatas,
                embeddings=embeddings_list
            )

            logger.info(
                f"çŸ¥è¯†æ¡ç›® {item_id} å·²æ·»åŠ : {len(chunks)} ä¸ªåˆ†å—"
            )

            return item_id

        except Exception as e:
            logger.error(
                f"æ·»åŠ çŸ¥è¯†æ¡ç›® {item_id} å¤±è´¥: {str(e)}",
                exc_info=True
            )
            raise

    def search_knowledge(
            self,
            query: str = None,
            domain: str = None,
            category: str = None,
            tags: List[str] = None,
            top_k: int = None
    ) -> List[KnowledgeItem]:
        """æœç´¢çŸ¥è¯†æ¡ç›®.

        Args:
            query: æŸ¥è¯¢æ–‡æœ¬ï¼ˆç”¨äºè¯­ä¹‰æ£€ç´¢ï¼Œå¯é€‰ï¼‰
            domain: é¢†åŸŸè¿‡æ»¤
            category: åˆ†ç±»è¿‡æ»¤
            tags: æ ‡ç­¾è¿‡æ»¤
            top_k: è¿”å›ç»“æœæ•°é‡

        Returns:
            çŸ¥è¯†æ¡ç›®åˆ—è¡¨ï¼ŒæŒ‰ç›¸ä¼¼åº¦åˆ†æ•°é™åºæ’åˆ—ï¼ˆè¯­ä¹‰æ£€ç´¢ï¼‰æˆ–æŒ‰åˆ›å»ºæ—¶é—´æ’åºï¼ˆå…ƒæ•°æ®è¿‡æ»¤ï¼‰
        """
        # ç¡®ä¿å†…ç½®çŸ¥è¯†åº“å·²åˆå§‹åŒ–ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰
        self._ensure_builtin_knowledge_initialized()

        # ä½¿ç”¨é…ç½®çš„é»˜è®¤å€¼æˆ–å‚æ•°æŒ‡å®šçš„å€¼
        if top_k is None:
            top_k = self.config.top_k

        # å¦‚æœæ²¡æœ‰æä¾› queryï¼Œä½¿ç”¨åŸºäºå…ƒæ•°æ®çš„è¿‡æ»¤æ£€ç´¢ï¼ˆéœ€æ±‚ 6.5ï¼‰
        if not query:
            logger.info(
                f"[KNOWLEDGE_STORE] ğŸ” æ‰§è¡Œå…ƒæ•°æ®è¿‡æ»¤æ£€ç´¢: domain={domain}, category={category}, tags={tags}, top_k={top_k}")
            return self._search_by_metadata(domain, category, tags, top_k)

        # æœ‰ query å‚æ•°æ—¶ï¼Œä½¿ç”¨ RAG è¯­ä¹‰æ£€ç´¢ï¼ˆéœ€æ±‚ 6.4ï¼‰
        logger.info(f"[KNOWLEDGE_STORE] ğŸ” å¼€å§‹è¯­ä¹‰æ£€ç´¢:")
        logger.info(f"[KNOWLEDGE_STORE]   - Query: '{query}'")
        logger.info(f"[KNOWLEDGE_STORE]   - Domain: {domain}")
        logger.info(f"[KNOWLEDGE_STORE]   - Category: {category}")
        logger.info(f"[KNOWLEDGE_STORE]   - Tags: {tags}")
        logger.info(f"[KNOWLEDGE_STORE]   - Top K: {top_k}")

        try:
            # 1. å‘é‡åŒ–æŸ¥è¯¢æ–‡æœ¬
            start_time = datetime.now()
            logger.info(f"[KNOWLEDGE_STORE] ğŸ§® å¼€å§‹å‘é‡åŒ–æŸ¥è¯¢æ–‡æœ¬...")
            query_vector = self.embedder.embed_text(query)
            vectorize_time = (datetime.now() - start_time).total_seconds()
            logger.info(
                f"[KNOWLEDGE_STORE] âœ… æŸ¥è¯¢å‘é‡åŒ–å®Œæˆï¼Œè€—æ—¶: {vectorize_time:.3f}ç§’ï¼Œå‘é‡ç»´åº¦: {len(query_vector)}")

            # 2. æ„å»ºå…ƒæ•°æ®è¿‡æ»¤æ¡ä»¶
            where_filter = {}
            if category:
                where_filter["category"] = category
            if tags:
                # Chroma æ”¯æŒ $in æ“ä½œç¬¦è¿›è¡Œæ ‡ç­¾è¿‡æ»¤
                # ä½†ç”±äº tags å­˜å‚¨ä¸ºå­—ç¬¦ä¸²åˆ—è¡¨ï¼Œæˆ‘ä»¬éœ€è¦æ£€æŸ¥æ˜¯å¦æœ‰ä»»ä½•æ ‡ç­¾åŒ¹é…
                where_filter["tags"] = {"$in": tags}

            # 3. ç¡®å®šè¦æœç´¢çš„é›†åˆ
            collections_to_search = []
            if domain:
                # åªæœç´¢æŒ‡å®šé¢†åŸŸ
                try:
                    collection = self._get_or_create_collection(domain)
                    collections_to_search.append((domain, collection))
                except Exception as e:
                    logger.warning(f"è·å–é¢†åŸŸ '{domain}' çš„é›†åˆå¤±è´¥: {str(e)}")
            else:
                # æœç´¢æ‰€æœ‰é¢†åŸŸ
                try:
                    all_collections = self.chroma_client.list_collections()
                    for coll_info in all_collections:
                        coll_name = coll_info.name
                        if coll_name.startswith("knowledge_"):
                            domain_name = coll_name.replace("knowledge_", "")
                            try:
                                collection = self.chroma_client.get_collection(coll_name)
                                collections_to_search.append((domain_name, collection))
                            except Exception as e:
                                logger.warning(f"è·å–é›†åˆ '{coll_name}' å¤±è´¥: {str(e)}")
                except Exception as e:
                    logger.error(f"åˆ—å‡ºé›†åˆå¤±è´¥: {str(e)}")
                    return []

            if not collections_to_search:
                logger.warning("[KNOWLEDGE_STORE] âš ï¸  æ²¡æœ‰å¯æœç´¢çš„é›†åˆ")
                return []

            logger.info(f"[KNOWLEDGE_STORE] ğŸ“š å°†åœ¨ {len(collections_to_search)} ä¸ªé›†åˆä¸­æœç´¢")

            # 4. åœ¨æ‰€æœ‰ç›¸å…³é›†åˆä¸­æ‰§è¡Œç›¸ä¼¼åº¦æœç´¢
            all_results = []
            search_start = datetime.now()

            for domain_name, collection in collections_to_search:
                try:
                    # æ‰§è¡Œ Chroma æŸ¥è¯¢
                    results = collection.query(
                        query_embeddings=[query_vector],
                        n_results=top_k,
                        where=where_filter if where_filter else None,
                        include=["documents", "metadatas", "distances"]
                    )

                    # å¤„ç†æŸ¥è¯¢ç»“æœ
                    if results and results["ids"] and len(results["ids"][0]) > 0:
                        for i in range(len(results["ids"][0])):
                            chunk_id = results["ids"][0][i]
                            document = results["documents"][0][i]
                            metadata = results["metadatas"][0][i]
                            distance = results["distances"][0][i]

                            # å°†è·ç¦»è½¬æ¢ä¸ºç›¸ä¼¼åº¦åˆ†æ•° (è·ç¦»è¶Šå°ï¼Œç›¸ä¼¼åº¦è¶Šé«˜)
                            # Chroma ä½¿ç”¨ L2 è·ç¦»ï¼Œæˆ‘ä»¬å°†å…¶è½¬æ¢ä¸º 0-1 çš„ç›¸ä¼¼åº¦åˆ†æ•°
                            # similarity = 1 / (1 + distance)
                            similarity_score = 1.0 / (1.0 + distance)

                            # è¿‡æ»¤ä½äºé˜ˆå€¼çš„ç»“æœ
                            if similarity_score < self.config.similarity_threshold:
                                continue

                            all_results.append({
                                "chunk_id": chunk_id,
                                "document": document,
                                "metadata": metadata,
                                "similarity_score": similarity_score,
                                "domain": domain_name
                            })

                except Exception as e:
                    logger.warning(f"åœ¨é¢†åŸŸ '{domain_name}' ä¸­æœç´¢å¤±è´¥: {str(e)}")
                    continue

            search_time = (datetime.now() - search_start).total_seconds()
            logger.info(
                f"[KNOWLEDGE_STORE] ğŸ” ç›¸ä¼¼åº¦æœç´¢å®Œæˆï¼Œè€—æ—¶: {search_time:.3f}ç§’ï¼Œæ‰¾åˆ° {len(all_results)} ä¸ªåˆ†å—ç»“æœ")

            # 5. æŒ‰ç›¸ä¼¼åº¦åˆ†æ•°é™åºæ’åº
            all_results.sort(key=lambda x: x["similarity_score"], reverse=True)

            # 6. é™åˆ¶è¿”å›ç»“æœæ•°é‡
            all_results = all_results[:top_k]

            # 7. é‡æ„ä¸º KnowledgeItem å¯¹è±¡
            knowledge_items = []
            seen_item_ids = set()  # ç”¨äºå»é‡ï¼ˆåŒä¸€çŸ¥è¯†æ¡ç›®çš„ä¸åŒåˆ†å—ï¼‰

            for result in all_results:
                metadata = result["metadata"]
                item_id = metadata.get("item_id")

                # å¦‚æœå·²ç»æ·»åŠ è¿‡è¿™ä¸ªçŸ¥è¯†æ¡ç›®ï¼Œè·³è¿‡ï¼ˆé¿å…é‡å¤ï¼‰
                if item_id in seen_item_ids:
                    continue
                seen_item_ids.add(item_id)

                # åˆ›å»º KnowledgeItem
                try:
                    knowledge_item = KnowledgeItem(
                        id=item_id,
                        domain=metadata.get("domain", result["domain"]),
                        category=metadata.get("category", ""),
                        title=metadata.get("title", ""),
                        content=result["document"],  # ä½¿ç”¨åˆ†å—çš„å†…å®¹
                        tags=metadata.get("tags", []),
                        created_at=metadata.get("created_at", ""),
                        updated_at=metadata.get("updated_at", ""),
                        source=metadata.get("source", "user"),
                        priority=metadata.get("priority", 1)
                    )

                    # æ·»åŠ ç›¸ä¼¼åº¦åˆ†æ•°ï¼ˆä½œä¸ºé¢å¤–å±æ€§ï¼‰
                    # æ³¨æ„ï¼šKnowledgeItem æ˜¯ dataclassï¼Œæˆ‘ä»¬éœ€è¦åŠ¨æ€æ·»åŠ å±æ€§
                    knowledge_item_dict = knowledge_item.to_dict()
                    knowledge_item_dict["similarity_score"] = result["similarity_score"]
                    knowledge_item_dict["chunk_index"] = metadata.get("chunk_index", 0)

                    # é‡æ–°åˆ›å»ºå¸¦æœ‰é¢å¤–å­—æ®µçš„å¯¹è±¡
                    # ç”±äº KnowledgeItem ä¸æ”¯æŒé¢å¤–å­—æ®µï¼Œæˆ‘ä»¬ç›´æ¥è¿”å›åŸå¯¹è±¡
                    # å¹¶åœ¨æ—¥å¿—ä¸­è®°å½•ç›¸ä¼¼åº¦åˆ†æ•°
                    knowledge_items.append(knowledge_item)

                    logger.debug(
                        f"æ·»åŠ ç»“æœ: id={item_id}, title={metadata.get('title', '')[:30]}, "
                        f"similarity={result['similarity_score']:.4f}"
                    )

                except Exception as e:
                    logger.warning(f"é‡æ„ KnowledgeItem å¤±è´¥: {str(e)}")
                    continue

            total_time = (datetime.now() - start_time).total_seconds()
            logger.info(f"[KNOWLEDGE_STORE] âœ… è¯­ä¹‰æ£€ç´¢å®Œæˆ:")
            logger.info(f"[KNOWLEDGE_STORE]   - è¿”å›ç»“æœæ•°: {len(knowledge_items)}")
            logger.info(f"[KNOWLEDGE_STORE]   - æ€»è€—æ—¶: {total_time:.3f}ç§’")

            # è®°å½•å‰3ä¸ªç»“æœçš„æ ‡é¢˜å’Œç›¸ä¼¼åº¦
            for i, item in enumerate(knowledge_items[:3], 1):
                score = all_results[i - 1]["similarity_score"] if i - 1 < len(all_results) else 0
                logger.info(f"[KNOWLEDGE_STORE]   {i}. {item.title[:50]} (ç›¸ä¼¼åº¦: {score:.4f})")

            return knowledge_items

        except Exception as e:
            logger.error(f"è¯­ä¹‰æ£€ç´¢å¤±è´¥: {str(e)}", exc_info=True)
            return []

    def _search_by_metadata(
            self,
            domain: str = None,
            category: str = None,
            tags: List[str] = None,
            top_k: int = None
    ) -> List[KnowledgeItem]:
        """åŸºäºå…ƒæ•°æ®çš„è¿‡æ»¤æ£€ç´¢ï¼ˆä¸ä½¿ç”¨è¯­ä¹‰æœç´¢ï¼‰.
        
        å½“æ²¡æœ‰æä¾› query å‚æ•°æ—¶ä½¿ç”¨æ­¤æ–¹æ³•ï¼ˆéœ€æ±‚ 6.5ï¼‰ã€‚
        
        Args:
            domain: é¢†åŸŸè¿‡æ»¤
            category: åˆ†ç±»è¿‡æ»¤
            tags: æ ‡ç­¾è¿‡æ»¤
            top_k: è¿”å›ç»“æœæ•°é‡
            
        Returns:
            çŸ¥è¯†æ¡ç›®åˆ—è¡¨ï¼ŒæŒ‰åˆ›å»ºæ—¶é—´é™åºæ’åˆ—
        """
        try:
            # æ„å»ºå…ƒæ•°æ®è¿‡æ»¤æ¡ä»¶
            where_filter = {}
            if category:
                where_filter["category"] = category
            if tags:
                where_filter["tags"] = {"$in": tags}

            # ç¡®å®šè¦æœç´¢çš„é›†åˆ
            collections_to_search = []
            if domain:
                # åªæœç´¢æŒ‡å®šé¢†åŸŸ
                try:
                    collection = self._get_or_create_collection(domain)
                    collections_to_search.append((domain, collection))
                except Exception as e:
                    logger.warning(f"è·å–é¢†åŸŸ '{domain}' çš„é›†åˆå¤±è´¥: {str(e)}")
            else:
                # æœç´¢æ‰€æœ‰é¢†åŸŸ
                try:
                    all_collections = self.chroma_client.list_collections()
                    for coll_info in all_collections:
                        coll_name = coll_info.name
                        if coll_name.startswith("knowledge_"):
                            domain_name = coll_name.replace("knowledge_", "")
                            try:
                                collection = self.chroma_client.get_collection(coll_name)
                                collections_to_search.append((domain_name, collection))
                            except Exception as e:
                                logger.warning(f"è·å–é›†åˆ '{coll_name}' å¤±è´¥: {str(e)}")
                except Exception as e:
                    logger.error(f"åˆ—å‡ºé›†åˆå¤±è´¥: {str(e)}")
                    return []

            if not collections_to_search:
                logger.warning("æ²¡æœ‰å¯æœç´¢çš„é›†åˆ")
                return []

            # åœ¨æ‰€æœ‰ç›¸å…³é›†åˆä¸­æ‰§è¡Œå…ƒæ•°æ®è¿‡æ»¤
            all_results = []

            for domain_name, collection in collections_to_search:
                try:
                    # ä½¿ç”¨ Chroma çš„ get æ–¹æ³•è¿›è¡Œå…ƒæ•°æ®è¿‡æ»¤
                    results = collection.get(
                        where=where_filter if where_filter else None,
                        limit=top_k if top_k else 1000,  # è®¾ç½®ä¸€ä¸ªåˆç†çš„ä¸Šé™
                        include=["documents", "metadatas"]
                    )

                    # å¤„ç†æŸ¥è¯¢ç»“æœ
                    if results and results["ids"]:
                        for i in range(len(results["ids"])):
                            chunk_id = results["ids"][i]
                            document = results["documents"][i]
                            metadata = results["metadatas"][i]

                            all_results.append({
                                "chunk_id": chunk_id,
                                "document": document,
                                "metadata": metadata,
                                "domain": domain_name
                            })

                except Exception as e:
                    logger.warning(f"åœ¨é¢†åŸŸ '{domain_name}' ä¸­æœç´¢å¤±è´¥: {str(e)}")
                    continue

            logger.debug(f"å…ƒæ•°æ®è¿‡æ»¤å®Œæˆï¼Œæ‰¾åˆ° {len(all_results)} ä¸ªç»“æœ")

            # æŒ‰åˆ›å»ºæ—¶é—´é™åºæ’åº
            all_results.sort(
                key=lambda x: x["metadata"].get("created_at", ""),
                reverse=True
            )

            # é™åˆ¶è¿”å›ç»“æœæ•°é‡
            if top_k:
                all_results = all_results[:top_k]

            # é‡æ„ä¸º KnowledgeItem å¯¹è±¡
            knowledge_items = []
            seen_item_ids = set()  # ç”¨äºå»é‡ï¼ˆåŒä¸€çŸ¥è¯†æ¡ç›®çš„ä¸åŒåˆ†å—ï¼‰

            for result in all_results:
                metadata = result["metadata"]
                item_id = metadata.get("item_id")

                # å¦‚æœå·²ç»æ·»åŠ è¿‡è¿™ä¸ªçŸ¥è¯†æ¡ç›®ï¼Œè·³è¿‡ï¼ˆé¿å…é‡å¤ï¼‰
                if item_id in seen_item_ids:
                    continue
                seen_item_ids.add(item_id)

                # åˆ›å»º KnowledgeItem
                try:
                    knowledge_item = KnowledgeItem(
                        id=item_id,
                        domain=metadata.get("domain", result["domain"]),
                        category=metadata.get("category", ""),
                        title=metadata.get("title", ""),
                        content=result["document"],  # ä½¿ç”¨åˆ†å—çš„å†…å®¹
                        tags=metadata.get("tags", []),
                        created_at=metadata.get("created_at", ""),
                        updated_at=metadata.get("updated_at", ""),
                        source=metadata.get("source", "user"),
                        priority=metadata.get("priority", 1)
                    )

                    knowledge_items.append(knowledge_item)

                    logger.debug(
                        f"æ·»åŠ ç»“æœ: id={item_id}, title={metadata.get('title', '')[:30]}"
                    )

                except Exception as e:
                    logger.warning(f"é‡æ„ KnowledgeItem å¤±è´¥: {str(e)}")
                    continue

            logger.info(f"å…ƒæ•°æ®è¿‡æ»¤æ£€ç´¢å®Œæˆ: è¿”å› {len(knowledge_items)} ä¸ªç»“æœ")

            return knowledge_items

        except Exception as e:
            logger.error(f"å…ƒæ•°æ®è¿‡æ»¤æ£€ç´¢å¤±è´¥: {str(e)}", exc_info=True)
            return []

    def update_knowledge(self, item_id: str, **kwargs) -> bool:
        """æ›´æ–°çŸ¥è¯†æ¡ç›®.
        
        æ ¹æ®éœ€æ±‚ 5.2ï¼Œæ›´æ–°çŸ¥è¯†æ¡ç›®æ—¶éœ€è¦ï¼š
        1. åˆ é™¤æ—§çš„å‘é‡æ•°æ®
        2. æ›´æ–°å†…å®¹å¹¶é‡æ–°å‘é‡åŒ–
        3. å­˜å‚¨æ–°çš„å‘é‡æ•°æ®
        
        Args:
            item_id: çŸ¥è¯†æ¡ç›® ID
            **kwargs: è¦æ›´æ–°çš„å­—æ®µï¼ˆtitle, content, tags, category, priorityï¼‰
            
        Returns:
            æ˜¯å¦æ›´æ–°æˆåŠŸ
        """
        logger.info(f"å¼€å§‹æ›´æ–°çŸ¥è¯†æ¡ç›®: {item_id}")

        try:
            # 1. é¦–å…ˆæŸ¥æ‰¾è¯¥çŸ¥è¯†æ¡ç›®æ‰€å±çš„é¢†åŸŸ
            # é€šè¿‡éå†æ‰€æœ‰é›†åˆæŸ¥æ‰¾åŒ…å«è¯¥ item_id çš„é›†åˆ
            domain = None
            old_metadata = None

            try:
                all_collections = self.chroma_client.list_collections()
                for coll_info in all_collections:
                    coll_name = coll_info.name
                    if coll_name.startswith("knowledge_"):
                        try:
                            collection = self.chroma_client.get_collection(coll_name)
                            # æŸ¥è¯¢è¯¥é›†åˆä¸­æ˜¯å¦æœ‰è¯¥ item_id çš„åˆ†å—
                            results = collection.get(
                                where={"item_id": item_id},
                                limit=1
                            )

                            if results and results["ids"] and len(results["ids"]) > 0:
                                domain = coll_name.replace("knowledge_", "")
                                old_metadata = results["metadatas"][0]
                                logger.info(f"æ‰¾åˆ°çŸ¥è¯†æ¡ç›® {item_id} åœ¨é¢†åŸŸ {domain}")
                                break
                        except Exception as e:
                            logger.warning(f"æŸ¥è¯¢é›†åˆ {coll_name} å¤±è´¥: {str(e)}")
                            continue
            except Exception as e:
                logger.error(f"åˆ—å‡ºé›†åˆå¤±è´¥: {str(e)}")
                return False

            if not domain or not old_metadata:
                logger.warning(f"çŸ¥è¯†æ¡ç›® {item_id} ä¸å­˜åœ¨")
                return False

            # 2. åˆ é™¤æ—§çš„å‘é‡æ•°æ®
            collection = self._get_or_create_collection(domain)

            # æŸ¥æ‰¾æ‰€æœ‰å±äºè¯¥ item_id çš„åˆ†å—
            old_chunks = collection.get(
                where={"item_id": item_id}
            )

            if old_chunks and old_chunks["ids"]:
                chunk_ids = old_chunks["ids"]
                collection.delete(ids=chunk_ids)
                logger.info(f"åˆ é™¤äº† {len(chunk_ids)} ä¸ªæ—§çš„å‘é‡åˆ†å—")
            else:
                logger.warning(f"æœªæ‰¾åˆ°çŸ¥è¯†æ¡ç›® {item_id} çš„æ—§å‘é‡æ•°æ®")

            # 3. å‡†å¤‡æ›´æ–°åçš„å…ƒæ•°æ®
            # åˆå¹¶æ—§å…ƒæ•°æ®å’Œæ–°çš„æ›´æ–°å­—æ®µ
            updated_metadata = old_metadata.copy()

            # å…è®¸æ›´æ–°çš„å­—æ®µ
            allowed_fields = ['title', 'content', 'tags', 'category', 'priority']
            for key, value in kwargs.items():
                if key in allowed_fields:
                    updated_metadata[key] = value

            # æ›´æ–°æ—¶é—´æˆ³
            updated_metadata["updated_at"] = datetime.now().isoformat()

            # 4. è·å–æ›´æ–°åçš„å†…å®¹ï¼ˆå¦‚æœæ²¡æœ‰æä¾›æ–°å†…å®¹ï¼Œä½¿ç”¨æ—§å†…å®¹ï¼‰
            # æ³¨æ„ï¼šæ—§çš„ content ä¸åœ¨ metadata ä¸­ï¼Œéœ€è¦ä» documents ä¸­è·å–
            if "content" in kwargs:
                new_content = kwargs["content"]
            else:
                # å¦‚æœæ²¡æœ‰æä¾›æ–°å†…å®¹ï¼Œä»æ—§åˆ†å—ä¸­é‡å»ºå†…å®¹
                if old_chunks and old_chunks["documents"]:
                    # å°†æ‰€æœ‰åˆ†å—çš„æ–‡æœ¬åˆå¹¶
                    new_content = " ".join(old_chunks["documents"])
                else:
                    logger.error(f"æ— æ³•è·å–çŸ¥è¯†æ¡ç›® {item_id} çš„å†…å®¹")
                    return False

            # 5. é‡æ–°åˆ†å—å’Œå‘é‡åŒ–
            # å‡†å¤‡ç”¨äºåˆ†å—çš„å…ƒæ•°æ®ï¼ˆä¸åŒ…å« chunk_index å’Œ total_chunksï¼‰
            chunk_metadata = {
                "item_id": item_id,
                "domain": updated_metadata.get("domain", domain),
                "category": updated_metadata.get("category", ""),
                "title": updated_metadata.get("title", ""),
                "tags": updated_metadata.get("tags", []),
                "source": updated_metadata.get("source", "user"),
                "priority": updated_metadata.get("priority", 1),
                "created_at": updated_metadata.get("created_at", ""),
                "updated_at": updated_metadata["updated_at"]
            }

            # æ–‡æœ¬åˆ†å—
            chunks = self.chunker.chunk_text(new_content, chunk_metadata)

            if not chunks:
                logger.warning(f"çŸ¥è¯†æ¡ç›® {item_id} æ›´æ–°ååˆ†å—ä¸ºç©º")
                return False

            # 6. æ‰¹é‡å‘é‡åŒ–
            chunk_texts = [chunk["text"] for chunk in chunks]
            try:
                embeddings = self.embedder.embed_batch(chunk_texts)
            except Exception as e:
                logger.error(f"çŸ¥è¯†æ¡ç›® {item_id} é‡æ–°å‘é‡åŒ–å¤±è´¥: {str(e)}")
                raise

            # 7. å­˜å‚¨æ–°çš„å‘é‡æ•°æ®
            # å‡†å¤‡æ‰¹é‡æ’å…¥çš„æ•°æ®
            ids = []
            documents = []
            metadatas = []
            embeddings_list = []

            for i, (chunk, embedding) in enumerate(zip(chunks, embeddings)):
                chunk_id = f"{item_id}_chunk_{i}"
                ids.append(chunk_id)
                documents.append(chunk["text"])
                metadatas.append(chunk["metadata"])
                embeddings_list.append(embedding)

            # æ‰¹é‡æ’å…¥åˆ° Chroma
            collection.add(
                ids=ids,
                documents=documents,
                metadatas=metadatas,
                embeddings=embeddings_list
            )

            logger.info(
                f"çŸ¥è¯†æ¡ç›® {item_id} æ›´æ–°æˆåŠŸ: {len(chunks)} ä¸ªæ–°åˆ†å—"
            )

            return True

        except Exception as e:
            logger.error(
                f"æ›´æ–°çŸ¥è¯†æ¡ç›® {item_id} å¤±è´¥: {str(e)}",
                exc_info=True
            )
            return False

    def delete_knowledge(self, item_id: str) -> bool:
        """åˆ é™¤çŸ¥è¯†æ¡ç›®.

        æ ¹æ®éœ€æ±‚ 5.3ï¼Œåˆ é™¤çŸ¥è¯†æ¡ç›®æ—¶éœ€è¦ï¼š
        ä» Chroma é›†åˆä¸­åˆ é™¤æ‰€æœ‰ç›¸å…³åˆ†å—

        Args:
            item_id: çŸ¥è¯†æ¡ç›® ID

        Returns:
            æ˜¯å¦åˆ é™¤æˆåŠŸ
        """
        logger.info(f"å¼€å§‹åˆ é™¤çŸ¥è¯†æ¡ç›®: {item_id}")

        try:
            # 1. æŸ¥æ‰¾è¯¥çŸ¥è¯†æ¡ç›®æ‰€å±çš„é¢†åŸŸ
            # é€šè¿‡éå†æ‰€æœ‰é›†åˆæŸ¥æ‰¾åŒ…å«è¯¥ item_id çš„é›†åˆ
            domain = None

            try:
                all_collections = self.chroma_client.list_collections()
                for coll_info in all_collections:
                    coll_name = coll_info.name
                    if coll_name.startswith("knowledge_"):
                        try:
                            collection = self.chroma_client.get_collection(coll_name)
                            # æŸ¥è¯¢è¯¥é›†åˆä¸­æ˜¯å¦æœ‰è¯¥ item_id çš„åˆ†å—
                            results = collection.get(
                                where={"item_id": item_id},
                                limit=1
                            )

                            if results and results["ids"] and len(results["ids"]) > 0:
                                domain = coll_name.replace("knowledge_", "")
                                logger.info(f"æ‰¾åˆ°çŸ¥è¯†æ¡ç›® {item_id} åœ¨é¢†åŸŸ {domain}")
                                break
                        except Exception as e:
                            logger.warning(f"æŸ¥è¯¢é›†åˆ {coll_name} å¤±è´¥: {str(e)}")
                            continue
            except Exception as e:
                logger.error(f"åˆ—å‡ºé›†åˆå¤±è´¥: {str(e)}")
                return False

            if not domain:
                logger.warning(f"çŸ¥è¯†æ¡ç›® {item_id} ä¸å­˜åœ¨")
                return False

            # 2. åˆ é™¤æ‰€æœ‰ç›¸å…³åˆ†å—
            collection = self._get_or_create_collection(domain)

            # æŸ¥æ‰¾æ‰€æœ‰å±äºè¯¥ item_id çš„åˆ†å—
            chunks = collection.get(
                where={"item_id": item_id}
            )

            if chunks and chunks["ids"]:
                chunk_ids = chunks["ids"]
                collection.delete(ids=chunk_ids)
                logger.info(f"æˆåŠŸåˆ é™¤çŸ¥è¯†æ¡ç›® {item_id} çš„ {len(chunk_ids)} ä¸ªåˆ†å—")
                return True
            else:
                logger.warning(f"æœªæ‰¾åˆ°çŸ¥è¯†æ¡ç›® {item_id} çš„åˆ†å—æ•°æ®")
                return False

        except Exception as e:
            logger.error(
                f"åˆ é™¤çŸ¥è¯†æ¡ç›® {item_id} å¤±è´¥: {str(e)}",
                exc_info=True
            )
            return False

    def get_domains(self) -> List[str]:
        """è·å–æ‰€æœ‰é¢†åŸŸåˆ—è¡¨.
        
        Returns:
            é¢†åŸŸåˆ—è¡¨
        """
        try:
            # è·å–æ‰€æœ‰é›†åˆ
            collections = self.chroma_client.list_collections()

            # ä»é›†åˆåç§°ä¸­æå–é¢†åŸŸåç§°
            # é›†åˆåç§°æ ¼å¼: knowledge_{domain}
            domains = []
            for collection in collections:
                if collection.name.startswith("knowledge_"):
                    domain = collection.name[len("knowledge_"):]
                    domains.append(domain)

            return sorted(domains)
        except Exception as e:
            logger.error(f"è·å–é¢†åŸŸåˆ—è¡¨å¤±è´¥: {str(e)}", exc_info=True)
            return []

    def get_categories(self, domain: str = None) -> List[str]:
        """è·å–åˆ†ç±»åˆ—è¡¨.
        
        Args:
            domain: é¢†åŸŸè¿‡æ»¤
            
        Returns:
            åˆ†ç±»åˆ—è¡¨
        """
        try:
            categories = set()

            if domain:
                # è·å–æŒ‡å®šé¢†åŸŸçš„åˆ†ç±»
                collection = self._get_or_create_collection(domain)
                results = collection.get()

                if results and results["metadatas"]:
                    for metadata in results["metadatas"]:
                        if "category" in metadata:
                            categories.add(metadata["category"])
            else:
                # è·å–æ‰€æœ‰é¢†åŸŸçš„åˆ†ç±»
                domains = self.get_domains()
                for d in domains:
                    collection = self._get_or_create_collection(d)
                    results = collection.get()

                    if results and results["metadatas"]:
                        for metadata in results["metadatas"]:
                            if "category" in metadata:
                                categories.add(metadata["category"])

            return sorted(list(categories))
        except Exception as e:
            logger.error(f"è·å–åˆ†ç±»åˆ—è¡¨å¤±è´¥: {str(e)}", exc_info=True)
            return []

    def get_tags(self, domain: str = None) -> List[str]:
        """è·å–æ ‡ç­¾åˆ—è¡¨.
        
        Args:
            domain: é¢†åŸŸè¿‡æ»¤
            
        Returns:
            æ ‡ç­¾åˆ—è¡¨
        """
        try:
            tags = set()

            if domain:
                # è·å–æŒ‡å®šé¢†åŸŸçš„æ ‡ç­¾
                collection = self._get_or_create_collection(domain)
                results = collection.get()

                if results and results["metadatas"]:
                    for metadata in results["metadatas"]:
                        if "tags" in metadata and metadata["tags"]:
                            # tags å¯èƒ½æ˜¯åˆ—è¡¨
                            if isinstance(metadata["tags"], list):
                                tags.update(metadata["tags"])
                            else:
                                tags.add(metadata["tags"])
            else:
                # è·å–æ‰€æœ‰é¢†åŸŸçš„æ ‡ç­¾
                domains = self.get_domains()
                for d in domains:
                    collection = self._get_or_create_collection(d)
                    results = collection.get()

                    if results and results["metadatas"]:
                        for metadata in results["metadatas"]:
                            if "tags" in metadata and metadata["tags"]:
                                # tags å¯èƒ½æ˜¯åˆ—è¡¨
                                if isinstance(metadata["tags"], list):
                                    tags.update(metadata["tags"])
                                else:
                                    tags.add(metadata["tags"])

            return sorted(list(tags))
        except Exception as e:
            logger.error(f"è·å–æ ‡ç­¾åˆ—è¡¨å¤±è´¥: {str(e)}", exc_info=True)
            return []

    def export_knowledge(self, domain: str = None) -> Dict[str, Any]:
        """å¯¼å‡ºçŸ¥è¯†ä¸º JSON æ ¼å¼.

        Args:
            domain: é¢†åŸŸè¿‡æ»¤ï¼ˆå¯é€‰ï¼‰

        Returns:
            åŒ…å«å¯¼å‡ºæ—¶é—´å’ŒçŸ¥è¯†æ¡ç›®åˆ—è¡¨çš„å­—å…¸
        """
        try:
            knowledge_items = []
            seen_item_ids = set()  # ç”¨äºå»é‡ï¼ˆåŒä¸€çŸ¥è¯†æ¡ç›®çš„ä¸åŒåˆ†å—ï¼‰

            # ç¡®å®šè¦å¯¼å‡ºçš„é¢†åŸŸ
            domains_to_export = [domain] if domain else self.get_domains()

            for d in domains_to_export:
                try:
                    collection = self._get_or_create_collection(d)
                    results = collection.get(
                        include=["documents", "metadatas"]
                    )

                    if results and results["ids"]:
                        # æŒ‰ item_id åˆ†ç»„ï¼Œåˆå¹¶åŒä¸€çŸ¥è¯†æ¡ç›®çš„æ‰€æœ‰åˆ†å—
                        item_chunks = {}
                        for i in range(len(results["ids"])):
                            metadata = results["metadatas"][i]
                            document = results["documents"][i]
                            item_id = metadata.get("item_id")

                            if not item_id:
                                continue

                            if item_id not in item_chunks:
                                item_chunks[item_id] = {
                                    "metadata": metadata,
                                    "chunks": []
                                }

                            # æ·»åŠ åˆ†å—å†…å®¹
                            chunk_index = metadata.get("chunk_index", 0)
                            item_chunks[item_id]["chunks"].append({
                                "index": chunk_index,
                                "text": document
                            })

                        # é‡æ„å®Œæ•´çš„çŸ¥è¯†æ¡ç›®
                        for item_id, data in item_chunks.items():
                            if item_id in seen_item_ids:
                                continue
                            seen_item_ids.add(item_id)

                            metadata = data["metadata"]

                            # æŒ‰ chunk_index æ’åºå¹¶åˆå¹¶å†…å®¹
                            sorted_chunks = sorted(data["chunks"], key=lambda x: x["index"])
                            full_content = " ".join(chunk["text"] for chunk in sorted_chunks)

                            # åˆ›å»º KnowledgeItem
                            knowledge_item = KnowledgeItem(
                                id=item_id,
                                domain=metadata.get("domain", d),
                                category=metadata.get("category", ""),
                                title=metadata.get("title", ""),
                                content=full_content,
                                tags=metadata.get("tags", []),
                                created_at=metadata.get("created_at", ""),
                                updated_at=metadata.get("updated_at", ""),
                                source=metadata.get("source", "user"),
                                priority=metadata.get("priority", 1)
                            )

                            knowledge_items.append(knowledge_item.to_dict())

                except Exception as e:
                    logger.warning(f"å¯¼å‡ºé¢†åŸŸ '{d}' çš„çŸ¥è¯†å¤±è´¥: {str(e)}")
                    continue

            logger.info(f"æˆåŠŸå¯¼å‡º {len(knowledge_items)} ä¸ªçŸ¥è¯†æ¡ç›®")

            return {
                "exported_at": datetime.now().isoformat(),
                "knowledge_items": knowledge_items
            }

        except Exception as e:
            logger.error(f"å¯¼å‡ºçŸ¥è¯†å¤±è´¥: {str(e)}", exc_info=True)
            return {
                "exported_at": datetime.now().isoformat(),
                "knowledge_items": []
            }


class DomainKnowledgeManager:
    """Specialized knowledge manager for specific domains."""

    def __init__(self, knowledge_store: "ChromaKnowledgeStore", domain: str):
        self.store = knowledge_store
        self.domain = domain

    def add_troubleshooting_guide(self, title: str, content: str, tags: List[str] = None) -> str:
        """Add a troubleshooting guide for the domain."""
        if tags is None:
            tags = ["troubleshooting"]
        else:
            tags.append("troubleshooting")

        return self.store.add_knowledge(
            domain=self.domain,
            category="troubleshooting",
            title=title,
            content=content,
            tags=tags,
            priority=3
        )

    def add_configuration_guide(self, title: str, content: str, tags: List[str] = None) -> str:
        """Add a configuration guide for the domain."""
        if tags is None:
            tags = ["configuration"]
        else:
            tags.append("configuration")

        return self.store.add_knowledge(
            domain=self.domain,
            category="configuration",
            title=title,
            content=content,
            tags=tags,
            priority=2
        )

    def add_best_practice(self, title: str, content: str, tags: List[str] = None) -> str:
        """Add a best practice for the domain."""
        if tags is None:
            tags = ["best_practices"]
        else:
            tags.append("best_practices")

        return self.store.add_knowledge(
            domain=self.domain,
            category="best_practices",
            title=title,
            content=content,
            tags=tags,
            priority=4
        )

    def add_checker_info(self, checker_name: str, description: str, usage: str,
                         admin_api: str = None, tags: List[str] = None) -> str:
        """Add checker information for the domain."""
        if tags is None:
            tags = ["checker", "diagnostic"]
        else:
            tags.extend(["checker", "diagnostic"])

        content = f"""## {checker_name}

**æè¿°**: {description}

**ä½¿ç”¨åœºæ™¯**: {usage}

"""

        if admin_api:
            content += f"**Admin API**: {admin_api}\n\n"

        return self.store.add_knowledge(
            domain=self.domain,
            category="diagnostic_tools",
            title=f"æ£€æŸ¥å™¨: {checker_name}",
            content=content,
            tags=tags,
            priority=3
        )

    def search_troubleshooting(self, query: str = None, tags: List[str] = None) -> List[KnowledgeItem]:
        """Search troubleshooting guides for the domain."""
        return self.store.search_knowledge(
            query=query,
            domain=self.domain,
            category="troubleshooting",
            tags=tags
        )

    def search_configuration(self, query: str = None, tags: List[str] = None) -> List[KnowledgeItem]:
        """Search configuration guides for the domain."""
        return self.store.search_knowledge(
            query=query,
            domain=self.domain,
            category="configuration",
            tags=tags
        )

    def search_checkers(self, query: str = None) -> List[KnowledgeItem]:
        """Search diagnostic checkers for the domain."""
        return self.store.search_knowledge(
            query=query,
            domain=self.domain,
            category="diagnostic_tools",
            tags=["checker"]
        )

    def get_all_checkers(self) -> List[KnowledgeItem]:
        """Get all diagnostic checkers for the domain."""
        return self.search_checkers()

    def get_common_issues(self) -> List[KnowledgeItem]:
        """Get common issues for the domain."""
        return self.store.search_knowledge(
            domain=self.domain,
            tags=["common", "issue"]
        )

    def export_domain_knowledge(self) -> Dict[str, Any]:
        """Export all knowledge for the domain."""
        return self.store.export_knowledge(domain=self.domain)


# é»˜è®¤ä½¿ç”¨ ChromaKnowledgeStoreï¼ˆæ”¯æŒ RAG å‘é‡æ£€ç´¢ï¼‰
KnowledgeStore = ChromaKnowledgeStore
