"""Text chunking for long documents."""

import logging
from typing import Any, Dict, List

from langchain_text_splitters import RecursiveCharacterTextSplitter
from loguru import logger

class TextChunker:
    """æ–‡æœ¬åˆ†å—å™¨ï¼Œå°†é•¿æ–‡æœ¬åˆ†å‰²ä¸ºè¯­ä¹‰å—."""

    def __init__(self, chunk_size: int = 1000, chunk_overlap: int = 200, 
                 smart_chunking: bool = False, preserve_structure: bool = False):
        """åˆå§‹åŒ–åˆ†å—å™¨.
        
        Args:
            chunk_size: å—å¤§å°ï¼ˆå­—ç¬¦æ•°ï¼‰
            chunk_overlap: å—é‡å å¤§å°ï¼ˆå­—ç¬¦æ•°ï¼‰
            smart_chunking: å¯ç”¨æ™ºèƒ½åˆ†å‰²
            preserve_structure: ä¿æŒæ–‡æ¡£ç»“æ„
        """
        self.chunk_size = chunk_size
        self.chunk_overlap = chunk_overlap
        self.smart_chunking = smart_chunking
        self.preserve_structure = preserve_structure
        self.splitter = None
        self._init_splitter()

    def _init_splitter(self) -> None:
        """åˆå§‹åŒ–æ–‡æœ¬åˆ†å‰²å™¨ï¼Œé…ç½®ä¸­æ–‡å‹å¥½çš„åˆ†éš”ç¬¦."""
        if self.smart_chunking and self.preserve_structure:
            # æ™ºèƒ½åˆ†å‰²ï¼šä¼˜å…ˆä¿æŒæ–‡æ¡£ç»“æ„å®Œæ•´æ€§
            separators = [
                "\n<!-- CHUNK_BOUNDARY -->\n",  # æ‰‹åŠ¨åˆ†å—æ ‡è®°ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
                "\n\n### ",  # ä¸‰çº§æ ‡é¢˜ï¼ˆæ“ä½œæ­¥éª¤ï¼‰
                "\n\n#### ",  # å››çº§æ ‡é¢˜ï¼ˆå…·ä½“ç»„ä»¶ï¼‰
                "\n\n```",  # ä»£ç å—
                "\n\n",  # æ®µè½åˆ†éš”ç¬¦
                "\n### ",  # ä¸‰çº§æ ‡é¢˜ï¼ˆæ— å‰å¯¼æ¢è¡Œï¼‰
                "\n#### ",  # å››çº§æ ‡é¢˜ï¼ˆæ— å‰å¯¼æ¢è¡Œï¼‰
                "\n```",  # ä»£ç å—ï¼ˆæ— å‰å¯¼æ¢è¡Œï¼‰
                "\n",  # æ¢è¡Œç¬¦
                "ã€‚",  # ä¸­æ–‡å¥å·
                "ï¼",  # ä¸­æ–‡æ„Ÿå¹å·
                "ï¼Ÿ",  # ä¸­æ–‡é—®å·
                "ï¼›",  # ä¸­æ–‡åˆ†å·
                ".",  # è‹±æ–‡å¥å·
                "!",  # è‹±æ–‡æ„Ÿå¹å·
                "?",  # è‹±æ–‡é—®å·
                ";",  # è‹±æ–‡åˆ†å·
                "ï¼Œ",  # ä¸­æ–‡é€—å·
                ",",  # è‹±æ–‡é€—å·
                " ",  # ç©ºæ ¼
                "",  # å­—ç¬¦çº§åˆ«åˆ†å‰²
            ]
            logger.info("å¯ç”¨æ™ºèƒ½åˆ†å‰²å’Œç»“æ„ä¿æŒæ¨¡å¼")
        else:
            # æ ‡å‡†åˆ†å‰²ï¼šä½¿ç”¨åŸæœ‰çš„åˆ†éš”ç¬¦
            separators = [
                "\n\n",  # æ®µè½åˆ†éš”ç¬¦
                "\n",  # æ¢è¡Œç¬¦
                "ã€‚",  # ä¸­æ–‡å¥å·
                "ï¼",  # ä¸­æ–‡æ„Ÿå¹å·
                "ï¼Ÿ",  # ä¸­æ–‡é—®å·
                "ï¼›",  # ä¸­æ–‡åˆ†å·
                ".",  # è‹±æ–‡å¥å·
                "!",  # è‹±æ–‡æ„Ÿå¹å·
                "?",  # è‹±æ–‡é—®å·
                ";",  # è‹±æ–‡åˆ†å·
                "ï¼Œ",  # ä¸­æ–‡é€—å·
                ",",  # è‹±æ–‡é€—å·
                " ",  # ç©ºæ ¼
                "",  # å­—ç¬¦çº§åˆ«åˆ†å‰²
            ]
            
        # ä½¿ç”¨é€’å½’å­—ç¬¦åˆ†å‰²ç­–ç•¥ï¼Œä¼˜å…ˆåœ¨æ®µè½ã€å¥å­è¾¹ç•Œå¤„åˆ†å—
        # åˆ†éš”ç¬¦æŒ‰ä¼˜å…ˆçº§æ’åºï¼šæ®µè½ > å¥å­ > æ ‡ç‚¹ > ç©ºæ ¼ > å­—ç¬¦
        self.splitter = RecursiveCharacterTextSplitter(
            chunk_size=self.chunk_size,
            chunk_overlap=self.chunk_overlap,
            separators=separators,
            keep_separator=True,  # ä¿ç•™åˆ†éš”ç¬¦
            length_function=len,
        )
        
        # æ·»åŠ è°ƒè¯•ä¿¡æ¯
        if self.smart_chunking and self.preserve_structure:
            logger.info(f"æ™ºèƒ½åˆ†å‰²åˆ†éš”ç¬¦: {separators[:5]}...")  # åªæ˜¾ç¤ºå‰5ä¸ª
        
        logger.info(
            f"æ–‡æœ¬åˆ†å—å™¨åˆå§‹åŒ–å®Œæˆ: chunk_size={self.chunk_size}, "
            f"chunk_overlap={self.chunk_overlap}, "
            f"smart_chunking={self.smart_chunking}, "
            f"preserve_structure={self.preserve_structure}"
        )

    def chunk_text(self, text: str, metadata: Dict[str, Any]) -> List[Dict[str, Any]]:
        """åˆ†å—æ–‡æœ¬å¹¶ä¿ç•™å…ƒæ•°æ®.
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            metadata: å…ƒæ•°æ®ï¼ˆid, domain, category, title, tags ç­‰ï¼‰
            
        Returns:
            åˆ†å—ç»“æœåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« text å’Œ metadata
            å¦‚æœæ–‡æœ¬é•¿åº¦ä¸è¶…è¿‡ chunk_sizeï¼Œè¿”å›å•ä¸ªå—
        """
        if not text or not text.strip():
            logger.warning("å°è¯•åˆ†å—ç©ºæ–‡æœ¬ï¼Œè¿”å›ç©ºåˆ—è¡¨")
            return []

        # æ£€æµ‹æ˜¯å¦åŒ…å«æ‰‹åŠ¨åˆ†å—æ ‡è®°
        if "<!-- CHUNK_BOUNDARY -->" in text:
            logger.info(f"æ£€æµ‹åˆ°æ‰‹åŠ¨åˆ†å—æ ‡è®° CHUNK_BOUNDARYï¼Œæ–‡æ¡£: {metadata.get('title', 'Unknown')}")
            chunk_count = text.count("<!-- CHUNK_BOUNDARY -->")
            logger.info(f"CHUNK_BOUNDARY æ ‡è®°æ•°é‡: {chunk_count}")

        # å¦‚æœæ–‡æœ¬é•¿åº¦ä¸è¶…è¿‡ chunk_sizeï¼Œä¸éœ€è¦åˆ†å—
        if len(text) <= self.chunk_size:
            logger.debug(f"æ–‡æœ¬é•¿åº¦ {len(text)} ä¸è¶…è¿‡ chunk_size {self.chunk_size}ï¼Œä¸åˆ†å—")
            return [{
                "text": text,
                "metadata": {
                    **metadata,
                    "chunk_index": 0,
                    "total_chunks": 1,
                }
            }]

        # ä½¿ç”¨æ™ºèƒ½åˆ†å—æˆ–æ ‡å‡†åˆ†å—
        try:
            if self.smart_chunking and self.preserve_structure:
                chunks = self._smart_chunk_text(text)
            else:
                chunks = self.splitter.split_text(text)
                
            logger.info(f"æ–‡æœ¬åˆ†å—å®Œæˆ: åŸå§‹é•¿åº¦={len(text)}, åˆ†å—æ•°={len(chunks)}")

            # æ‰“å°åŸå§‹åˆ†å—çš„è¯¦ç»†ä¿¡æ¯
            logger.debug("=== åŸå§‹åˆ†å—è¯¦æƒ… ===")
            for i, chunk in enumerate(chunks):
                chunk_preview = chunk.replace('\n', '\\n')[:100]
                logger.debug(f"åŸå§‹Chunk {i+1}: é•¿åº¦={len(chunk)}, é¢„è§ˆ='{chunk_preview}...'")
                if "<!-- CHUNK_BOUNDARY -->" in chunk:
                    logger.debug(f"  âš ï¸ Chunk {i+1} åŒ…å«CHUNK_BOUNDARYæ ‡è®°")

            # ä¸ºæ¯ä¸ªåˆ†å—æ·»åŠ å…ƒæ•°æ®
            result = []
            for i, chunk in enumerate(chunks):
                # è¿‡æ»¤æ‰åªåŒ…å«CHUNK_BOUNDARYæ ‡è®°çš„ç©ºchunk
                clean_chunk = chunk.replace("<!-- CHUNK_BOUNDARY -->", "").strip()
                if len(clean_chunk) < 10:  # è¿‡æ»¤æ‰å†…å®¹å¤ªå°‘çš„chunk
                    logger.debug(f"è·³è¿‡å†…å®¹è¿‡å°‘çš„chunk {i+1}: {len(clean_chunk)} å­—ç¬¦, å†…å®¹='{clean_chunk}'")
                    continue
                    
                result.append({
                    "text": chunk,
                    "metadata": {
                        **metadata,  # ä¿ç•™åŸå§‹å…ƒæ•°æ®
                        "chunk_index": len(result),  # é‡æ–°ç¼–å·
                        "total_chunks": len(chunks),  # æš‚æ—¶ä½¿ç”¨åŸå§‹æ•°é‡ï¼Œåé¢ä¼šæ›´æ–°
                    }
                })

            # æ›´æ–°æ€»chunkæ•°é‡
            for item in result:
                item["metadata"]["total_chunks"] = len(result)

            # æ‰“å°æœ€ç»ˆåˆ†å—çš„è¯¦ç»†ä¿¡æ¯
            logger.debug("=== æœ€ç»ˆåˆ†å—è¯¦æƒ… ===")
            for i, item in enumerate(result):
                chunk = item["text"]
                chunk_preview = chunk.replace('\n', '\\n')
                has_boundary = "<!-- CHUNK_BOUNDARY -->" in chunk
                logger.debug(f"æœ€ç»ˆChunk {i+1}: é•¿åº¦={len(chunk)}, BOUNDARY={has_boundary}")
                logger.debug(f"  å…¨éƒ¨chunkå†…å®¹: {chunk_preview}")
                
                # å¦‚æœchunkåŒ…å«æ ‡é¢˜ï¼Œç‰¹åˆ«æ ‡æ³¨
                if any(marker in chunk for marker in ["####", "###", "**æ­¥éª¤"]):
                    titles = []
                    if "####" in chunk:
                        titles.append("å››çº§æ ‡é¢˜")
                    if "###" in chunk:
                        titles.append("ä¸‰çº§æ ‡é¢˜")
                    if "**æ­¥éª¤" in chunk:
                        titles.append("æ­¥éª¤æ ‡è®°")
                    logger.debug(f"  ğŸ“‹ åŒ…å«ç»“æ„: {', '.join(titles)}")

            logger.info(f"è¿‡æ»¤åçš„åˆ†å—æ•°é‡: {len(result)} (åŸå§‹: {len(chunks)})")
            return result

        except Exception as e:
            logger.error(f"æ–‡æœ¬åˆ†å—å¤±è´¥: {str(e)}", exc_info=True)
            # åˆ†å—å¤±è´¥æ—¶ï¼Œè¿”å›æ•´ä¸ªæ–‡æœ¬ä½œä¸ºå•ä¸ªå—
            logger.warning("åˆ†å—å¤±è´¥ï¼Œè¿”å›æ•´ä¸ªæ–‡æœ¬ä½œä¸ºå•ä¸ªå—")
            return [{
                "text": text,
                "metadata": {
                    **metadata,
                    "chunk_index": 0,
                    "total_chunks": 1,
                }
            }]

    def _smart_chunk_text(self, text: str) -> List[str]:
        """æ™ºèƒ½åˆ†å—æ–‡æœ¬ï¼Œä¿æŒæ“ä½œæµç¨‹çš„å®Œæ•´æ€§.
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            
        Returns:
            åˆ†å—ç»“æœåˆ—è¡¨
        """
        import re
        
        # æ£€æµ‹æ“ä½œæµç¨‹æ¨¡å¼
        operation_patterns = [
            r'#### .+?\n.*?æ­¥éª¤1.*?æ­¥éª¤2.*?(?=####|$)',  # å®Œæ•´çš„æ“ä½œæµç¨‹
            r'### .+?\n.*?æ­¥éª¤1.*?æ­¥éª¤2.*?(?=###|$)',   # ä¸‰çº§æ ‡é¢˜çš„æ“ä½œæµç¨‹
        ]
        
        # æŸ¥æ‰¾æ“ä½œæµç¨‹å—
        operation_blocks = []
        remaining_text = text
        
        for pattern in operation_patterns:
            matches = re.finditer(pattern, text, re.DOTALL | re.MULTILINE)
            for match in matches:
                start, end = match.span()
                operation_blocks.append({
                    'start': start,
                    'end': end,
                    'text': match.group(),
                    'type': 'operation_flow'
                })
        
        # å¦‚æœæ‰¾åˆ°æ“ä½œæµç¨‹ï¼Œç‰¹æ®Šå¤„ç†
        if operation_blocks:
            logger.info(f"æ£€æµ‹åˆ° {len(operation_blocks)} ä¸ªæ“ä½œæµç¨‹å—ï¼Œä½¿ç”¨æ™ºèƒ½åˆ†å‰²")
            logger.debug("=== æ“ä½œæµç¨‹å—è¯¦æƒ… ===")
            for i, block in enumerate(operation_blocks):
                block_preview = block['text'].replace('\n', '\\n')[:100]
                logger.debug(f"æ“ä½œå— {i+1}: ä½ç½®={block['start']}-{block['end']}, é•¿åº¦={len(block['text'])}")
                logger.debug(f"  é¢„è§ˆ: '{block_preview}...'")
            return self._chunk_with_operation_blocks(text, operation_blocks)
        else:
            logger.debug("æœªæ£€æµ‹åˆ°æ“ä½œæµç¨‹æ¨¡å¼ï¼Œä½¿ç”¨æ ‡å‡†åˆ†å‰²")
            # æ²¡æœ‰ç‰¹æ®Šç»“æ„ï¼Œä½¿ç”¨æ ‡å‡†åˆ†å‰²
            return self.splitter.split_text(text)
    
    def _chunk_with_operation_blocks(self, text: str, operation_blocks: List[Dict]) -> List[str]:
        """å¤„ç†åŒ…å«æ“ä½œæµç¨‹çš„æ–‡æœ¬åˆ†å—.
        
        Args:
            text: åŸå§‹æ–‡æœ¬
            operation_blocks: æ“ä½œæµç¨‹å—åˆ—è¡¨
            
        Returns:
            åˆ†å—ç»“æœåˆ—è¡¨
        """
        chunks = []
        last_end = 0
        
        # æŒ‰ä½ç½®æ’åºæ“ä½œå—
        operation_blocks.sort(key=lambda x: x['start'])
        
        logger.debug("=== æ“ä½œæµç¨‹å—å¤„ç†è¿‡ç¨‹ ===")
        
        for i, block in enumerate(operation_blocks):
            # æ·»åŠ æ“ä½œå—ä¹‹å‰çš„æ–‡æœ¬
            if block['start'] > last_end:
                before_text = text[last_end:block['start']].strip()
                if before_text:
                    logger.debug(f"å¤„ç†æ“ä½œå— {i+1} ä¹‹å‰çš„æ–‡æœ¬: é•¿åº¦={len(before_text)}")
                    # å¯¹å‰é¢çš„æ–‡æœ¬ä½¿ç”¨æ ‡å‡†åˆ†å‰²
                    before_chunks = self.splitter.split_text(before_text)
                    logger.debug(f"  æ ‡å‡†åˆ†å‰²äº§ç”Ÿ {len(before_chunks)} ä¸ªchunk")
                    for j, chunk in enumerate(before_chunks):
                        logger.debug(f"    å‰ç½®Chunk {j+1}: é•¿åº¦={len(chunk)}")
                    chunks.extend(before_chunks)
            
            # å¤„ç†æ“ä½œæµç¨‹å—
            operation_text = block['text']
            logger.debug(f"å¤„ç†æ“ä½œæµç¨‹å— {i+1}: é•¿åº¦={len(operation_text)}")
            
            if len(operation_text) <= self.chunk_size:
                # æ“ä½œæµç¨‹å—ä¸è¶…è¿‡å¤§å°é™åˆ¶ï¼Œä¿æŒå®Œæ•´
                chunks.append(operation_text)
                logger.debug(f"  âœ… ä¿æŒæ“ä½œæµç¨‹å—å®Œæ•´: {len(operation_text)} å­—ç¬¦")
            else:
                # æ“ä½œæµç¨‹å—å¤ªå¤§ï¼Œéœ€è¦åˆ†å‰²ï¼Œä½†å°½é‡åœ¨æ­¥éª¤è¾¹ç•Œåˆ†å‰²
                logger.debug(f"  âš ï¸ æ“ä½œæµç¨‹å—è¿‡å¤§ï¼Œéœ€è¦åˆ†å‰²: {len(operation_text)} > {self.chunk_size}")
                operation_chunks = self._split_operation_block(operation_text)
                logger.debug(f"  åˆ†å‰²ä¸º {len(operation_chunks)} ä¸ªå­å—")
                for j, chunk in enumerate(operation_chunks):
                    logger.debug(f"    æ“ä½œå­å— {j+1}: é•¿åº¦={len(chunk)}")
                chunks.extend(operation_chunks)
            
            last_end = block['end']
        
        # æ·»åŠ æœ€åå‰©ä½™çš„æ–‡æœ¬
        if last_end < len(text):
            remaining_text = text[last_end:].strip()
            if remaining_text:
                logger.debug(f"å¤„ç†å‰©ä½™æ–‡æœ¬: é•¿åº¦={len(remaining_text)}")
                remaining_chunks = self.splitter.split_text(remaining_text)
                logger.debug(f"  æ ‡å‡†åˆ†å‰²äº§ç”Ÿ {len(remaining_chunks)} ä¸ªchunk")
                for j, chunk in enumerate(remaining_chunks):
                    logger.debug(f"    å‰©ä½™Chunk {j+1}: é•¿åº¦={len(chunk)}")
                chunks.extend(remaining_chunks)
        
        logger.debug(f"æ“ä½œæµç¨‹å¤„ç†å®Œæˆï¼Œæ€»å…±äº§ç”Ÿ {len(chunks)} ä¸ªchunk")
        return chunks
    
    def _split_operation_block(self, operation_text: str) -> List[str]:
        """åˆ†å‰²å¤§çš„æ“ä½œæµç¨‹å—ï¼Œå°½é‡ä¿æŒæ­¥éª¤å®Œæ•´æ€§.
        
        Args:
            operation_text: æ“ä½œæµç¨‹æ–‡æœ¬
            
        Returns:
            åˆ†å—ç»“æœåˆ—è¡¨
        """
        import re
        
        logger.debug("=== æ“ä½œæµç¨‹å—åˆ†å‰²è¯¦æƒ… ===")
        logger.debug(f"åŸå§‹æ“ä½œå—é•¿åº¦: {len(operation_text)}")
        
        # å°è¯•åœ¨æ­¥éª¤è¾¹ç•Œåˆ†å‰²
        step_pattern = r'\n\*\*æ­¥éª¤\d+[ï¼š:][^*]*?(?=\n\*\*æ­¥éª¤\d+[ï¼š:]|\n\*\*|$)'
        steps = re.findall(step_pattern, operation_text, re.DOTALL)
        
        logger.debug(f"æ£€æµ‹åˆ°æ­¥éª¤æ•°é‡: {len(steps)}")
        for i, step in enumerate(steps):
            step_preview = step.replace('\n', '\\n')[:80]
            logger.debug(f"  æ­¥éª¤ {i+1}: é•¿åº¦={len(step)}, é¢„è§ˆ='{step_preview}...'")
        
        if len(steps) >= 2:
            # æ‰¾åˆ°å¤šä¸ªæ­¥éª¤ï¼Œå°è¯•ç»„åˆ
            logger.debug("æ‰¾åˆ°å¤šä¸ªæ­¥éª¤ï¼ŒæŒ‰æ­¥éª¤è¾¹ç•Œåˆ†å‰²")
            chunks = []
            current_chunk = ""
            
            # æ·»åŠ æ ‡é¢˜éƒ¨åˆ†ï¼ˆæ­¥éª¤ä¹‹å‰çš„å†…å®¹ï¼‰
            title_match = re.match(r'^(.*?)(?=\n\*\*æ­¥éª¤)', operation_text, re.DOTALL)
            if title_match:
                title_part = title_match.group(1).strip()
                current_chunk = title_part
                logger.debug(f"æ ‡é¢˜éƒ¨åˆ†: é•¿åº¦={len(title_part)}")
            
            for i, step in enumerate(steps):
                step_text = step.strip()
                # æ£€æŸ¥æ·»åŠ è¿™ä¸ªæ­¥éª¤æ˜¯å¦ä¼šè¶…è¿‡å¤§å°é™åˆ¶
                combined_length = len(current_chunk + "\n\n" + step_text)
                logger.debug(f"å°è¯•æ·»åŠ æ­¥éª¤ {i+1}: å½“å‰é•¿åº¦={len(current_chunk)}, æ­¥éª¤é•¿åº¦={len(step_text)}, åˆå¹¶å={combined_length}")
                
                if combined_length <= self.chunk_size:
                    if current_chunk:
                        current_chunk += "\n\n" + step_text
                    else:
                        current_chunk = step_text
                    logger.debug(f"  âœ… æˆåŠŸæ·»åŠ æ­¥éª¤ {i+1}ï¼Œå½“å‰chunké•¿åº¦={len(current_chunk)}")
                else:
                    # è¶…è¿‡é™åˆ¶ï¼Œä¿å­˜å½“å‰å—å¹¶å¼€å§‹æ–°å—
                    if current_chunk:
                        chunks.append(current_chunk)
                        logger.debug(f"  ğŸ’¾ ä¿å­˜å½“å‰chunk: é•¿åº¦={len(current_chunk)}")
                    current_chunk = step_text
                    logger.debug(f"  ğŸ†• å¼€å§‹æ–°chunkï¼Œæ­¥éª¤ {i+1}: é•¿åº¦={len(step_text)}")
            
            # æ·»åŠ æœ€åä¸€ä¸ªå—
            if current_chunk:
                chunks.append(current_chunk)
                logger.debug(f"ğŸ’¾ ä¿å­˜æœ€åä¸€ä¸ªchunk: é•¿åº¦={len(current_chunk)}")
            
            logger.debug(f"æ“ä½œæµç¨‹å—æŒ‰æ­¥éª¤åˆ†å‰²ä¸º {len(chunks)} ä¸ªå—")
            for i, chunk in enumerate(chunks):
                chunk_preview = chunk.replace('\n', '\\n')[:100]
                logger.debug(f"  ç»“æœChunk {i+1}: é•¿åº¦={len(chunk)}, é¢„è§ˆ='{chunk_preview}...'")
            return chunks
        else:
            # æ²¡æœ‰æ‰¾åˆ°æ­¥éª¤ç»“æ„ï¼Œä½¿ç”¨æ ‡å‡†åˆ†å‰²
            logger.debug("æœªæ‰¾åˆ°æ­¥éª¤ç»“æ„ï¼Œä½¿ç”¨æ ‡å‡†åˆ†å‰²")
            standard_chunks = self.splitter.split_text(operation_text)
            logger.debug(f"æ ‡å‡†åˆ†å‰²äº§ç”Ÿ {len(standard_chunks)} ä¸ªchunk")
            for i, chunk in enumerate(standard_chunks):
                logger.debug(f"  æ ‡å‡†Chunk {i+1}: é•¿åº¦={len(chunk)}")
            return standard_chunks
