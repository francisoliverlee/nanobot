"""
RocketMQ Knowledge Initialization

This module provides built-in RocketMQ knowledge that will be automatically loaded
when the knowledge system is initialized.
"""

import json
import re
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional
from .store import ChromaKnowledgeStore, DomainKnowledgeManager

# Version control for RocketMQ knowledge
ROCKETMQ_KNOWLEDGE_VERSION = "1.0.0"


def get_rocketmq_content_files(base_path: Path) -> List[Path]:
    """Get list of RocketMQ knowledge content files."""
    knowledge_dir = base_path / "knowledge"
    if not knowledge_dir.exists():
        return []
    
    # Find all markdown files in knowledge directory
    md_files = []
    for pattern in ["**/*.md", "**/*.MD"]:
        md_files.extend(knowledge_dir.glob(pattern))
    
    return md_files


def parse_markdown_file(file_path: Path) -> Dict[str, Any]:
    """Parse markdown file and extract title, content, and metadata."""
    import logging
    logger = logging.getLogger("nanobot.knowledge.rocketmq_init")
    
    if not file_path.exists():
        logger.warning(f"âš ï¸  æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return {}
    
    try:
        logger.info(f"ðŸ“– å¼€å§‹è§£æž Markdown æ–‡ä»¶: {file_path.absolute()}")
        content = file_path.read_text(encoding='utf-8')
        
        # Extract title from first heading
        title_match = re.search(r'^#\s+(.+)$', content, re.MULTILINE)
        title = title_match.group(1).strip() if title_match else file_path.stem
        
        # Extract tags from file content or path
        tags = []
        
        # Add category as tag based on directory structure
        parent_dir = file_path.parent.name
        if parent_dir and not parent_dir.startswith('20'):  # Skip date directories
            category_tag = parent_dir.replace('-', ' ').title()
            tags.append(category_tag)
            logger.debug(f"   - æ·»åŠ åˆ†ç±»æ ‡ç­¾: {category_tag}")
        
        # Add file name keywords as tags
        filename_keywords = re.findall(r'[A-Z][a-z]*|[a-z]+|[A-Z]+', file_path.stem)
        file_tags = [kw.lower() for kw in filename_keywords if len(kw) > 2]
        tags.extend(file_tags)
        
        if file_tags:
            logger.debug(f"   - æ·»åŠ æ–‡ä»¶åæ ‡ç­¾: {', '.join(file_tags)}")
        
        # ç»Ÿè®¡å†…å®¹ä¿¡æ¯
        content_length = len(content)
        line_count = content.count('\n') + 1
        
        logger.info(f"âœ… æ–‡ä»¶è§£æžæˆåŠŸ: {title[:30]}...")
        logger.info(f"   - æ–‡ä»¶è·¯å¾„: {file_path.absolute()}")
        logger.info(f"   - æ–‡ä»¶å¤§å°: {content_length} å­—ç¬¦")
        logger.info(f"   - è¡Œæ•°: {line_count}")
        logger.info(f"   - æ ‡ç­¾æ•°: {len(tags)}")
        logger.debug(f"   - æ ‡é¢˜: {title}")
        logger.debug(f"   - å†…å®¹å‰100å­—ç¬¦: {content[:100].replace(chr(10), ' ')}...")
        
        return {
            "title": title,
            "content": content,
            "tags": tags,
            "file_path": str(file_path.absolute())
        }
    except Exception as e:
        logger.error(f"âŒ æ–‡ä»¶è§£æžå¤±è´¥: {file_path.absolute()}")
        logger.error(f"   é”™è¯¯è¯¦æƒ…: {str(e)}")
        return {}


def get_knowledge_categories(base_path: Path) -> Dict[str, List[Dict]]:
    """Organize knowledge files by category based on directory structure."""
    import logging
    logger = logging.getLogger("nanobot.knowledge.rocketmq_init")
    
    knowledge_dir = base_path / "knowledge"
    logger.info(f"ðŸ“‚ æ‰«æçŸ¥è¯†æ–‡ä»¶ç›®å½•...")
    logger.info(f"   - åŸºç¡€è·¯å¾„: {base_path}")
    logger.info(f"   - çŸ¥è¯†ç›®å½•: {knowledge_dir}")
    logger.info(f"   - ç›®å½•å­˜åœ¨: {knowledge_dir.exists()}")
    
    if not knowledge_dir.exists():
        logger.warning("âš ï¸  çŸ¥è¯†ç›®å½•ä¸å­˜åœ¨ï¼Œè¿”å›žç©ºå­—å…¸")
        return {}
    
    categories = {}
    total_files = 0
    
    # é€’å½’æ‰«ææ‰€æœ‰å­ç›®å½•ä¸­çš„ Markdown æ–‡ä»¶
    logger.info(f"ðŸ” å¼€å§‹é€’å½’æ‰«æçŸ¥è¯†ç›®å½•åŠå…¶æ‰€æœ‰å­ç›®å½•...")
    
    # ä½¿ç”¨ glob é€’å½’æŸ¥æ‰¾æ‰€æœ‰ Markdown æ–‡ä»¶
    md_files = list(knowledge_dir.glob("**/*.md")) + list(knowledge_dir.glob("**/*.MD"))
    logger.info(f"ðŸ“„ æ‰¾åˆ° {len(md_files)} ä¸ª Markdown æ–‡ä»¶")
    
    # æŒ‰ç›®å½•ç»“æž„åˆ†ç±»æ–‡ä»¶
    file_groups = {}
    for md_file in md_files:
        # èŽ·å–ç›¸å¯¹äºŽçŸ¥è¯†ç›®å½•çš„ç›¸å¯¹è·¯å¾„
        relative_path = md_file.relative_to(knowledge_dir)
        
        # æå–åˆ†ç±»ä¿¡æ¯ï¼šä½¿ç”¨çˆ¶ç›®å½•åä½œä¸ºåˆ†ç±»ï¼Œå¦‚æžœæœ‰å¤šå±‚ç›®å½•åˆ™ä½¿ç”¨æœ€åŽä¸¤çº§
        parts = list(relative_path.parent.parts)
        
        if len(parts) >= 2:
            # å¦‚æžœæœ‰æ—¥æœŸç›®å½•å’Œåˆ†ç±»ç›®å½•ï¼Œä½¿ç”¨åˆ†ç±»ç›®å½•å
            category_name = parts[-1]  # æœ€åŽä¸€çº§ç›®å½•å
        elif len(parts) == 1:
            # å¦‚æžœåªæœ‰ä¸€çº§ç›®å½•ï¼Œä½¿ç”¨è¯¥ç›®å½•å
            category_name = parts[0]
        else:
            # å¦‚æžœåœ¨æ ¹ç›®å½•ï¼Œä½¿ç”¨ "general"
            category_name = "general"
        
        # è·³è¿‡ä»¥ _ å¼€å¤´çš„ç›®å½•ï¼ˆå…ƒæ•°æ®ç›®å½•ï¼‰
        if category_name.startswith('_'):
            logger.debug(f"   - è·³è¿‡å…ƒæ•°æ®ç›®å½•: {category_name}")
            continue
            
        if category_name not in file_groups:
            file_groups[category_name] = []
        file_groups[category_name].append(md_file)
    
    logger.info(f"ðŸ“‚ æŒ‰ç›®å½•ç»“æž„åˆ†ç±»: {len(file_groups)} ä¸ªåˆ†ç±»")
    logger.info(f"   - åˆ†ç±»åˆ—è¡¨: {list(file_groups.keys())}")
    
    # å¤„ç†æ¯ä¸ªåˆ†ç±»çš„æ–‡ä»¶
    for category_name, files in file_groups.items():
        logger.info(f"ðŸ“‚ å¼€å§‹å¤„ç†åˆ†ç±»: {category_name}")
        logger.info(f"   - æ–‡ä»¶æ•°: {len(files)}")
        logger.info(f"   - æ–‡ä»¶åˆ—è¡¨: {[f.name for f in files]}")
        
        category_file_count = 0
        
        for md_file in files:
            logger.info(f"ðŸ“„ å¼€å§‹å¤„ç†çŸ¥è¯†æ–‡ä»¶: {md_file.absolute()}")
            knowledge_item = parse_markdown_file(md_file)
            if knowledge_item:
                if category_name not in categories:
                    categories[category_name] = []
                categories[category_name].append(knowledge_item)
                total_files += 1
                category_file_count += 1
                logger.info(f"âœ… æ–‡ä»¶è§£æžæˆåŠŸ: {md_file.name} -> {knowledge_item['title'][:30]}...")
                logger.info(f"   - æ–‡ä»¶è·¯å¾„: {md_file.absolute()}")
                logger.info(f"   - æ ‡é¢˜: {knowledge_item['title']}")
                logger.info(f"   - æ ‡ç­¾æ•°: {len(knowledge_item.get('tags', []))}")
            else:
                logger.warning(f"âš ï¸  æ–‡ä»¶è§£æžå¤±è´¥: {md_file.absolute()}")
        
        logger.info(f"âœ… åˆ†ç±» '{category_name}' å¤„ç†å®Œæˆ: {category_file_count}/{len(files)} ä¸ªæ–‡ä»¶æˆåŠŸ")
    
    logger.info(f"âœ… çŸ¥è¯†æ–‡ä»¶æ‰«æå®Œæˆ:")
    logger.info(f"   - æ‰¾åˆ°åˆ†ç±»æ•°: {len(categories)}")
    logger.info(f"   - æ€»æ–‡ä»¶æ•°: {total_files}")
    logger.info(f"   - å„åˆ†ç±»æ–‡ä»¶æ•°: {', '.join([f'{cat}:{len(items)}' for cat, items in categories.items()])}")
    
    # å¦‚æžœæ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ–‡ä»¶ï¼Œè®°å½•è­¦å‘Š
    if total_files == 0:
        logger.warning("âš ï¸  æœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„çŸ¥è¯†æ–‡ä»¶")
        logger.warning(f"   - æ‰«æè·¯å¾„: {knowledge_dir.absolute()}")
        logger.warning(f"   - æ”¯æŒçš„æ–‡ä»¶ç±»åž‹: *.md, *.MD")
    
    return categories


class RocketMQKnowledgeInitializer:
    """Initializer for built-in RocketMQ knowledge."""
    
    def __init__(self, knowledge_store):
        """åˆå§‹åŒ– RocketMQ çŸ¥è¯†åˆå§‹åŒ–å™¨.
        
        Args:
            knowledge_store: KnowledgeStore æˆ– ChromaKnowledgeStore å®žä¾‹
        """
        self.store = knowledge_store
        self.domain = "rocketmq"
        self.initialized_count = 0
        self.chunk_count = 0
        
        # æ£€æµ‹æ˜¯å¦ä¸º ChromaKnowledgeStoreï¼ˆæ”¯æŒå‘é‡åŒ–ï¼‰
        self.is_chroma_store = hasattr(knowledge_store, 'embedder') and hasattr(knowledge_store, 'chunker')
        
        # å¦‚æžœä¸æ˜¯ ChromaKnowledgeStoreï¼Œä½¿ç”¨ DomainKnowledgeManager
        if not self.is_chroma_store:
            self.manager = DomainKnowledgeManager(knowledge_store, self.domain)
        
        # èŽ·å–åŸºç¡€è·¯å¾„
        if hasattr(knowledge_store, 'workspace'):
            self.base_path = knowledge_store.workspace.parent
        else:
            self.base_path = Path.cwd()
    
    def initialize(self):
        """Initialize built-in RocketMQ knowledge from file system.
        
        Returns:
            å¦‚æžœæ˜¯ ChromaKnowledgeStore: (item_count, chunk_count)
            å¦‚æžœæ˜¯å…¶ä»–å­˜å‚¨ç±»åž‹: item_count
        """
        import logging
        logger = logging.getLogger("nanobot.knowledge.rocketmq_init")
        
        logger.info(f"ðŸš€ å¼€å§‹åˆå§‹åŒ– RocketMQ çŸ¥è¯†åº“")
        logger.info(f"   - å­˜å‚¨ç±»åž‹: ChromaKnowledgeStore (å‘é‡åŒ–)")
        logger.info(f"   - åŸºç¡€è·¯å¾„: {self.base_path}")
        
        self.initialized_count = 0
        self.chunk_count = 0
        
        # Load knowledge from file system
        logger.info("ðŸ“‚ æ­£åœ¨åŠ è½½çŸ¥è¯†æ–‡ä»¶...")
        categories = get_knowledge_categories(self.base_path)
        
        if not categories:
            logger.warning("âš ï¸  æœªæ‰¾åˆ°çŸ¥è¯†æ–‡ä»¶ï¼Œä½¿ç”¨å†…ç½®çŸ¥è¯†ä½œä¸ºå¤‡é€‰")
            # Fallback to embedded knowledge if no files found
            self._initialize_embedded_knowledge()
        else:
            logger.info(f"âœ… æ‰¾åˆ° {len(categories)} ä¸ªçŸ¥è¯†ç±»åˆ«ï¼Œå…± {sum(len(items) for items in categories.values())} ä¸ªçŸ¥è¯†æ¡ç›®")
            # Initialize from file system
            self._initialize_from_filesystem(categories)
        
        logger.info(f"ðŸŽ‰ RocketMQ çŸ¥è¯†åº“åˆå§‹åŒ–å®Œæˆ:")
        logger.info(f"ðŸ“Š åˆå§‹åŒ–ç»“æžœç»Ÿè®¡:")
        logger.info(f"   - å­˜å‚¨ç±»åž‹: ChromaKnowledgeStore (å‘é‡åŒ–)")
        logger.info(f"   - åˆå§‹åŒ–çŸ¥è¯†æ¡ç›®æ•°: {self.initialized_count}")
        if self.is_chroma_store:
            logger.info(f"   - å‘é‡åŒ–æ–‡æœ¬å—æ•°: {self.chunk_count}")
            logger.info(f"   - å¹³å‡æ¯ä¸ªæ¡ç›®åˆ†å—æ•°: {self.chunk_count / self.initialized_count if self.initialized_count > 0 else 0:.1f}")
        logger.info(f"   - åŸºç¡€è·¯å¾„: {self.base_path}")
        logger.info(f"   - çŸ¥è¯†åŸŸ: {self.domain}")
        logger.info(f"   - åˆå§‹åŒ–æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        if self.initialized_count == 0:
            logger.warning("âš ï¸  è­¦å‘Š: æœªæˆåŠŸåˆå§‹åŒ–ä»»ä½•çŸ¥è¯†æ¡ç›®")
        else:
            logger.info("âœ… çŸ¥è¯†åº“åˆå§‹åŒ–æˆåŠŸï¼Œå¯ä»¥å¼€å§‹ä½¿ç”¨çŸ¥è¯†æœç´¢åŠŸèƒ½")
        
        if self.is_chroma_store:
            return self.initialized_count, self.chunk_count
        else:
            return self.initialized_count
    
    def _increment_count(self) -> None:
        """Increment the initialization counter."""
        self.initialized_count += 1
    
    def _initialize_from_filesystem(self, categories: Dict[str, List[Dict]]) -> None:
        """Initialize knowledge from file system categories."""
        import logging
        logger = logging.getLogger("nanobot.knowledge.rocketmq_init")
        
        logger.info("ðŸ“ å¼€å§‹å¤„ç†çŸ¥è¯†æ–‡ä»¶...")
        
        for category_name, knowledge_items in categories.items():
            logger.info(f"ðŸ“ å¤„ç†ç±»åˆ« '{category_name}': {len(knowledge_items)} ä¸ªæ¡ç›®")
            
            for i, item in enumerate(knowledge_items, 1):
                # Determine knowledge type based on category and content
                knowledge_type = self._determine_knowledge_type(category_name, item["content"])
                
                logger.info(f"ðŸ”§ æ­£åœ¨åˆå§‹åŒ–çŸ¥è¯†æ¡ç›® {i}/{len(knowledge_items)}: {item['title'][:50]}...")
                logger.debug(f"   - çŸ¥è¯†ç±»åž‹: {knowledge_type}")
                logger.debug(f"   - æ–‡ä»¶æ¥æº: {item.get('file_path', 'æœªçŸ¥')}")
                
                try:
                    if self.is_chroma_store:
                        # ä½¿ç”¨å‘é‡åŒ–å­˜å‚¨
                        self._add_knowledge_with_vectorization(
                            knowledge_type=knowledge_type,
                            title=item["title"],
                            content=item["content"],
                            tags=item["tags"]
                        )
                    else:
                        # ä½¿ç”¨æ—§çš„å­˜å‚¨æ–¹å¼
                        if knowledge_type == "troubleshooting":
                            self.manager.add_troubleshooting_guide(
                                title=item["title"],
                                content=item["content"],
                                tags=item["tags"]
                            )
                        elif knowledge_type == "configuration":
                            self.manager.add_configuration_guide(
                                title=item["title"],
                                content=item["content"],
                                tags=item["tags"]
                            )
                        elif knowledge_type == "best_practice":
                            self.manager.add_best_practice(
                                title=item["title"],
                                content=item["content"],
                                tags=item["tags"]
                            )
                        else:
                            # Default to troubleshooting guide
                            self.manager.add_troubleshooting_guide(
                                title=item["title"],
                                content=item["content"],
                                tags=item["tags"]
                            )
                    
                    self._increment_count()
                    logger.info(f"âœ… çŸ¥è¯†æ¡ç›®åˆå§‹åŒ–æˆåŠŸ: {item['title'][:30]}...")
                    
                except Exception as e:
                    logger.error(f"âŒ çŸ¥è¯†æ¡ç›®åˆå§‹åŒ–å¤±è´¥: {item['title'][:30]}...")
                    logger.error(f"   é”™è¯¯è¯¦æƒ…: {str(e)}")
                    logger.error(f"   æ–‡ä»¶è·¯å¾„: {item.get('file_path', 'æœªçŸ¥')}")
            
            logger.info(f"âœ… ç±»åˆ« '{category_name}' å¤„ç†å®Œæˆ: {len(knowledge_items)} ä¸ªæ¡ç›®")
        
        logger.info(f"âœ… æ‰€æœ‰çŸ¥è¯†æ–‡ä»¶å¤„ç†å®Œæˆï¼Œå…± {self.initialized_count} ä¸ªæ¡ç›®")
    
    def _add_knowledge_with_vectorization(
        self, 
        knowledge_type: str, 
        title: str, 
        content: str, 
        tags: List[str]
    ) -> None:
        """æ·»åŠ çŸ¥è¯†å¹¶è¿›è¡Œå‘é‡åŒ–å­˜å‚¨.
        
        Args:
            knowledge_type: çŸ¥è¯†ç±»åž‹ï¼ˆtroubleshooting, configuration, best_practiceï¼‰
            title: æ ‡é¢˜
            content: å†…å®¹
            tags: æ ‡ç­¾åˆ—è¡¨
        """
        from datetime import datetime
        import logging
        
        logger = logging.getLogger("nanobot.knowledge.rocketmq_init")
        
        # ç”Ÿæˆå”¯ä¸€ ID
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S%f")
        item_id = f"{self.domain}_{timestamp}"
        
        # ç¡®å®šä¼˜å…ˆçº§
        priority_map = {
            "troubleshooting": 3,
            "configuration": 2,
            "best_practice": 4
        }
        priority = priority_map.get(knowledge_type, 2)
        
        # å‡†å¤‡å…ƒæ•°æ®
        metadata = {
            "item_id": item_id,
            "domain": self.domain,
            "category": knowledge_type,
            "title": title,
            "tags": tags,
            "source": "system",
            "priority": priority,
            "created_at": datetime.now().isoformat(),
            "updated_at": datetime.now().isoformat()
        }
        
        try:
            logger.info(f"ðŸ§© å¼€å§‹å‘é‡åŒ–å¤„ç†çŸ¥è¯†æ¡ç›®: {title[:50]}...")
            logger.debug(f"   - æ¡ç›®ID: {item_id}")
            logger.debug(f"   - çŸ¥è¯†ç±»åž‹: {knowledge_type}")
            logger.debug(f"   - å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
            
            # 1. æ–‡æœ¬åˆ†å—
            logger.info(f"ðŸ“„ æ­£åœ¨å¯¹æ–‡æœ¬è¿›è¡Œåˆ†å—å¤„ç†...")
            chunks = self.store.chunker.chunk_text(content, metadata)
            
            if not chunks:
                logger.warning(f"âš ï¸ çŸ¥è¯†æ¡ç›® {item_id} åˆ†å—åŽä¸ºç©ºï¼Œè·³è¿‡")
                return
            
            logger.info(f"âœ… æ–‡æœ¬åˆ†å—å®Œæˆ: {len(chunks)} ä¸ªåˆ†å—")
            logger.debug(f"   - å¹³å‡åˆ†å—å¤§å°: {sum(len(chunk['text']) for chunk in chunks) / len(chunks):.0f} å­—ç¬¦")
            
            # 2. æ‰¹é‡å‘é‡åŒ–
            logger.info(f"ðŸ”¢ æ­£åœ¨å¯¹ {len(chunks)} ä¸ªåˆ†å—è¿›è¡Œå‘é‡åŒ–...")
            chunk_texts = [chunk["text"] for chunk in chunks]
            try:
                embeddings = self.store.embedder.embed_batch(chunk_texts)
                logger.info(f"âœ… å‘é‡åŒ–å®Œæˆ: {len(embeddings)} ä¸ªå‘é‡ï¼Œç»´åº¦: {len(embeddings[0]) if embeddings else 0}")
                logger.debug(f"   - å‘é‡åŒ–æˆåŠŸçŽ‡: {len(embeddings)}/{len(chunks)}")
            except Exception as e:
                logger.error(f"âŒ çŸ¥è¯†æ¡ç›® {item_id} å‘é‡åŒ–å¤±è´¥: {str(e)}")
                return
            
            # 3. å­˜å‚¨åˆ° Chroma
            logger.info(f"ðŸ’¾ æ­£åœ¨å­˜å‚¨åˆ° Chroma æ•°æ®åº“...")
            collection = self.store._get_or_create_collection(self.domain)
            
            # å‡†å¤‡æ‰¹é‡æ’å…¥çš„æ•°æ®
            ids = []
            documents = []
            metadatas = []
            embeddings_list = []
            
            for i, (chunk, embedding) in enumerate(zip(chunks, embeddings)):
                chunk_id = f"{item_id}_chunk_{i}"
                ids.append(chunk_id)
                documents.append(chunk["text"])
                metadatas.append(chunk["metadata"])
                embeddings_list.append(embedding)
            
            # æ‰¹é‡æ’å…¥åˆ° Chroma
            collection.add(
                ids=ids,
                documents=documents,
                metadatas=metadatas,
                embeddings=embeddings_list
            )
            
            # æ›´æ–°åˆ†å—è®¡æ•°
            self.chunk_count += len(chunks)
            
            logger.info(f"âœ… çŸ¥è¯†æ¡ç›® '{title[:30]}...' å·²æˆåŠŸå­˜å‚¨: {len(chunks)} ä¸ªåˆ†å—")
            logger.info(f"ðŸ“Š å­˜å‚¨ç»Ÿè®¡: æ¡ç›® {self.initialized_count + 1}, åˆ†å— {self.chunk_count}")
            logger.debug(f"   - å­˜å‚¨é›†åˆ: {self.domain}")
            logger.debug(f"   - å­˜å‚¨æ—¶é—´: {datetime.now().strftime('%H:%M:%S')}")
            
        except Exception as e:
            logger.error(f"âŒ çŸ¥è¯†æ¡ç›® {item_id} å­˜å‚¨å¤±è´¥: {str(e)}")
            logger.error(f"   é”™è¯¯è¯¦æƒ…: {str(e)}")
            logger.error(f"   æ¡ç›®æ ‡é¢˜: {title}")
            logger.error(f"   çŸ¥è¯†ç±»åž‹: {knowledge_type}")
    
    def _determine_knowledge_type(self, category_name: str, content: str) -> str:
        """Determine the type of knowledge based on category and content."""
        category_lower = category_name.lower()
        content_lower = content.lower()
        
        if any(keyword in category_lower for keyword in ['troubleshoot', 'problem', 'issue', 'error', 'æ•…éšœ', 'é—®é¢˜']):
            return "troubleshooting"
        elif any(keyword in category_lower for keyword in ['config', 'setup', 'install', 'éƒ¨ç½²', 'é…ç½®', 'å®‰è£…']):
            return "configuration"
        elif any(keyword in category_lower for keyword in ['best', 'practice', 'guide', 'æœ€ä½³', 'å®žè·µ', 'æŒ‡å—']):
            return "best_practice"
        elif any(keyword in content_lower for keyword in ['æŽ’æŸ¥', 'é—®é¢˜', 'é”™è¯¯', 'æ•…éšœ', 'troubleshoot', 'problem']):
            return "troubleshooting"
        elif any(keyword in content_lower for keyword in ['é…ç½®', 'å®‰è£…', 'éƒ¨ç½²', 'config', 'setup', 'install']):
            return "configuration"
        elif any(keyword in content_lower for keyword in ['æœ€ä½³', 'å®žè·µ', 'æŒ‡å—', 'best', 'practice', 'guide']):
            return "best_practice"
        
        return "troubleshooting"  # Default type
    
    def _initialize_embedded_knowledge(self) -> None:
        """Fallback to embedded knowledge if no files found."""
        # Add basic troubleshooting guide as fallback
        title = "RocketMQçŸ¥è¯†åº“åˆå§‹åŒ–"
        content = "RocketMQçŸ¥è¯†åº“å·²ä»Žæ–‡ä»¶ç³»ç»ŸåŠ è½½ã€‚å¦‚æžœæœªæ‰¾åˆ°çŸ¥è¯†æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥knowledgeç›®å½•ç»“æž„ã€‚"
        tags = ["åˆå§‹åŒ–", "RocketMQ", "çŸ¥è¯†åº“"]
        
        if self.is_chroma_store:
            self._add_knowledge_with_vectorization(
                knowledge_type="troubleshooting",
                title=title,
                content=content,
                tags=tags
            )
        else:
            self.manager.add_troubleshooting_guide(
                title=title,
                content=content,
                tags=tags
            )
        
        self._increment_count()
    
    # ç¡¬ç¼–ç çš„çŸ¥è¯†å†…å®¹å·²è¢«ç§»é™¤ï¼Œæ”¹ä¸ºä»Žæ–‡ä»¶ç³»ç»Ÿè¯»å–knowledgeç›®å½•ä¸­çš„çŸ¥è¯†æ–‡ä»¶
    # çŸ¥è¯†æ–‡ä»¶åº”æŒ‰ç…§ç›®å½•ç»“æž„ç»„ç»‡ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨åˆ†ç±»å’ŒåŠ è½½


def initialize_rocketmq_knowledge(workspace: Path) -> int | tuple[int, int]:
    """Initialize built-in RocketMQ knowledge."""
    store = ChromaKnowledgeStore(workspace)
    initializer = RocketMQKnowledgeInitializer(store)
    return initializer.initialize()